{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O67uhlT4MExK"
   },
   "source": [
    "_Lambda School Data Science — Practicing & Understanding Predictive Modeling_\n",
    "\n",
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VE4rfZd4NUGA"
   },
   "source": [
    "Today we'll use this process:\n",
    "\n",
    "## \"A universal workflow of machine learning\"\n",
    "\n",
    "_Excerpt from Francois Chollet, [Deep Learning with Python](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/README.md), Chapter 4: Fundamentals of machine learning_\n",
    " \n",
    "**1. Define the problem at hand and the data on which you’ll train.** Collect this data, or annotate it with labels if need be.\n",
    "\n",
    "**2. Choose how you’ll measure success on your problem.** Which metrics will you monitor on your validation data?\n",
    "\n",
    "**3. Determine your evaluation protocol:** hold-out validation? K-fold validation? Which portion of the data should you use for validation?\n",
    "\n",
    "**4. Develop a first model that does better than a basic baseline:** a model with statistical power.\n",
    "\n",
    "**5. Develop a model that overfits.** The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
    "\n",
    "**6. Regularize your model and tune its hyperparameters, based on performance on the validation data.** Repeatedly modify your model, train it, evaluate on your validation data (not the test data, at this point), modify it again, and repeat, until the model is as good as it can get. \n",
    "\n",
    "**Iterate on feature engineering: add new features, or remove features that don’t seem to be informative.** \n",
    "\n",
    "Once you’ve developed a satisfactory model configuration, you can **train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3kt6bzEcOIaa"
   },
   "source": [
    "## 1. Define the problem at hand and the data on which you'll train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "di16k7vpRg67"
   },
   "source": [
    "We'll apply the workflow to a [project from _Python Data Science Handbook_](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic) by Jake VanderPlas:\n",
    "\n",
    "> **Predicting Bicycle Traffic**\n",
    "\n",
    "> As an example, let's take a look at whether we can predict the number of bicycle trips across Seattle's Fremont Bridge based on weather, season, and other factors.\n",
    "\n",
    "> We will join the bike data with another dataset, and try to determine the extent to which weather and seasonal factors—temperature, precipitation, and daylight hours—affect the volume of bicycle traffic through this corridor. Fortunately, the NOAA makes available their daily [weather station data](http://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND) (I used station ID USW00024233) and we can easily use Pandas to join the two data sources.\n",
    "\n",
    "> Let's start by loading the two datasets, indexing by date:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19dpb_d0R1A6"
   },
   "source": [
    "So this is a regression problem, not a classification problem. We'll define the target, choose an evaluation metric, and choose models that are appropriate for regression problems.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "os1zruXQ30KM"
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XVu-HSeMDtV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1616k    0 1616k    0     0   861k      0 --:--:--  0:00:01 --:--:--  861k\n"
     ]
    }
   ],
   "source": [
    "!curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sih_7mTzMdfr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-13 15:36:28--  https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.52.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.52.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 234945 (229K) [text/plain]\n",
      "Saving to: ‘BicycleWeather.csv.4’\n",
      "\n",
      "BicycleWeather.csv. 100%[===================>] 229.44K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2019-05-13 15:36:28 (3.47 MB/s) - ‘BicycleWeather.csv.4’ saved [234945/234945]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GYm74kD34OQ"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BfQ7gE28MNdF"
   },
   "outputs": [],
   "source": [
    "# Modified from cells 15, 16, and 20, at\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Download and join data into a dataframe\n",
    "def load(): \n",
    "    fremont_bridge = 'https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD'\n",
    "    \n",
    "    bicycle_weather = 'https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv'\n",
    "\n",
    "    counts = pd.read_csv(fremont_bridge, index_col='Date', parse_dates=True, \n",
    "                         infer_datetime_format=True)\n",
    "\n",
    "    weather = pd.read_csv(bicycle_weather, index_col='DATE', parse_dates=True, \n",
    "                          infer_datetime_format=True)\n",
    "\n",
    "    daily = counts.resample('d').sum()\n",
    "    daily['Total'] = daily.sum(axis=1)\n",
    "    daily = daily[['Total']] # remove other columns\n",
    "\n",
    "    weather_columns = ['PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND']\n",
    "    daily = daily.join(weather[weather_columns], how='inner')\n",
    "    \n",
    "    # Make a feature for yesterday's total\n",
    "    daily['Total_yesterday'] = daily.Total.shift(1)\n",
    "    daily = daily.drop(index=daily.index[0])\n",
    "    \n",
    "    return daily\n",
    "\n",
    "daily = load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VVB3g4704An5"
   },
   "source": [
    "### First fast look at the data\n",
    "- What's the shape?\n",
    "- What's the date range?\n",
    "- What's the target and the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t50E2fTUWBBU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1063, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "daily.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>Total_yesterday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-28</th>\n",
       "      <td>2653.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>156</td>\n",
       "      <td>26</td>\n",
       "      <td>4336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-29</th>\n",
       "      <td>699.0</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>133</td>\n",
       "      <td>58</td>\n",
       "      <td>2653.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-30</th>\n",
       "      <td>1213.0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>47</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-31</th>\n",
       "      <td>2823.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>161</td>\n",
       "      <td>58</td>\n",
       "      <td>1213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-01</th>\n",
       "      <td>2876.0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>139</td>\n",
       "      <td>-9999</td>\n",
       "      <td>2823.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
       "2015-08-28  2653.0     5     0     0   233   156    26           4336.0\n",
       "2015-08-29   699.0   325     0     0   222   133    58           2653.0\n",
       "2015-08-30  1213.0   102     0     0   200   128    47            699.0\n",
       "2015-08-31  2823.0     0     0     0   189   161    58           1213.0\n",
       "2015-09-01  2876.0    58     0     0   194   139 -9999           2823.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# daily.head()\n",
    "daily.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1063 entries, 2012-10-04 to 2015-09-01\n",
      "Data columns (total 8 columns):\n",
      "Total              1063 non-null float64\n",
      "PRCP               1063 non-null int64\n",
      "SNOW               1063 non-null int64\n",
      "SNWD               1063 non-null int64\n",
      "TMAX               1063 non-null int64\n",
      "TMIN               1063 non-null int64\n",
      "AWND               1063 non-null int64\n",
      "Total_yesterday    1063 non-null float64\n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 74.7 KB\n"
     ]
    }
   ],
   "source": [
    "daily.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgMvCsaWJR7Q"
   },
   "source": [
    "Target\n",
    "- Total : Daily total number of bicycle trips across Seattle's Fremont Bridge\n",
    "\n",
    "Features\n",
    "- Date (index) : from 2012-10-04 to 2015-09-01\n",
    "- Total_yesterday : Total trips yesterday\n",
    "- PRCP : Precipitation (1/10 mm)\n",
    "- SNOW : Snowfall (1/10 mm)\n",
    "- SNWD : Snow depth (1/10 mm)\n",
    "- TMAX : Maximum temperature (1/10 Celsius)\n",
    "- TMIN : Minimum temperature (1/10 Celsius)\n",
    "- AWND : Average daily wind speed (1/10 meters per second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lenL-przSYCo"
   },
   "source": [
    "## 2. Choose how you’ll measure success on your problem.\n",
    "\n",
    "Which metrics will you monitor on your validation data?\n",
    "\n",
    "This is a regression problem, so we need to choose a regression [metric](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
    "\n",
    "\n",
    "\n",
    "I'll choose mean absolute error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1TqbomapSyRP"
   },
   "outputs": [],
   "source": [
    "# TODO from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IRHrB3rsS5hF"
   },
   "source": [
    "## 3. Determine your evaluation protocol \n",
    "\n",
    "We're doing model selection, hyperparameter optimization, and performance estimation. So generally we have two ideal [options](https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg) to choose from:\n",
    "\n",
    "- 3-way holdout method (train/validation/test split)\n",
    "- Cross-validation with independent test set\n",
    "\n",
    "I'll choose cross-validation with independent test set. Scikit-learn makes cross-validation convenient for us!\n",
    "\n",
    "Specifically, I will use random shuffled cross validation to train and validate, but I will hold out an \"out-of-time\" test set, from the last 100 days of data:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3xo6HgbPMFm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((963, 8), (100, 8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "train = daily[:-100] #everything but the last 100 days\n",
    "test = daily[-100:]\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Total', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND',\n",
       "       'Total_yesterday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((963, 7), (963,), (100, 7), (100,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(columns='Total')\n",
    "y_train = train['Total']\n",
    "\n",
    "X_test = test.drop(columns='Total')\n",
    "y_test = test['Total']\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vH6IsORQTvTU"
   },
   "source": [
    "## 4. Develop a first model that does better than a basic baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJBs2nQkj7oB"
   },
   "source": [
    "### Look at the target's distribution and descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5peakv9Zs71"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.distplot(y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     963.000000\n",
       "mean     2534.329180\n",
       "std      1224.065027\n",
       "min        98.000000\n",
       "25%      1755.000000\n",
       "50%      2381.000000\n",
       "75%      3317.500000\n",
       "max      6088.000000\n",
       "Name: Total, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEjxxgV9kExY"
   },
   "source": [
    "### Basic baseline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GepKdQjYcEP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "971.9376947040498"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [y_train.median()] * len(y_train)\n",
    "mean_absolute_error(y_train, y_pred) #this is in the units of y, # of bicyclists per day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tN2I_F3FkIHb"
   },
   "source": [
    "### Basic baseline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZW8bhZFtTunV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708.061266874351"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X_train['Total_yesterday']\n",
    "mean_absolute_error(y_train, y_pred) #a bit better, within one std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ggf3VpxwkJ0T"
   },
   "source": [
    "### First model that does better than a basic baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KfaqL1Ezer2-"
   },
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OeBtU68skfW-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>estimator</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001651</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>-651.126513</td>\n",
       "      <td>-583.427702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>-615.965800</td>\n",
       "      <td>-589.341301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>-555.186275</td>\n",
       "      <td>-619.509206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time                                          estimator  \\\n",
       "1  0.001651    0.000592  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "2  0.001985    0.000637  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "0  0.008414    0.000773  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "\n",
       "   test_score  train_score  \n",
       "1 -651.126513  -583.427702  \n",
       "2 -615.965800  -589.341301  \n",
       "0 -555.186275  -619.509206  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(LinearRegression(), X_train, y_train,\n",
    "                       scoring='neg_mean_absolute_error', cv=3, #neg MAE makes this score higher is better\n",
    "                       return_train_score=True, return_estimator=True)\n",
    "\n",
    "pd.DataFrame(scores).sort_values(by='test_score')\n",
    "\n",
    "# sklearn tries to maximize, so neg MAE flips and now we want to max this score (to zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607.4261958631805"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've beaten the Total_yesterday baseline by 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566.7766337283692"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['estimator'][0].intercept_\n",
    "#the actual model is in here, not text, so we can call built in functs on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model from cross-validation fold #0\n",
      "Intercept 566.7766337283692\n",
      "PRCP               -3.525103\n",
      "SNOW               -0.082029\n",
      "SNWD              -12.045027\n",
      "TMAX                9.475238\n",
      "TMIN               -4.607775\n",
      "AWND               -2.745191\n",
      "Total_yesterday     0.417360\n",
      "\n",
      "\n",
      "Model from cross-validation fold #1\n",
      "Intercept 671.9064515706045\n",
      "PRCP               -2.772253\n",
      "SNOW               -0.000995\n",
      "SNWD               20.800688\n",
      "TMAX                8.804948\n",
      "TMIN               -3.741386\n",
      "AWND               -6.108300\n",
      "Total_yesterday     0.405074\n",
      "\n",
      "\n",
      "Model from cross-validation fold #2\n",
      "Intercept 465.84525362296336\n",
      "PRCP               -2.876196\n",
      "SNOW               -0.016432\n",
      "SNWD               -8.809696\n",
      "TMAX               10.419441\n",
      "TMIN               -5.862868\n",
      "AWND               -2.398991\n",
      "Total_yesterday     0.423493\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(scores['estimator']):\n",
    "    coefficients = model.coef_\n",
    "    intercept = model.intercept_\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    print(f'Model from cross-validation fold #{i}')\n",
    "    print('Intercept', intercept)\n",
    "    print(pd.Series(coefficients, feature_names).to_string())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fg1YI4X8n9nI"
   },
   "source": [
    "## 5. Develop a model that overfits. \n",
    "\n",
    "\"The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\" —Chollet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lodd6UPOoy89"
   },
   "source": [
    "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.03-validation-curve.png\">\n",
    "\n",
    "Diagram Source: https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xj82P0VdwYlh"
   },
   "source": [
    "### Random Forest?\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_yYXpk99C4cM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>estimator</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.184757</td>\n",
       "      <td>0.102902</td>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>-644.242617</td>\n",
       "      <td>-223.864315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200848</td>\n",
       "      <td>0.102863</td>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>-640.918255</td>\n",
       "      <td>-223.415327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.792009</td>\n",
       "      <td>0.104330</td>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>-555.883209</td>\n",
       "      <td>-240.566121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time                                          estimator  \\\n",
       "2  0.184757    0.102902  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "1  0.200848    0.102863  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "0  0.792009    0.104330  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "\n",
       "   test_score  train_score  \n",
       "2 -644.242617  -223.864315  \n",
       "1 -640.918255  -223.415327  \n",
       "0 -555.883209  -240.566121  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# from xgboost import \n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=None, n_jobs=-1)\n",
    "\n",
    "scores = cross_validate(model, X_train, y_train,\n",
    "                       scoring='neg_mean_absolute_error', cv=3, #neg MAE makes this score higher is better\n",
    "                       return_train_score=True, return_estimator=True)\n",
    "\n",
    "RFR_scores = pd.DataFrame(scores).sort_values(by='test_score')\n",
    "\n",
    "RFR_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229.28192107995847"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-scores['train_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ryO1hVKr-6f"
   },
   "source": [
    "### Validation Curve\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html\n",
    "\n",
    "> Validation curve. Determine training and test scores for varying parameter values. This is similar to grid search with one parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apKk4vKiwgtM"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XucznX+//HHq4kUWiKdJCqKGeM0pJQQVm0lHXXa1LZKh2/tb1Oq7aRskdJWq1bHrdhIB8qhUkm1JWMyRSjEGoeMQ84GM6/fH+/LGMyYYQ6fOTzvt9t1c83n+lzX9ZrPuD6v6/M+vN7m7oiISMV2QNQBiIhI9JQMREREyUBERJQMREQEJQMREUHJQEREUDIQERGUDEREBCUDEREBDow6gIKqXbu2169fP+owRETKjOnTp69098MLsm+ZSQb169cnOTk56jBERMoMM1tU0H3VTCQiIkoGIiKiZCAiIpShPoPcbNu2jbS0NLZs2RJ1KFIIVapUoW7dulSqVCnqUEQqrDKdDNLS0qhevTr169fHzKIOR/aDu7Nq1SrS0tJo0KBB1OGIVFhluploy5Yt1KpVS4mgDDMzatWqpas7kYiV6WQAKBGUA/obikSvzCcDEZHy6tNPYdCgknkvJYNC+O233xg6dOh+Pfecc87ht99+2+s+999/P5MmTdqv1xeRsmv6dOjaFc46C55/HjZtKv73LJJkYGZ3mJmbWe3Yzx3MbK2ZzYjd7s+xbzczm2tm88ysX1G8f1T2lgwyMzP3+tzx48dTo0aNve7Tv39/OnfuvN/xFZf8fjcR2T8//QSXXgpJSZCSAk8+CT/+CIccUvzvXehkYGbHAl2A/+320Bfu3jx26x/bNw74J3A20AS43MyaFDaGqPTr14/58+fTvHlz+vbty+TJk+nYsSNXXHEFTZs2BeCCCy6gVatWxMfHM2zYsOzn1q9fn5UrV7Jw4UIaN27Mn//8Z+Lj4+natSubN28GoFevXowePTp7/wceeICWLVvStGlT5syZA0B6ejpdunShZcuW3HDDDRx33HGsXLlylzgzMzPp1asXCQkJNG3alCFDhgAwb948OnfuTLNmzWjZsiXz58/H3enbt2/2viNHjgTI9Xd74403aNOmDc2bN+eGG25QkhDZT0uWwA03QJMmMH483H8/LFgAf/kLVKlSMjEUxdDSIcCdwJgC7NsGmOfuCwDM7E2gO/BjYYO4/XaYMaOwr7Kr5s3hqafyfvyxxx5j5syZzIi98eTJk/n222+ZOXNm9jDJl19+mcMOO4zNmzfTunVrLrroImrVqrXL6/z888/85z//4YUXXuDSSy/l7bff5qqrrtrj/WrXrk1KSgpDhw5l8ODBvPjiizz00EN06tSJu+++m4kTJ+6ScHaYMWMGS5YsYebMmQDZzVNXXnkl/fr1o0ePHmzZsoWsrCzeeecdZsyYQWpqKitXrqR169a0b98eYJffbfbs2YwcOZKvvvqKSpUqcdNNNzF8+HD++Mc/7vuBFqmgVq+GgQPh6achMxNuugnuvReOOKLkYylUMjCz84El7p6ay4iQU80sFVgK3OHus4BjgMU59kkDTilMDKVNmzZtdhkv//TTT/Puu+8CsHjxYn7++ec9kkGDBg1o3rw5AK1atWLhwoW5vvaFF16Yvc8777wDwJdffpn9+t26daNmzZp7PO/4449nwYIF3HrrrfzhD3+ga9eurF+/niVLltCjRw8gTPza8XqXX345cXFxHHHEEZx55plMmzaNQw89dJff7ZNPPmH69Om0bt0agM2bN1OnTp19P2AiFdDGjSEBDBwI69bBVVfBQw9BlFNt8k0GZjYJODKXh+4F7gG65vJYCnCcu28ws3OA94CGQG5jCH0v790b6A1Qr169vca5t2/wJalq1arZ9ydPnsykSZP4+uuvOeSQQ+jQoUOu4+kPOuig7PtxcXHZzUR57RcXF8f27duBMGkrPzVr1iQ1NZUPP/yQf/7zn4waNYqn8jhge3u9nL+bu3PNNdfw6KOP5vv+IhJs2wYvvgj9+8Py5XDeeTBgAMRaXiOVb5+Bu3d294Tdb8ACoAGQamYLgbpAipkd6e7r3H1D7PnjgUqxzuU04NgcL1+XcOWQ13sPc/ckd086/PACleQuUdWrV2f9+vV5Pr527Vpq1qzJIYccwpw5c/jmm2+KPIbTTz+dUaNGAfDRRx+xZs2aPfZZuXIlWVlZXHTRRTz88MOkpKRw6KGHUrduXd577z0AMjIy2LRpE+3bt2fkyJFkZmaSnp7OlClTaNOmzR6vedZZZzF69GhWrFgBwOrVq1m0qMDVckUqlKwsePNNaNw4NAWdeCJ8+SWMHVs6EgEUogPZ3X9w9zruXt/d6xNO9C3dfbmZHWmxdiMzaxN7n1XANKChmTUws8pAT2BsoX+LiNSqVYt27dqRkJBA375993i8W7dubN++ncTERO677z7atm1b5DE88MADfPTRR7Rs2ZIJEyZw1FFHUb169V32WbJkCR06dKB58+b06tUr+9v866+/ztNPP01iYiKnnXYay5cvp0ePHiQmJtKsWTM6derEoEGDOPLIPS8MmzRpwiOPPELXrl1JTEykS5cuLFu2rMh/P5GyzB0mToRWreDyy8OooA8+gClToF27qKPbjbsXyQ1YCNSO3b8FmAWkAt8Ap+XY7xzgJ2A+cG9BX79Vq1a+ux9//HGPbRXNli1bfNu2be7u/t///tebNWsWcUT7R39LKW++/tr9zDPdwb1BA/c33nDPzCzZGIBkL+A5tsgK1Xm4Othx/1ng2Tz2Gw+ML6r3rej+97//cemll5KVlUXlypV54YUXog5JpEKbNQv+9jd47z2oUweefRb+/GeoXDnqyPauTFctFWjYsCHfffdd1GGIVHiLFsGDD8Jrr0G1avDww2HIe7VqUUdWMEoGIiKFkJ4Of/87DB0KZmGiWL9+ULt21JHtGyUDEZH9sH49DBkCgweHeQPXXgsPPADHHpv/c0sjJQMRkX2QkQH/+hc88ki4KrjwwnC/ceOoIyscVS0VESmAzMzQH3DSSXDbbZCQAFOnwttvl/1EAEoGJa5arDdp6dKlXHzxxbnu06FDB5KTk/f6Ok899RSbctS1LUhJbBHZd+7w/vuhVtk110CtWvDRR/DJJ5DLfMwyS8kgIkcffXR2RdL9sXsyKEhJ7CiokqmUZV98AaefDuefH5qHRo6EadOgS5fQWVyeKBkUwl133bXLegYPPvggTzzxBBs2bOCss87KLjc9ZsyeBV0XLlxIQkICEIq89ezZk8TERC677LJdahP16dOHpKQk4uPjeeCBB4BQ/G7p0qV07NiRjh07AjtLYgM8+eSTJCQkkJCQkF2DaG+lsnN66623SEhIoFmzZtnVSjMzM7njjjto2rQpiYmJPPPMM0AoVteiRQuaNm3KddddR0ZGRnYs/fv35/TTT+ett95i/vz5dOvWjVatWnHGGWdkl98WKa1SU+EPf4D27WHhwtBHMGtWWGvggPJ61izo7LSob/nOQL7ttjDdryhvt92219l9KSkp3r59++yfGzdu7IsWLfJt27b52rVr3d09PT3dTzjhBM/KynJ396pVq7q7+y+//OLx8fHu7v7EE0/4tdde6+7uqampHhcX59OmTXN391WrVrm7+/bt2/3MM8/01NRUd3c/7rjjPD09Pfu9d/ycnJzsCQkJvmHDBl+/fr03adLEU1JS/JdffvG4uDj/7rvv3N39kksu8ddff32P3ykhIcHT0tLc3X3NmjXu7j506FC/8MILs2c6r1q1yjdv3ux169b1uXPnurv71Vdf7UOGDMmOZeDAgdmv2alTJ//pp5/c3f2bb77xjh077vG+moEspcH8+e5XXOFu5l6jhvvAge4bN0Yd1f5jH2Ygl9ccVyJatGjBihUrWLp0KampqdSsWZN69erh7txzzz0kJibSuXNnlixZwq+//prn60yZMiV7/YLExEQSExOzHxs1ahQtW7akRYsWzJo1ix9/3PvSD19++SU9evSgatWqVKtWjQsvvJAvvvgCKFip7Hbt2tGrVy9eeOGF7CaeSZMmceONN3LggWHw2WGHHcbcuXNp0KABjRo1AuCaa65hypQp2a9z2WWXAbBhwwb++9//cskll2QvgqMaRlLaLF8Ot9wSOofffTfME1iwAO68s2RWGSsNys/Q0ohqWF988cWMHj2a5cuX07NnTwCGDx9Oeno606dPp1KlStSvXz/X0tU55bIeBL/88guDBw9m2rRp1KxZk169euX7Or6XEtQFKZX9/PPPM3XqVMaNG0fz5s2ZMWMG7r5HfHt7H9hZ7jorK4saNWpkLwAkUpqsXQuPPx7mC2RkhLIR990HRx8ddWQlT1cGhdSzZ0/efPNNRo8enT06aO3atdSpU4dKlSrx2Wef5VvauX379gwfPhyAmTNn8v333wOwbt06qlatyu9+9zt+/fVXJkyYkP2cvMpnt2/fnvfee49NmzaxceNG3n33Xc4444wC/z7z58/nlFNOoX///tSuXZvFixfTtWtXnn/++ew1FFavXs3JJ5/MwoULmTdvHhAqoJ555pl7vN6hhx5KgwYNeOutt4CQRFJTUwscj0hx2Lw5TBY7/viwnsD558Ps2fDccxUzEYCSQaHFx8ezfv16jjnmGI466iggLCeZnJxMUlISw4cP5+STT97ra/Tp04cNGzaQmJjIoEGDstcPaNasGS1atCA+Pp7rrruOdjlq3vbu3Zuzzz47uwN5h5YtW9KrVy/atGnDKaecwvXXX0+LFi0K/Pv07duXpk2bkpCQQPv27WnWrBnXX3899erVyy5tPWLECKpUqcIrr7zCJZdcQtOmTTnggAO48cYbc33N4cOH89JLL9GsWTPi4+Nz7VAXKQnbt8NLL0GjRtC3bxgampIC//kPNGwYdXTRsvwu90uLpKQk333s/ezZs2lcHmZ7iP6WUqzc4Z13wvrCc+fCKafAY49Bhw5RR1a8zGy6uycVZF9dGYhIufbJJ+Hkf/HFYVjou+/C11+X/0Swr5QMRKRcmj4dunaFzp3DaKFXXoEffoALLih/E8aKQplPBmWlmUvypr+hFKW5c8PksKSk0B8wZAj89BP06gVxcVFHV3qV6WRQpUoVVq1apZNJGeburFq1iipVqkQdipRxS5ZA794QHw/jx8P994e5ArffDvrvlb8yPc+gbt26pKWlkZ6eHnUoUghVqlShbt26UYchZdTq1TBwIDz9dKgsevPNoaO4Tp2oIytbynQyqFSpEg0aNIg6DBGJwMaNIQEMHAjr1sFVV8FDD4FOCfunTCcDEal4tm2DF1+E/v1Dx/B554WJY02bRh1Z2aZkICJlQlYWjBoFf/sbzJ8fSkuPHg055mJKIZTpDmQRKf/cYeJEaNUKLr8cqlaFceNgyhQlgqKkZCAipdY330DHjnD22aGo3BtvwHffwTnnaK5AUVMyEJFSZ9Ys6NEDTj01FJB79lmYMweuvLIcLy4TMR1WESk1Fi2Ca6+FxET49FN45JHQP3DzzVC5ctTRlW/qQBaRyKWnw9//DkOHhuafv/wF7r47LD4vJUPJQEQis359KBcxeHCYN3DttfDAA3DssVFHVvEoGYhIicvICIvMP/JIuCq46CJ4+GFQFfPoqM9AREpMZia89lpYa/i228JEsalTw3wBJYJoKRmISLFzh7FjoXlzuOaa0Bfw0UcwaVJYbUyip2QgIsXq88/D5LDu3UPz0MiRMG0adOmiuQKliZKBiBSL774Lk8U6dAhDRocNC/MHLr1UcwVKI/1JRKRI/fwz9OwJLVuG/oDHH4d58+DPf4ZKlaKOTvJSqGRgZg+a2RIzmxG7nZPjsbvNbJ6ZzTWz3+fY3i22bZ6Z9SvM+4tI6bF0Kdx4Y+gIfv/9sKbAggVwxx1w8MFRRyf5KYqhpUPcfXDODWbWBOgJxANHA5PMrFHs4X8CXYA0YJqZjXX3H4sgDhGJwJo1YU2Bf/wjjBbq0yckgiOPjDoy2RfFNc+gO/Cmu2cAv5jZPGDHmIF57r4AwMzejO2rZCBSxmhxmfKlKPoMbjGz783sZTOrGdt2DLA4xz5psW15bReRMmLr1lA24sQT4Z57oH17SE0N8weUCMqufJOBmU0ys5m53LoDzwEnAM2BZcATO56Wy0v5Xrbn9d69zSzZzJK1zrFItLKyYMSI0Cdw883QsCF89VWYP6BVxsq+fJuJ3L1zQV7IzF4APoj9mAbkrC5SF1gau5/X9tzeexgwDCApKSnPpCEixccdxo8PVwHffw/NmoWfu3XTPIHypLCjiY7K8WMPYGbs/ligp5kdZGYNgIbAt8A0oKGZNTCzyoRO5rGFiUFEis+XX4ZmoHPPDX0EI0ZASkqYP6BEUL4UtgN5kJk1JzT1LARuAHD3WWY2itAxvB242d0zAczsFuBDIA542d1nFTIGESli338frgTGjQujgp57Dv70J80TKM/MvWy0viQlJXlycnLUYYiUawsWwP33hyuA3/0O+vWDW2+FQw6JOjLZH2Y23d2TCrKvSliLCMuWhXLSw4aFb/933QV33gk1a+b/XCkflAxEKrDffoNBg8KEsa1bQ8mI++6Do47K/7lSvigZiFRAmzaFReYfeyzMIL78cujfP8wdkIpJhepEKpBt20JTUMOGoSno1FNDddERI5QIKjolA5EKICsrrCPQpAnccAPUrx/WGRg3Liw4I6JkIFKOucPEiZCUFMpKV6kSZgzvmD8gsoOSgUg59fXX0LFjmCC2Zg28/jrMmAHnnacJY7InJQORcmbmzLDE5GmnwZw5oaN47txQVTQuLuropLRSMhApJxYuDIvNJybC5Mlh3sC8eaGoXOXKUUcnpZ2GloqUcb/+CgMGwPPPh2/+d9wRRgrVqhV1ZFKWKBmIlFFr18LgwTBkCGzZEmoH3X8/HKMVQmQ/KBmIlDGbN4fFZf7+d1i9Gi69FB5+GBo1yv+5InlRn4FIGbF9O7z0Ujjp33FHGC6anBzmDygRSGEpGYiUcu4wejQkJMD114dmoE8/hQ8/hFatoo5OygslA5FSbNIkaNMGLrkkdA6/++7O+QMiRUnJQKQU+vZbOOss6NIFVqyAV18NC85ccIEmjEnxUDIQKUVmz4aLLoJTToEffgilpX/6Kcwf0IQxKU4aTSRSCvzvf/Dgg/Dvf0PVqvDQQ/CXv0D16lFHJhWFkoFIhNLTwxDRoUND88/tt8Pdd0Pt2lFHJhWNkoFIBNavhyefDJPGNm2CXr3ggQegXr2oI5OKSslApARt2RLKRgwYACtXhv6Bhx+Gxo2jjkwqOnUgi5SAzMwwIuikk0JfQLNmMHVqmD+gRCClgZKBSDFyD3MDEhPh2muhTh34+OOd8wdESgslA5Fi8tln0LYtXHhhuDIYPTrMH+jcOerIRPakZCBSxKZPh65doVMnWLo01BOaOTP0D2jCmJRWSgYiRWTu3FBBNCkJUlLgiSfg55/huuvgQA3VkFJO/0VFCiktLUwSe+WVsOD8/ffDX/8Khx4adWQiBadkILKfVq+GRx+FZ56BrKywvOS994ZOYpGyRslAZB9t3gxPPx0Swbp1cPXV4cqgfv2oIxPZf+ozECmgHYvLNGwI/frB6adDamqoJ6REIGWdkoFIPtxhzJgwV+D666FuXZg8GT74AJo2jTo6kaKhZCCyF199BWecEdYRyMyEt98Oi8uceWbUkYkULSUDkVz8+GNIAKefDvPnw7/+BbNmhQlkmisg5ZGSgUgOaWmhKahp0zCDeMAAmDcPevfWXAEp3/TfWwRYswYGDgwri2VlwW23wT33aF0BqTgKdWVgZg+a2RIzmxG7nRPbXt/MNufY/nyO57Qysx/MbJ6ZPW2mi26JzpYtYU2BE06AQYPg4ovDTOInn1QikIqlKK4Mhrj74Fy2z3f35rlsfw7oDXwDjAe6AROKIA6RAsvMhDfegPvug8WLoVu3MG+geW7/Y0UqgBLtMzCzo4BD3f1rd3fgNeCCkoxBKjZ3GDcunPR79YIjjoBPPoEJE5QIpGIrimRwi5l9b2Yvm1nNHNsbmNl3Zva5mZ0R23YMkJZjn7TYtlyZWW8zSzaz5PT09CIIVSqyb76BDh3g3HND89CoUaGkdKdOUUcmEr18k4GZTTKzmbncuhOafE4AmgPLgCdiT1sG1HP3FsD/A0aY2aFAbv0Dntd7u/swd09y96TDDz98H381kWDu3FA++tRTw/2hQ8PQ0Usu0TBRkR3y7TNw9wItxWFmLwAfxJ6TAWTE7k83s/lAI8KVQN0cT6sLLN3HmEUKZOnSUDPopZfg4IOhf/+w5GS1alFHJlL6FHY00VE5fuwBzIxtP9zM4mL3jwcaAgvcfRmw3szaxkYR/REYU5gYRHa3dm2oHnriiaGs9E03hYlj992nRCCSl8KOJhpkZs0JTT0LgRti29sD/c1sO5AJ3Ojuq2OP9QFeBQ4mjCLSSCIpEhkZ8Nxz8MgjsGoVXH45PPxwGDYqIntXqGTg7lfnsf1t4O08HksGEgrzviI5ZWXBiBHwt7/BokXQpQs89hi0bBl1ZCJlh8pRSJnlDhMnhpP+1VfDYYfBRx+FmxKByL5RMpAyado0OOssOPtsWL8e/vMfSE4OVwUisu+UDKRM+fnnsOh8mzYwc2ZYcnL2bOjZEw7Q/2aR/aZCdVImLF8ehoa+8AIcdFBYdP6OO6B69agjEykflAykVFu3Dp54ItwyMkIp6fvugyOPjDoykfJFyUBKpa1bw4IyDz8M6emhaeiRR8L6wyJS9NTKKqVKVlboDG7cGP7v/yAhIdQPGjlSiUCkOCkZSKnx8ceQlARXXBH6AiZODBVFW7eOOjKR8k/JQCKXkgJdu4bbmjVhnYGUFPj971VITqSkKBlIZBYsCFcBrVqFk/+QITBnDlx5pYaJipQ0dSBLiVuxInQGP/98WGT+3nuhb1/43e+ijkyk4lIykBKzYUNYW/jxx2HzZrj++jBf4Oijo45MRJQMpNht2xYmiz30ULgquOgiGDAATjop6shEZAclAyk27vDWW6EZaN48aN8exoyBtm2jjkxEdqduOikWn30W6gdddhlUqRIWoZ88WYlApLRSMpAilZoaKol26gS//gqvvgozZsA552iYqEhppmQgRWLhwrCmQIsWMHUqDB4MP/0E11wDcXFRRyci+VGfgRTKypWhM3jo0DA34K67wq1GjagjE5F9oWQg+2XjRnjqKRg0KAwZve46ePBBOOaYqCMTkf2hZCD7ZPt2eOmlcOJfvhwuuAD+/vdQWE5Eyi4lAykQd3j3Xbj77tAX0K4dvP02nHZa1JGJSFFQB7Lka8oUOPXUMFnswAPDXIEvvlAiEClPlAwkTz/8AOeeC2eeCWlpoXkoNRXOP1/DREXKGyUD2cP//ge9ekGzZvDVVzBwYFiI/rrrwpWBiJQ/+mhLtnXrQjXRp58OP99xB/TrB4cdFm1cIlL8lAwEdxgxIpSRXr4c/vjHsPbwscdGHZmIlBQlgwru++/hlltCh3Dr1vDee6GmkIhULOozqKB++y0sON+iBfz4Yygx/c03SgQiFZWuDCqYrKxQPK5fP1i1Cm68MTQJqV9ApGJTMqhAkpNDk9DUqWGOwIcfhisDERE1E1UAK1fCDTeEJqCFC+G11+DLL5UIRGQnJYNyLDMzLDp/0klhwtjtt8PcuaHUtCaNiUhOaiYqp77+OjQJpaRAx47wzDMQHx91VCJSWunKoJz59Ve49trQJ/Drr/Dmm/DJJ0oEIrJ3hU4GZnarmc01s1lmNijH9rvNbF7ssd/n2N4ttm2emfUr7PtLsH07/OMf0KgRDB8eRgvNmRPWIFaTkIjkp1DNRGbWEegOJLp7hpnViW1vAvQE4oGjgUlm1ij2tH8CXYA0YJqZjXX3HwsTR0X3+eehSWjmTOjaNZSTOOmkqKMSkbKksFcGfYDH3D0DwN1XxLZ3B9509wx3/wWYB7SJ3ea5+wJ33wq8GdtX9sOSJXDFFdChA6xfH9YbmDhRiUBE9l1hk0Ej4Awzm2pmn5tZ69j2Y4DFOfZLi23La3uuzKy3mSWbWXJ6enohQy0/tm6Fxx+Hk0+Gd96B++8Ps4gvuEBNQiKyf/JtJjKzScCRuTx0b+z5NYG2QGtglJkdD+R2SnJyTz6e13u7+zBgGEBSUlKe+1UkH38Mt94ahoiefz4MGQLHHx91VCJS1uWbDNy9c16PmVkf4B13d+BbM8sCahO+8eeseVkXWBq7n9d22YtFi+Cvfw1LTZ5wAowbB+ecE3VUIlJeFLaZ6D2gE0Csg7gysBIYC/Q0s4PMrAHQEPgWmAY0NLMGZlaZ0Mk8tpAxlGtbtoQ1Bho3hvHjYcCA0FGsRCAiRamwk85eBl42s5nAVuCa2FXCLDMbBfwIbAdudvdMADO7BfgQiANedvdZhYyh3Bo3Dm67DebPh4svhieegHr1oo5KRMqjQiWD2Iigq/J4bAAwIJft44HxhXnf8m7+/FA64oMPQifxxx9D5zwb60RECk8zkEuRTZvCyKD4eJg8GQYPDgvQKxGISHFTbaJSwD3MEfjLX8Ji9FdeCYMGwdFHRx2ZiFQUSgYRmzs3rDj20UfQtGmYTdy+fdRRiUhFo2aiiKxfD3fdFRLA1KmhhERKihKBiERDVwYlzB1GjgxzBpYuheuug0cfhTp1oo5MRCoyXRmUoJkzw9oCl18ORx4Z1hx46SUlAhGJnpJBCVi7NgwVbd4cfvgB/vUv+PZbaNs26shERAI1ExWjrCx4/XW4805ITw/rED/yCNSqFXVkIiK7UjIoJikpYY2Br78OVwATJkDLllFHJSKSOzUTFbHVq+GmmyApKcwkfuUV+OorJQIRKd2UDIpIZiYMGxaWnRw2LMwdmDsXevWCA3SURaSUUzNREZg6NTQJJSeHeQLPPAOJiVFHJSJScPrOWgjp6fCnP4U+gaVLYcSIUFNIiUBEyholg/2wfTs8+2xoEnrtNejbF+bMCfMHtOykiJRFaibaR198EZqEvv8+VBN95plQZlpEpCzTlUEBLVsGV18d+gTWrIHRo0NxOSUCESkPdGWQj23bQhG5hx6CjAz429/1l636AAAO3ElEQVTg7rvhkEOijkwkQu7hw5Hfbfv2PbfFxUG1anveKldWO2uElAz24pNP4NZbYfbssObwP/4BJ54YdVRSJmVl5X+S3NeTalHtvz+vnZlZ9MfowAN3TQ7Vq+eeNHa/7W2/KlWUYApIySAXixeHqqJvvQXHHw/vvw/nnht1VFIquMPChWEc8Y7bsmX5n1SzskouxgMPhEqVCn478ECoWnXf9t+X19/9OZmZsHEjbNiw6239+j23bdgAaWm77rNxY/g7FMQBBxRtcqlWLTQLlMMEo2SQQ0YGPPlkqB+UlQX9+4eRQlWqRB2ZRMIdlizZedKfNi38u3p1eLxSJWjWDJo0KZ6T6P6cdOPiyuWJahdZWbB5c+6JY29JJedt+fI99ytowjYLybOokku1auH1Ip6dqmQQM2FCmDU8bx706BGSQv36UUclJerXX3f9xp+cHE4aEE6yCQnhP0dSErRuHX4+6KBoY66IDjggnDyrVoUjjiia13SHLVv2L7Hs2Cc9HX75Zdft+9KcVrVq7oniyCPh1VeL5vfciwqfDH75Jaw9PGZMmDcwcSL8/vdRRyXFbvVqmD5957f95OTQPgjhm1/jxtC1azjxJyWF+uMHHxxtzFJ8zMLf9+CD4fDDi+Y13WHr1v1LLDtua9aE1ygBFTYZbN4MAweGW1xc+Pf228OABiln1q0LZWRzNvUsWLDz8RNPhNNP33nib9EiXNqLFIZZuHI86KAyUbe+wiUDdxg7Npz4Fy6Enj3h8cehbt2oI5MisXEjzJixazv/3Lk7Hz/uuHDC7907/NuyJdSsGV28IqVEhUoGP/8c+gUmToT4ePjsM+jQIeqoZL9lZEBq6q5t/LNm7ewIPProcMK/8srQxt+qVdE1AYiUMxUiGWzcCAMGwBNPhJFBQ4bAzTeHwRdSRmzbFk70Odv4f/ghbAeoXTuc8C+4YGdzz9FHRxuzSBlSrpOBe5gr8Ne/hqHK11wDjz0WOuelFMvMDJX/crbxz5gRrgQAatQIJ/u//nXnib9evfI/pFKkGJXrZLB2LfTpE84Tb74J7dpFHZHsISsrjOfN2cb/3Xfhcg7C0LqWLUN1wB0n/hNO0IlfpIiV62RQowZMmRKKycXFRR2N5Dp7d/r0kLUhtOG1aAHXXbdzLH+jRvrjiZSAcp0MIHQUSwTcw4o/Odv4k5Nh1arw+I7Zu5dfvvMbf3x8mHUrIiVOnzwpGitW7NrGv/vs3fj4XTt3mzbV7F2RUkTJQPbdjtm7OU/+OWfvnnwydOkSmnmSksIVgGp+i5RqSgaydzln7+64zZ+/8/ETTww98zu+8bdsqdm7ImWQkoHslJUVTvxffbXzxD937s5ywfXqhW/7118fTvytWmn2rkg5UehkYGa3ArcA24Fx7n6nmdUHZgM76gB84+43xvZvBbwKHAyMB25zL2hxcilyGRlhKvaYMaFOx9KlYfuRR4YT/xVX7Dzx16kTbawiUmwKlQzMrCPQHUh09wwzy3m2mO/uzXN52nNAb+AbQjLoBkwoTByyj9asgXHjQgKYODFUR6xaNZRr7d4dzjoLjjkm6ihFpAQV9sqgD/CYu2cAuPuKve1sZkcBh7r717GfXwMuQMmg+C1cGE7+Y8aEyReZmeHb/xVXhATQqZNW8RGpwAqbDBoBZ5jZAGALcIe7T4s91sDMvgPWAX9z9y+AY4C0HM9Pi22TouYe2v93JIDvvw/bmzSBO+8MCaB168hXVxKR0iHfZGBmk4DcqvncG3t+TaAt0BoYZWbHA8uAeu6+KtZH8J6ZxQO51RDIs7/AzHoTmpSoV69efqHK1q2h/X/s2HBLSwsn+3btYPDgkABOPDHqKEWkFMo3Gbh757weM7M+wDuxDuBvzSwLqO3u6cCOpqPpZjafcBWRBuRcOaAusHQv7z0MGAaQlJSkTubc/PYbjB8fvv1PmBBWSjrkkLBK18MPw7nnhoqeIiJ7UdhmoveATsBkM2sEVAZWmtnhwGp3z4xdKTQEFrj7ajNbb2ZtganAH4FnChlDxbNoUfjmP2YMfP45bN8e1oK97LKdHcBaolFE9kFhk8HLwMtmNhPYClzj7m5m7YH+ZrYdyARudPfVsef0YefQ0gmo8zh/7qGE8472/xkzwvaTTw5lnLt3h1NOUfu/iOw3KytD/JOSkjw5OTnqMErO1q3hW/+O8f+LF4dSD6edFk7+3buHip4iInkws+nunlSQfTUDuTRZuza0++9o/1+7NjT3dO0KDz0U2v+1bKOIFAMlg6gtXryz/X/y5LCM4+GHw0UXhW//nTuryJuIFDslg5LmHhZx39H8k5IStjdqBLffHhJA27Za0EVESpSSQUnYti3M+t2RABYtCu3/p54aFmXu3j10BouIRETJoLisWxfq/owZE+YB/PZbKPfQpQvcd19o/z/iiKijFBEBlAyKVlraztm/n34arghq1w4rfHXvHhJB1apRRykisgclg8Jwhx9+2Dn+f/r0sL1hQ7jtNjj//DAUVO3/IlLKKRnsq+3b4YsvdiaAhQvD9rZt4dFHd7b/W25lmERESiclg4JYvx4+/DCc/MeNC+sBHHRQGPZ5zz1w3nmhHLSISBmlZJCXpUt3jv//9NMwI/iww8KJv3v3MBGsWrWooxQRKRJKBju4w6xZO5t/psWWZTjhBLjllpAATjsNDtQhE5Hyp2Kf2bZvD4u/70gACxaE7W3awIABIQE0aaL2fxEp9ypeMtiwIbT/jx0LH3wAq1dD5cqh7POdd4ZmoKOPjjpKEZESVTGSwbJl8P774dv/J59ARgbUrAl/+EP49v/730P16lFHKSISmfKdDDZtCgu9T50afm7QAPr0CQng9NPV/i8iElO+z4aHHBLW/D333JAAEhLU/i8ikovynQwA3ngj6ghEREo9rZMoIiJKBiIiomQgIiIoGYiICEoGIiKCkoGIiKBkICIiKBmIiAhg7h51DAViZunAov18em1gZRGGU1QU175RXPtGce2b8hjXce5+eEF2LDPJoDDMLNndk6KOY3eKa98orn2juPZNRY9LzUQiIqJkICIiFScZDIs6gDworn2juPaN4to3FTquCtFnICIie1dRrgxERGQvyk0yMLNjzewzM5ttZrPM7LZc9jEze9rM5pnZ92bWspTE1cHM1prZjNjt/hKIq4qZfWtmqbG4Hspln4PMbGTseE01s/qlJK5eZpae43hdX9xx5XjvODP7zsw+yOWxEj9eBYwrkuNlZgvN7IfYeybn8niJfx4LGFeJfx5j71vDzEab2ZzY+eLU3R4v3uPl7uXiBhwFtIzdrw78BDTZbZ9zgAmAAW2BqaUkrg7AByV8vAyoFrtfCZgKtN1tn5uA52P3ewIjS0lcvYBnI/p/9v+AEbn9vaI4XgWMK5LjBSwEau/l8RL/PBYwrhL/PMbe99/A9bH7lYEaJXm8ys2Vgbsvc/eU2P31wGzgmN126w685sE3QA0zO6oUxFXiYsdgQ+zHSrHb7h1I3Qn/QQFGA2eZFe+6oQWMKxJmVhf4A/BiHruU+PEqYFylVYl/HksrMzsUaA+8BODuW939t912K9bjVW6SQU6xy/MWhG+VOR0DLM7xcxoleGLeS1wAp8aaRiaYWXwJxRNnZjOAFcDH7p7n8XL37cBaoFYpiAvgotil8mgzO7a4Y4p5CrgTyMrj8UiOVwHigmiOlwMfmdl0M+udy+NRfR7ziwtK/vN4PJAOvBJr7nvRzKrutk+xHq9ylwzMrBrwNnC7u6/b/eFcnlIi3zrziSuFMG28GfAM8F5JxOTume7eHKgLtDGzhN12ieR4FSCu94H67p4ITGLnt/FiY2bnAivcffredstlW7EerwLGVeLHK6adu7cEzgZuNrP2uz0e1ecxv7ii+DweCLQEnnP3FsBGoN9u+xTr8SpXycDMKhFOuMPd/Z1cdkkDcn4rqgssjToud1+3o2nE3ccDlcysdnHHleP9fwMmA912eyj7eJnZgcDvgNVRx+Xuq9w9I/bjC0CrEginHXC+mS0E3gQ6mdkbu+0TxfHKN66IjhfuvjT27wrgXaDNbrtE8nnML66IPo9pQFqOq+DRhOSw+z7FdrzKTTKItc2+BMx29yfz2G0s8MdYr3xbYK27L4s6LjM7ckfbspm1IfxdVhVzXIebWY3Y/YOBzsCc3XYbC1wTu38x8KnHerKijGu3dtLzCf0wxcrd73b3uu5en9A5/Km7X7XbbiV+vAoSVxTHy8yqmln1HfeBrsDM3XaL4vOYb1xRfB7dfTmw2MxOim06C/hxt92K9XgdWFQvVAq0A64Gfoi1NwPcA9QDcPfngfGEHvl5wCbg2lIS18VAHzPbDmwGehb3SYQwyunfZhZH+M8+yt0/MLP+QLK7jyUksdfNbB7hG27PYo6poHH9n5mdD2yPxdWrBOLKVSk4XgWJK4rjdQTwbuyceiAwwt0nmtmNEOnnsSBxRfF5BLgVGG5mlYEFwLUlebw0A1lERMpPM5GIiOw/JQMREVEyEBERJQMREUHJQEREUDIQyZOZPWhmd+zH85qb2TmFfR2RkqRkIFL0mhPGg4uUGUoGIjmY2b1mNtfMJgEnxbadYGYTY4XNvjCzk2PbXzWz52PbfjKzc2MThvoDl1mohX9Z7KWbmNlkM1tgZv8XzW8nkrfyNANZpFDMrBVh1nALwmcjBZhOWIP2Rnf/2cxOAYYCnWJPqw+cCZwAfAacCNwPJLn7LbHXfRA4GehIWNNirpk95+7bSuY3E8mfkoHITmcA77r7JgAzGwtUAU4D3rKdSxMclOM5o9w9C/jZzBYQTvq5GRcrFpdhZisIZRHSiuF3ENkvSgYiu9q9PssBwG+xktoF2T+v+i4ZOe5nos+elDLqMxDZaQrQw8wOjlW2PI9QEOwXM7sEstehbZbjOZeY2QFmdgJhgZK5wHpCc5BImaFkIBITW550JDCDsP7EF7GHrgT+ZGapwCzC8oM7zAU+J6xNe6O7byH0HTTZrQNZpFRT1VKR/WRmrxIWTh8ddSwihaUrAxER0ZWBiIjoykBERFAyEBERlAxERAQlAxERQclARERQMhAREeD/A703YraHh2QwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modified from cell 13 at\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "depth = [2, 3, 4, 5, 6]\n",
    "train_score, val_score = validation_curve(\n",
    "    model, X_train, y_train,\n",
    "    param_name='max_depth', param_range=depth, \n",
    "    scoring='neg_mean_absolute_error', cv=3)\n",
    "\n",
    "plt.plot(depth, np.median(train_score, 1), color='blue', label='training score')\n",
    "plt.plot(depth, np.median(val_score, 1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('depth');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQoMvZ7-yCAQ"
   },
   "source": [
    "### `RandomizedSearchCV`\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bk_dX_mByKm7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  24 | elapsed:    3.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=8, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [100, 200], 'max_depth': [4, 5], 'criterion': ['mse', 'mae']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions ={\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4,5],\n",
    "    'criterion': ['mse', 'mae']\n",
    "}\n",
    "\n",
    "gridsearch = RandomizedSearchCV(\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=42),\n",
    "    param_distributions = param_distributions,\n",
    "    n_iter = 8,\n",
    "    cv=3,\n",
    "    n_jobs = -1,\n",
    "    verbose=10,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.255131</td>\n",
       "      <td>0.149603</td>\n",
       "      <td>0.857953</td>\n",
       "      <td>0.571009</td>\n",
       "      <td>0.184405</td>\n",
       "      <td>0.134422</td>\n",
       "      <td>0.461709</td>\n",
       "      <td>0.927162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0699281</td>\n",
       "      <td>0.0208485</td>\n",
       "      <td>0.0258206</td>\n",
       "      <td>0.105283</td>\n",
       "      <td>0.00843635</td>\n",
       "      <td>0.00437787</td>\n",
       "      <td>0.0109395</td>\n",
       "      <td>0.150282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.139739</td>\n",
       "      <td>0.103684</td>\n",
       "      <td>0.103336</td>\n",
       "      <td>0.131353</td>\n",
       "      <td>0.104539</td>\n",
       "      <td>0.106213</td>\n",
       "      <td>0.106122</td>\n",
       "      <td>0.126234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.0472047</td>\n",
       "      <td>0.000946506</td>\n",
       "      <td>0.000461299</td>\n",
       "      <td>0.0341514</td>\n",
       "      <td>0.00171375</td>\n",
       "      <td>0.00170592</td>\n",
       "      <td>0.00356265</td>\n",
       "      <td>0.0182058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_n_estimators</th>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_max_depth</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_criterion</th>\n",
       "      <td>mse</td>\n",
       "      <td>mse</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mse</td>\n",
       "      <td>mse</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.686349</td>\n",
       "      <td>0.686414</td>\n",
       "      <td>0.674895</td>\n",
       "      <td>0.671806</td>\n",
       "      <td>0.680051</td>\n",
       "      <td>0.678284</td>\n",
       "      <td>0.665306</td>\n",
       "      <td>0.664744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.603705</td>\n",
       "      <td>0.603045</td>\n",
       "      <td>0.604927</td>\n",
       "      <td>0.602432</td>\n",
       "      <td>0.60085</td>\n",
       "      <td>0.599862</td>\n",
       "      <td>0.599608</td>\n",
       "      <td>0.600918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.572116</td>\n",
       "      <td>0.571434</td>\n",
       "      <td>0.575245</td>\n",
       "      <td>0.578304</td>\n",
       "      <td>0.568387</td>\n",
       "      <td>0.565588</td>\n",
       "      <td>0.56973</td>\n",
       "      <td>0.567196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.620724</td>\n",
       "      <td>0.620297</td>\n",
       "      <td>0.618356</td>\n",
       "      <td>0.617514</td>\n",
       "      <td>0.616429</td>\n",
       "      <td>0.614578</td>\n",
       "      <td>0.611548</td>\n",
       "      <td>0.610953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0481628</td>\n",
       "      <td>0.0484997</td>\n",
       "      <td>0.0417758</td>\n",
       "      <td>0.0396338</td>\n",
       "      <td>0.0468988</td>\n",
       "      <td>0.0471703</td>\n",
       "      <td>0.0399216</td>\n",
       "      <td>0.0404508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.72046</td>\n",
       "      <td>0.719051</td>\n",
       "      <td>0.70738</td>\n",
       "      <td>0.70801</td>\n",
       "      <td>0.669612</td>\n",
       "      <td>0.668432</td>\n",
       "      <td>0.663279</td>\n",
       "      <td>0.663952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.743804</td>\n",
       "      <td>0.743615</td>\n",
       "      <td>0.743709</td>\n",
       "      <td>0.745337</td>\n",
       "      <td>0.703293</td>\n",
       "      <td>0.703249</td>\n",
       "      <td>0.701783</td>\n",
       "      <td>0.701851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.762005</td>\n",
       "      <td>0.760804</td>\n",
       "      <td>0.746244</td>\n",
       "      <td>0.74538</td>\n",
       "      <td>0.714408</td>\n",
       "      <td>0.712584</td>\n",
       "      <td>0.704817</td>\n",
       "      <td>0.703754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.742089</td>\n",
       "      <td>0.741157</td>\n",
       "      <td>0.732445</td>\n",
       "      <td>0.732909</td>\n",
       "      <td>0.695771</td>\n",
       "      <td>0.694755</td>\n",
       "      <td>0.68996</td>\n",
       "      <td>0.689853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.0170041</td>\n",
       "      <td>0.0171341</td>\n",
       "      <td>0.0177532</td>\n",
       "      <td>0.0176064</td>\n",
       "      <td>0.0190455</td>\n",
       "      <td>0.0189992</td>\n",
       "      <td>0.018907</td>\n",
       "      <td>0.0183309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    3  \\\n",
       "mean_fit_time                                                0.255131   \n",
       "std_fit_time                                                0.0699281   \n",
       "mean_score_time                                              0.139739   \n",
       "std_score_time                                              0.0472047   \n",
       "param_n_estimators                                                200   \n",
       "param_max_depth                                                     5   \n",
       "param_criterion                                                   mse   \n",
       "params              {'n_estimators': 200, 'max_depth': 5, 'criteri...   \n",
       "split0_test_score                                            0.686349   \n",
       "split1_test_score                                            0.603705   \n",
       "split2_test_score                                            0.572116   \n",
       "mean_test_score                                              0.620724   \n",
       "std_test_score                                              0.0481628   \n",
       "rank_test_score                                                     1   \n",
       "split0_train_score                                            0.72046   \n",
       "split1_train_score                                           0.743804   \n",
       "split2_train_score                                           0.762005   \n",
       "mean_train_score                                             0.742089   \n",
       "std_train_score                                             0.0170041   \n",
       "\n",
       "                                                                    2  \\\n",
       "mean_fit_time                                                0.149603   \n",
       "std_fit_time                                                0.0208485   \n",
       "mean_score_time                                              0.103684   \n",
       "std_score_time                                            0.000946506   \n",
       "param_n_estimators                                                100   \n",
       "param_max_depth                                                     5   \n",
       "param_criterion                                                   mse   \n",
       "params              {'n_estimators': 100, 'max_depth': 5, 'criteri...   \n",
       "split0_test_score                                            0.686414   \n",
       "split1_test_score                                            0.603045   \n",
       "split2_test_score                                            0.571434   \n",
       "mean_test_score                                              0.620297   \n",
       "std_test_score                                              0.0484997   \n",
       "rank_test_score                                                     2   \n",
       "split0_train_score                                           0.719051   \n",
       "split1_train_score                                           0.743615   \n",
       "split2_train_score                                           0.760804   \n",
       "mean_train_score                                             0.741157   \n",
       "std_train_score                                             0.0171341   \n",
       "\n",
       "                                                                    7  \\\n",
       "mean_fit_time                                                0.857953   \n",
       "std_fit_time                                                0.0258206   \n",
       "mean_score_time                                              0.103336   \n",
       "std_score_time                                            0.000461299   \n",
       "param_n_estimators                                                200   \n",
       "param_max_depth                                                     5   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 200, 'max_depth': 5, 'criteri...   \n",
       "split0_test_score                                            0.674895   \n",
       "split1_test_score                                            0.604927   \n",
       "split2_test_score                                            0.575245   \n",
       "mean_test_score                                              0.618356   \n",
       "std_test_score                                              0.0417758   \n",
       "rank_test_score                                                     3   \n",
       "split0_train_score                                            0.70738   \n",
       "split1_train_score                                           0.743709   \n",
       "split2_train_score                                           0.746244   \n",
       "mean_train_score                                             0.732445   \n",
       "std_train_score                                             0.0177532   \n",
       "\n",
       "                                                                    6  \\\n",
       "mean_fit_time                                                0.571009   \n",
       "std_fit_time                                                 0.105283   \n",
       "mean_score_time                                              0.131353   \n",
       "std_score_time                                              0.0341514   \n",
       "param_n_estimators                                                100   \n",
       "param_max_depth                                                     5   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 100, 'max_depth': 5, 'criteri...   \n",
       "split0_test_score                                            0.671806   \n",
       "split1_test_score                                            0.602432   \n",
       "split2_test_score                                            0.578304   \n",
       "mean_test_score                                              0.617514   \n",
       "std_test_score                                              0.0396338   \n",
       "rank_test_score                                                     4   \n",
       "split0_train_score                                            0.70801   \n",
       "split1_train_score                                           0.745337   \n",
       "split2_train_score                                            0.74538   \n",
       "mean_train_score                                             0.732909   \n",
       "std_train_score                                             0.0176064   \n",
       "\n",
       "                                                                    1  \\\n",
       "mean_fit_time                                                0.184405   \n",
       "std_fit_time                                               0.00843635   \n",
       "mean_score_time                                              0.104539   \n",
       "std_score_time                                             0.00171375   \n",
       "param_n_estimators                                                200   \n",
       "param_max_depth                                                     4   \n",
       "param_criterion                                                   mse   \n",
       "params              {'n_estimators': 200, 'max_depth': 4, 'criteri...   \n",
       "split0_test_score                                            0.680051   \n",
       "split1_test_score                                             0.60085   \n",
       "split2_test_score                                            0.568387   \n",
       "mean_test_score                                              0.616429   \n",
       "std_test_score                                              0.0468988   \n",
       "rank_test_score                                                     5   \n",
       "split0_train_score                                           0.669612   \n",
       "split1_train_score                                           0.703293   \n",
       "split2_train_score                                           0.714408   \n",
       "mean_train_score                                             0.695771   \n",
       "std_train_score                                             0.0190455   \n",
       "\n",
       "                                                                    0  \\\n",
       "mean_fit_time                                                0.134422   \n",
       "std_fit_time                                               0.00437787   \n",
       "mean_score_time                                              0.106213   \n",
       "std_score_time                                             0.00170592   \n",
       "param_n_estimators                                                100   \n",
       "param_max_depth                                                     4   \n",
       "param_criterion                                                   mse   \n",
       "params              {'n_estimators': 100, 'max_depth': 4, 'criteri...   \n",
       "split0_test_score                                            0.678284   \n",
       "split1_test_score                                            0.599862   \n",
       "split2_test_score                                            0.565588   \n",
       "mean_test_score                                              0.614578   \n",
       "std_test_score                                              0.0471703   \n",
       "rank_test_score                                                     6   \n",
       "split0_train_score                                           0.668432   \n",
       "split1_train_score                                           0.703249   \n",
       "split2_train_score                                           0.712584   \n",
       "mean_train_score                                             0.694755   \n",
       "std_train_score                                             0.0189992   \n",
       "\n",
       "                                                                    4  \\\n",
       "mean_fit_time                                                0.461709   \n",
       "std_fit_time                                                0.0109395   \n",
       "mean_score_time                                              0.106122   \n",
       "std_score_time                                             0.00356265   \n",
       "param_n_estimators                                                100   \n",
       "param_max_depth                                                     4   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 100, 'max_depth': 4, 'criteri...   \n",
       "split0_test_score                                            0.665306   \n",
       "split1_test_score                                            0.599608   \n",
       "split2_test_score                                             0.56973   \n",
       "mean_test_score                                              0.611548   \n",
       "std_test_score                                              0.0399216   \n",
       "rank_test_score                                                     7   \n",
       "split0_train_score                                           0.663279   \n",
       "split1_train_score                                           0.701783   \n",
       "split2_train_score                                           0.704817   \n",
       "mean_train_score                                              0.68996   \n",
       "std_train_score                                              0.018907   \n",
       "\n",
       "                                                                    5  \n",
       "mean_fit_time                                                0.927162  \n",
       "std_fit_time                                                 0.150282  \n",
       "mean_score_time                                              0.126234  \n",
       "std_score_time                                              0.0182058  \n",
       "param_n_estimators                                                200  \n",
       "param_max_depth                                                     4  \n",
       "param_criterion                                                   mae  \n",
       "params              {'n_estimators': 200, 'max_depth': 4, 'criteri...  \n",
       "split0_test_score                                            0.664744  \n",
       "split1_test_score                                            0.600918  \n",
       "split2_test_score                                            0.567196  \n",
       "mean_test_score                                              0.610953  \n",
       "std_test_score                                              0.0404508  \n",
       "rank_test_score                                                     8  \n",
       "split0_train_score                                           0.663952  \n",
       "split1_train_score                                           0.701851  \n",
       "split2_train_score                                           0.703754  \n",
       "mean_train_score                                             0.689853  \n",
       "std_train_score                                             0.0183309  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(gridsearch.cv_results_)\n",
    "results.sort_values(by='rank_test_score').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result from search of 8 parameter combinations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.255131</td>\n",
       "      <td>0.069928</td>\n",
       "      <td>0.139739</td>\n",
       "      <td>0.047205</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>mse</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>0.686349</td>\n",
       "      <td>0.603705</td>\n",
       "      <td>0.572116</td>\n",
       "      <td>0.620724</td>\n",
       "      <td>0.048163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72046</td>\n",
       "      <td>0.743804</td>\n",
       "      <td>0.762005</td>\n",
       "      <td>0.742089</td>\n",
       "      <td>0.017004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       0.255131      0.069928         0.139739        0.047205   \n",
       "\n",
       "  param_n_estimators param_max_depth param_criterion  \\\n",
       "3                200               5             mse   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "3  {'n_estimators': 200, 'max_depth': 5, 'criteri...           0.686349   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "3           0.603705           0.572116         0.620724        0.048163   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "3                1             0.72046            0.743804   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "3            0.762005          0.742089         0.017004  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Best result from search of {len(results)} parameter combinations')\n",
    "results.sort_values(by='rank_test_score').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZW5HfYtU0GW2"
   },
   "source": [
    "## FEATURE ENGINEERING!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ms-eoOHFvPG"
   },
   "source": [
    "Jake VanderPlas demonstrates this feature engineering: \n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>Total_yesterday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-04</th>\n",
       "      <td>3475.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>83</td>\n",
       "      <td>65</td>\n",
       "      <td>3521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-05</th>\n",
       "      <td>3148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>89</td>\n",
       "      <td>57</td>\n",
       "      <td>3475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-06</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>78</td>\n",
       "      <td>51</td>\n",
       "      <td>3148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-07</th>\n",
       "      <td>2142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>78</td>\n",
       "      <td>13</td>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-08</th>\n",
       "      <td>3537.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>2142.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
       "2012-10-04  3475.0     0     0     0   189    83    65           3521.0\n",
       "2012-10-05  3148.0     0     0     0   217    89    57           3475.0\n",
       "2012-10-06  2006.0     0     0     0   239    78    51           3148.0\n",
       "2012-10-07  2142.0     0     0     0   239    78    13           2006.0\n",
       "2012-10-08  3537.0     0     0     0   211    78    19           2142.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEwME8wR3A5g"
   },
   "outputs": [],
   "source": [
    "# Modified from code cells 17-21 at\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
    "\n",
    "def jake_wrangle(X):  \n",
    "    X = X.copy()\n",
    "\n",
    "    # patterns of use generally vary from day to day; \n",
    "    # let's add binary columns that indicate the day of the week:\n",
    "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    for i, day in enumerate(days):\n",
    "        X[day] = (X.index.dayofweek == i).astype(float)\n",
    "\n",
    "\n",
    "    # we might expect riders to behave differently on holidays; \n",
    "    # let's add an indicator of this as well:\n",
    "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "    cal = USFederalHolidayCalendar()\n",
    "    holidays = cal.holidays('2012', '2016')\n",
    "    X = X.join(pd.Series(1, index=holidays, name='holiday'))\n",
    "    X['holiday'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "    # We also might suspect that the hours of daylight would affect \n",
    "    # how many people ride; let's use the standard astronomical calculation \n",
    "    # to add this information:\n",
    "    def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
    "        \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
    "        days = (date - pd.datetime(2000, 12, 21)).days\n",
    "        m = (1. - np.tan(np.radians(latitude))\n",
    "             * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
    "        return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
    "\n",
    "    X['daylight_hrs'] = list(map(hours_of_daylight, X.index))\n",
    "\n",
    "    \n",
    "    # temperatures are in 1/10 deg C; convert to C\n",
    "    X['TMIN'] /= 10\n",
    "    X['TMAX'] /= 10\n",
    "    \n",
    "    # We can also calcuate the average temperature.\n",
    "    X['Temp (C)'] = 0.5 * (X['TMIN'] + X['TMAX'])\n",
    "\n",
    "    # precip is in 1/10 mm; convert to inches\n",
    "    X['PRCP'] /= 254\n",
    "\n",
    "    # In addition to the inches of precipitation, let's add a flag that \n",
    "    # indicates whether a day is dry (has zero precipitation):\n",
    "    X['dry day'] = (X['PRCP'] == 0).astype(int)\n",
    "\n",
    "\n",
    "    # Let's add a counter that increases from day 1, and measures how many \n",
    "    # years have passed. This will let us measure any observed annual increase \n",
    "    # or decrease in daily crossings:\n",
    "    X['annual'] = (X.index - X.index[0]).days / 365.\n",
    "\n",
    "    return X\n",
    "\n",
    "X_train = jake_wrangle(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDGkAv813Wtj"
   },
   "source": [
    "### Linear Regression (with new features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cj3HTM6p5F1A"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>estimator</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>-297.692524</td>\n",
       "      <td>-294.532315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>-300.419037</td>\n",
       "      <td>-283.779461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>-322.640378</td>\n",
       "      <td>-283.509114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time                                          estimator  \\\n",
       "0  0.002514    0.000610  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "1  0.001470    0.000568  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "2  0.001415    0.000582  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "\n",
       "   test_score  train_score  \n",
       "0 -297.692524  -294.532315  \n",
       "1 -300.419037  -283.779461  \n",
       "2 -322.640378  -283.509114  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(LinearRegression(), X_train, y_train,\n",
    "                       scoring='neg_mean_absolute_error', cv=3,\n",
    "                       return_train_score=True, return_estimator=True)\n",
    "\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306.91731307944264"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6zxN2xB3bX_"
   },
   "source": [
    "### Random Forest (with new features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3sWUDZIz1-kk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  24 | elapsed:   12.2s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   14.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>4</th>\n",
       "      <th>2</th>\n",
       "      <th>6</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>2.8984</td>\n",
       "      <td>3.23329</td>\n",
       "      <td>2.72409</td>\n",
       "      <td>1.58095</td>\n",
       "      <td>1.32818</td>\n",
       "      <td>1.61845</td>\n",
       "      <td>2.01916</td>\n",
       "      <td>1.1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0834404</td>\n",
       "      <td>0.230598</td>\n",
       "      <td>0.294636</td>\n",
       "      <td>0.206104</td>\n",
       "      <td>0.0988643</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>0.022291</td>\n",
       "      <td>0.0697146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.106823</td>\n",
       "      <td>0.133928</td>\n",
       "      <td>0.117637</td>\n",
       "      <td>0.131337</td>\n",
       "      <td>0.119216</td>\n",
       "      <td>0.134345</td>\n",
       "      <td>0.140745</td>\n",
       "      <td>0.137212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.0058392</td>\n",
       "      <td>0.00780424</td>\n",
       "      <td>0.0107485</td>\n",
       "      <td>0.0249508</td>\n",
       "      <td>0.0159591</td>\n",
       "      <td>0.00645246</td>\n",
       "      <td>0.0155132</td>\n",
       "      <td>0.0264394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_n_estimators</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_max_depth</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_criterion</th>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 10, 'criter...</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 15, 'criter...</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': None, 'crit...</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 15, 'criter...</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 10, 'criter...</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': None, 'crit...</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-339.636</td>\n",
       "      <td>-343.774</td>\n",
       "      <td>-346.19</td>\n",
       "      <td>-347.235</td>\n",
       "      <td>-349.442</td>\n",
       "      <td>-358.797</td>\n",
       "      <td>-356.325</td>\n",
       "      <td>-360.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-323.366</td>\n",
       "      <td>-319.609</td>\n",
       "      <td>-318.915</td>\n",
       "      <td>-319.651</td>\n",
       "      <td>-324.468</td>\n",
       "      <td>-320.269</td>\n",
       "      <td>-383.679</td>\n",
       "      <td>-387.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-300.122</td>\n",
       "      <td>-301.557</td>\n",
       "      <td>-302.467</td>\n",
       "      <td>-304.429</td>\n",
       "      <td>-297.641</td>\n",
       "      <td>-301.251</td>\n",
       "      <td>-333.667</td>\n",
       "      <td>-335.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-321.041</td>\n",
       "      <td>-321.647</td>\n",
       "      <td>-322.524</td>\n",
       "      <td>-323.772</td>\n",
       "      <td>-323.85</td>\n",
       "      <td>-326.772</td>\n",
       "      <td>-357.89</td>\n",
       "      <td>-361.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>16.2148</td>\n",
       "      <td>17.2951</td>\n",
       "      <td>18.0313</td>\n",
       "      <td>17.717</td>\n",
       "      <td>21.1524</td>\n",
       "      <td>23.9391</td>\n",
       "      <td>20.447</td>\n",
       "      <td>21.0313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-141.294</td>\n",
       "      <td>-110.517</td>\n",
       "      <td>-106.517</td>\n",
       "      <td>-112.552</td>\n",
       "      <td>-143.936</td>\n",
       "      <td>-108.846</td>\n",
       "      <td>-298.027</td>\n",
       "      <td>-299.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-127.463</td>\n",
       "      <td>-101.516</td>\n",
       "      <td>-99.6095</td>\n",
       "      <td>-102.188</td>\n",
       "      <td>-128.38</td>\n",
       "      <td>-99.8395</td>\n",
       "      <td>-265.317</td>\n",
       "      <td>-266.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-143.127</td>\n",
       "      <td>-113.195</td>\n",
       "      <td>-111.021</td>\n",
       "      <td>-116.336</td>\n",
       "      <td>-145.615</td>\n",
       "      <td>-113.804</td>\n",
       "      <td>-293.242</td>\n",
       "      <td>-294.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-137.295</td>\n",
       "      <td>-108.409</td>\n",
       "      <td>-105.716</td>\n",
       "      <td>-110.359</td>\n",
       "      <td>-139.31</td>\n",
       "      <td>-107.496</td>\n",
       "      <td>-285.529</td>\n",
       "      <td>-286.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>6.99208</td>\n",
       "      <td>4.99563</td>\n",
       "      <td>4.69295</td>\n",
       "      <td>5.98049</td>\n",
       "      <td>7.75927</td>\n",
       "      <td>5.78017</td>\n",
       "      <td>14.4249</td>\n",
       "      <td>14.6533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    3  \\\n",
       "mean_fit_time                                                  2.8984   \n",
       "std_fit_time                                                0.0834404   \n",
       "mean_score_time                                              0.106823   \n",
       "std_score_time                                              0.0058392   \n",
       "param_n_estimators                                                200   \n",
       "param_max_depth                                                    10   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 200, 'max_depth': 10, 'criter...   \n",
       "split0_test_score                                            -339.636   \n",
       "split1_test_score                                            -323.366   \n",
       "split2_test_score                                            -300.122   \n",
       "mean_test_score                                              -321.041   \n",
       "std_test_score                                                16.2148   \n",
       "rank_test_score                                                     1   \n",
       "split0_train_score                                           -141.294   \n",
       "split1_train_score                                           -127.463   \n",
       "split2_train_score                                           -143.127   \n",
       "mean_train_score                                             -137.295   \n",
       "std_train_score                                               6.99208   \n",
       "\n",
       "                                                                    5  \\\n",
       "mean_fit_time                                                 3.23329   \n",
       "std_fit_time                                                 0.230598   \n",
       "mean_score_time                                              0.133928   \n",
       "std_score_time                                             0.00780424   \n",
       "param_n_estimators                                                200   \n",
       "param_max_depth                                                    15   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 200, 'max_depth': 15, 'criter...   \n",
       "split0_test_score                                            -343.774   \n",
       "split1_test_score                                            -319.609   \n",
       "split2_test_score                                            -301.557   \n",
       "mean_test_score                                              -321.647   \n",
       "std_test_score                                                17.2951   \n",
       "rank_test_score                                                     2   \n",
       "split0_train_score                                           -110.517   \n",
       "split1_train_score                                           -101.516   \n",
       "split2_train_score                                           -113.195   \n",
       "mean_train_score                                             -108.409   \n",
       "std_train_score                                               4.99563   \n",
       "\n",
       "                                                                    7  \\\n",
       "mean_fit_time                                                 2.72409   \n",
       "std_fit_time                                                 0.294636   \n",
       "mean_score_time                                              0.117637   \n",
       "std_score_time                                              0.0107485   \n",
       "param_n_estimators                                                200   \n",
       "param_max_depth                                                  None   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 200, 'max_depth': None, 'crit...   \n",
       "split0_test_score                                             -346.19   \n",
       "split1_test_score                                            -318.915   \n",
       "split2_test_score                                            -302.467   \n",
       "mean_test_score                                              -322.524   \n",
       "std_test_score                                                18.0313   \n",
       "rank_test_score                                                     3   \n",
       "split0_train_score                                           -106.517   \n",
       "split1_train_score                                           -99.6095   \n",
       "split2_train_score                                           -111.021   \n",
       "mean_train_score                                             -105.716   \n",
       "std_train_score                                               4.69295   \n",
       "\n",
       "                                                                    4  \\\n",
       "mean_fit_time                                                 1.58095   \n",
       "std_fit_time                                                 0.206104   \n",
       "mean_score_time                                              0.131337   \n",
       "std_score_time                                              0.0249508   \n",
       "param_n_estimators                                                100   \n",
       "param_max_depth                                                    15   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 100, 'max_depth': 15, 'criter...   \n",
       "split0_test_score                                            -347.235   \n",
       "split1_test_score                                            -319.651   \n",
       "split2_test_score                                            -304.429   \n",
       "mean_test_score                                              -323.772   \n",
       "std_test_score                                                 17.717   \n",
       "rank_test_score                                                     4   \n",
       "split0_train_score                                           -112.552   \n",
       "split1_train_score                                           -102.188   \n",
       "split2_train_score                                           -116.336   \n",
       "mean_train_score                                             -110.359   \n",
       "std_train_score                                               5.98049   \n",
       "\n",
       "                                                                    2  \\\n",
       "mean_fit_time                                                 1.32818   \n",
       "std_fit_time                                                0.0988643   \n",
       "mean_score_time                                              0.119216   \n",
       "std_score_time                                              0.0159591   \n",
       "param_n_estimators                                                100   \n",
       "param_max_depth                                                    10   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 100, 'max_depth': 10, 'criter...   \n",
       "split0_test_score                                            -349.442   \n",
       "split1_test_score                                            -324.468   \n",
       "split2_test_score                                            -297.641   \n",
       "mean_test_score                                               -323.85   \n",
       "std_test_score                                                21.1524   \n",
       "rank_test_score                                                     5   \n",
       "split0_train_score                                           -143.936   \n",
       "split1_train_score                                            -128.38   \n",
       "split2_train_score                                           -145.615   \n",
       "mean_train_score                                              -139.31   \n",
       "std_train_score                                               7.75927   \n",
       "\n",
       "                                                                    6  \\\n",
       "mean_fit_time                                                 1.61845   \n",
       "std_fit_time                                                 0.126084   \n",
       "mean_score_time                                              0.134345   \n",
       "std_score_time                                             0.00645246   \n",
       "param_n_estimators                                                100   \n",
       "param_max_depth                                                  None   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 100, 'max_depth': None, 'crit...   \n",
       "split0_test_score                                            -358.797   \n",
       "split1_test_score                                            -320.269   \n",
       "split2_test_score                                            -301.251   \n",
       "mean_test_score                                              -326.772   \n",
       "std_test_score                                                23.9391   \n",
       "rank_test_score                                                     6   \n",
       "split0_train_score                                           -108.846   \n",
       "split1_train_score                                           -99.8395   \n",
       "split2_train_score                                           -113.804   \n",
       "mean_train_score                                             -107.496   \n",
       "std_train_score                                               5.78017   \n",
       "\n",
       "                                                                    1  \\\n",
       "mean_fit_time                                                 2.01916   \n",
       "std_fit_time                                                 0.022291   \n",
       "mean_score_time                                              0.140745   \n",
       "std_score_time                                              0.0155132   \n",
       "param_n_estimators                                                200   \n",
       "param_max_depth                                                     5   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 200, 'max_depth': 5, 'criteri...   \n",
       "split0_test_score                                            -356.325   \n",
       "split1_test_score                                            -383.679   \n",
       "split2_test_score                                            -333.667   \n",
       "mean_test_score                                               -357.89   \n",
       "std_test_score                                                 20.447   \n",
       "rank_test_score                                                     7   \n",
       "split0_train_score                                           -298.027   \n",
       "split1_train_score                                           -265.317   \n",
       "split2_train_score                                           -293.242   \n",
       "mean_train_score                                             -285.529   \n",
       "std_train_score                                               14.4249   \n",
       "\n",
       "                                                                    0  \n",
       "mean_fit_time                                                  1.1375  \n",
       "std_fit_time                                                0.0697146  \n",
       "mean_score_time                                              0.137212  \n",
       "std_score_time                                              0.0264394  \n",
       "param_n_estimators                                                100  \n",
       "param_max_depth                                                     5  \n",
       "param_criterion                                                   mae  \n",
       "params              {'n_estimators': 100, 'max_depth': 5, 'criteri...  \n",
       "split0_test_score                                            -360.615  \n",
       "split1_test_score                                            -387.242  \n",
       "split2_test_score                                            -335.736  \n",
       "mean_test_score                                              -361.198  \n",
       "std_test_score                                                21.0313  \n",
       "rank_test_score                                                     8  \n",
       "split0_train_score                                           -299.175  \n",
       "split1_train_score                                           -266.206  \n",
       "split2_train_score                                            -294.98  \n",
       "mean_train_score                                             -286.787  \n",
       "std_train_score                                               14.6533  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params= {\n",
    "    'n_estimators': [100,200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'criterion' : ['mae']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "gridsearch = RandomizedSearchCV(\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=42),\n",
    "    param_distributions = params,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_iter = 8,\n",
    "    cv=3,\n",
    "    n_jobs = -1,\n",
    "    verbose=10,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "results = pd.DataFrame(gridsearch.cv_results_)\n",
    "results.sort_values(by='rank_test_score').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edpJ87A8A8sd"
   },
   "source": [
    "\n",
    "### Feature engineering, explained by Francois Chollet\n",
    "\n",
    "> _Feature engineering_ is the process of using your own knowledge about the data and about the machine learning algorithm at hand to make the algorithm work better by applying hardcoded (nonlearned) transformations to the data before it goes into the model. In many cases, it isn’t reasonable to expect a machine-learning model to be able to learn from completely arbitrary data. The data needs to be presented to the model in a way that will make the model’s job easier.\n",
    "\n",
    "> Let’s look at an intuitive example. Suppose you’re trying to develop a model that can take as input an image of a clock and can output the time of day.\n",
    "\n",
    "> If you choose to use the raw pixels of the image as input data, then you have a difficult machine-learning problem on your hands. You’ll need a convolutional neural network to solve it, and you’ll have to expend quite a bit of computational resources to train the network.\n",
    "\n",
    "> But if you already understand the problem at a high level (you understand how humans read time on a clock face), then you can come up with much better input features for a machine-learning algorithm: for instance, write a Python script to follow the black pixels of the clock hands and output the (x, y) coordinates of the tip of each hand. Then a simple machine-learning algorithm can learn to associate these coordinates with the appropriate time of day.\n",
    "\n",
    "> You can go even further: do a coordinate change, and express the (x, y) coordinates as polar coordinates with regard to the center of the image. Your input will become the angle theta of each clock hand. At this point, your features are making the problem so easy that no machine learning is required; a simple rounding operation and dictionary lookup are enough to recover the approximate time of day.\n",
    "\n",
    "> That’s the essence of feature engineering: making a problem easier by expressing it in a simpler way. It usually requires understanding the problem in depth.\n",
    "\n",
    "> Before convolutional neural networks became successful on the MNIST digit-classification problem, solutions were typically based on hardcoded features such as the number of loops in a digit image, the height of each digit in an image, a histogram of pixel values, and so on.\n",
    "\n",
    "> Neural networks are capable of automatically extracting useful features from raw data. Does this mean you don’t have to worry about feature engineering as long as you’re using deep neural networks? No, for two reasons:\n",
    "\n",
    "> - Good features still allow you to solve problems more elegantly while using fewer resources. For instance, it would be ridiculous to solve the problem of reading a clock face using a convolutional neural network.\n",
    "> - Good features let you solve a problem with far less data. The ability of deep-learning models to learn features on their own relies on having lots of training data available; if you have only a few samples, then the information value in their features becomes critical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oux-dd-5FD6p"
   },
   "source": [
    "# ASSIGNMENT\n",
    "\n",
    "**1.** Complete the notebook cells that were originally commented **`TODO`**. \n",
    "\n",
    "**2.** Then, focus on feature engineering to improve your cross validation scores. Collaborate with your cohort on Slack. You could start with the ideas [Jake VanderPlas suggests:](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic)\n",
    "\n",
    "> Our model is almost certainly missing some relevant information. For example, nonlinear effects (such as effects of precipitation and cold temperature) and nonlinear trends within each variable (such as disinclination to ride at very cold and very hot temperatures) cannot be accounted for in this model. Additionally, we have thrown away some of the finer-grained information (such as the difference between a rainy morning and a rainy afternoon), and we have ignored correlations between days (such as the possible effect of a rainy Tuesday on Wednesday's numbers, or the effect of an unexpected sunny day after a streak of rainy days). These are all potentially interesting effects, and you now have the tools to begin exploring them if you wish!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train['SNOW'].hist();#describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>Total_yesterday</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>holiday</th>\n",
       "      <th>daylight_hrs</th>\n",
       "      <th>Temp (C)</th>\n",
       "      <th>dry day</th>\n",
       "      <th>annual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-04-13</th>\n",
       "      <td>0.370079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>57</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.263023</td>\n",
       "      <td>6.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-16</th>\n",
       "      <td>0.011811</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>26</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.432650</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-16</th>\n",
       "      <td>0.141732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>24</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.757561</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0</td>\n",
       "      <td>1.698630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>40</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.239536</td>\n",
       "      <td>9.15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday  Mon  Tue  \\\n",
       "2013-04-13  0.370079     0     0  10.6   3.3    57           2045.0  0.0  0.0   \n",
       "2013-04-16  0.011811     0     0  13.9   3.3    26           2687.0  0.0  1.0   \n",
       "2014-06-16  0.141732     0     0  17.8   8.9    24           1267.0  1.0  0.0   \n",
       "2014-12-16  0.000000     0     0  10.0   8.3    40           2283.0  0.0  1.0   \n",
       "\n",
       "            Wed  Thu  Fri  Sat  Sun  holiday  daylight_hrs  Temp (C)  dry day  \\\n",
       "2013-04-13  0.0  0.0  0.0  1.0  0.0      0.0     13.263023      6.95        0   \n",
       "2013-04-16  0.0  0.0  0.0  0.0  0.0      0.0     13.432650      8.60        0   \n",
       "2014-06-16  0.0  0.0  0.0  0.0  0.0      0.0     15.757561     13.35        0   \n",
       "2014-12-16  0.0  0.0  0.0  0.0  0.0      0.0      8.239536      9.15        1   \n",
       "\n",
       "              annual  \n",
       "2013-04-13  0.523288  \n",
       "2013-04-16  0.531507  \n",
       "2014-06-16  1.698630  \n",
       "2014-12-16  2.200000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[X_train['SNOW'] == -9999].replace({-9999:0})\n",
    "# X_train.loc[X_train['SNWD'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>Total_yesterday</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>holiday</th>\n",
       "      <th>daylight_hrs</th>\n",
       "      <th>Temp (C)</th>\n",
       "      <th>dry day</th>\n",
       "      <th>annual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-18</th>\n",
       "      <td>0.051181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>28</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.226113</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.205479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.222355</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.208219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-20</th>\n",
       "      <td>0.220472</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>37</td>\n",
       "      <td>2075.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.219963</td>\n",
       "      <td>4.45</td>\n",
       "      <td>0</td>\n",
       "      <td>1.210959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-21</th>\n",
       "      <td>0.220472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>23</td>\n",
       "      <td>739.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.218937</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1.213699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-22</th>\n",
       "      <td>0.421260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>40</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.219279</td>\n",
       "      <td>9.45</td>\n",
       "      <td>0</td>\n",
       "      <td>1.216438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-23</th>\n",
       "      <td>0.059055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>59</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.220988</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1.219178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>17</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.224064</td>\n",
       "      <td>5.55</td>\n",
       "      <td>1</td>\n",
       "      <td>1.221918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>8</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.228502</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1.224658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday  Mon  Tue  \\\n",
       "2013-12-18  0.051181     0     0   7.8   2.2    28           2232.0  0.0  0.0   \n",
       "2013-12-19  0.000000     0     0   5.0   0.0    21           2171.0  0.0  0.0   \n",
       "2013-12-20  0.220472    28     0   8.3   0.6    37           2075.0  0.0  0.0   \n",
       "2013-12-21  0.220472     0     0   8.9   5.6    23            739.0  0.0  0.0   \n",
       "2013-12-22  0.421260     0     0  10.6   8.3    40            520.0  0.0  0.0   \n",
       "2013-12-23  0.059055     0     0  11.7   6.1    59            400.0  1.0  0.0   \n",
       "2013-12-24  0.000000     0     0   8.3   2.8    17           1417.0  0.0  1.0   \n",
       "2013-12-25  0.000000     0     0   6.7   1.7     8           1082.0  0.0  0.0   \n",
       "\n",
       "            Wed  Thu  Fri  Sat  Sun  holiday  daylight_hrs  Temp (C)  dry day  \\\n",
       "2013-12-18  1.0  0.0  0.0  0.0  0.0      0.0      8.226113      5.00        0   \n",
       "2013-12-19  0.0  1.0  0.0  0.0  0.0      0.0      8.222355      2.50        1   \n",
       "2013-12-20  0.0  0.0  1.0  0.0  0.0      0.0      8.219963      4.45        0   \n",
       "2013-12-21  0.0  0.0  0.0  1.0  0.0      0.0      8.218937      7.25        0   \n",
       "2013-12-22  0.0  0.0  0.0  0.0  1.0      0.0      8.219279      9.45        0   \n",
       "2013-12-23  0.0  0.0  0.0  0.0  0.0      0.0      8.220988      8.90        0   \n",
       "2013-12-24  0.0  0.0  0.0  0.0  0.0      0.0      8.224064      5.55        1   \n",
       "2013-12-25  1.0  0.0  0.0  0.0  0.0      1.0      8.228502      4.20        1   \n",
       "\n",
       "              annual  \n",
       "2013-12-18  1.205479  \n",
       "2013-12-19  1.208219  \n",
       "2013-12-20  1.210959  \n",
       "2013-12-21  1.213699  \n",
       "2013-12-22  1.216438  \n",
       "2013-12-23  1.219178  \n",
       "2013-12-24  1.221918  \n",
       "2013-12-25  1.224658  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc['2013-12-18':'2013-12-25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# I want to add wet day \n",
    "X_train['PRCP'].hist();\n",
    "X_train['PRCP'].describe()\n",
    "# looks like 75% of the values are under 0.12 so I'll set that as my threshold\n",
    "\n",
    "def ned_wrangle(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    #wet day cat\n",
    "    X['wet_day'] = (X['PRCP'] >0.129921).astype(int)\n",
    "    \n",
    "    #remove SNOW -9999s, after analyzing the set they look like errors\n",
    "    X.loc[X['SNOW'] == -9999].replace({-9999:0})\n",
    "    \n",
    "    #snow and snwd is in 1/10 mm; convert to inches\n",
    "    X['SNOW'] /= 254\n",
    "    X['SNWD'] /= 254\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nedderlander/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>15</th>\n",
       "      <th>11</th>\n",
       "      <th>14</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>9</th>\n",
       "      <th>4</th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>4.59149</td>\n",
       "      <td>4.47198</td>\n",
       "      <td>3.43167</td>\n",
       "      <td>3.33439</td>\n",
       "      <td>1.14177</td>\n",
       "      <td>1.15142</td>\n",
       "      <td>2.37445</td>\n",
       "      <td>2.16108</td>\n",
       "      <td>0.97817</td>\n",
       "      <td>4.00686</td>\n",
       "      <td>2.96848</td>\n",
       "      <td>2.05906</td>\n",
       "      <td>0.725026</td>\n",
       "      <td>2.19304</td>\n",
       "      <td>2.82138</td>\n",
       "      <td>1.46448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.161362</td>\n",
       "      <td>0.157715</td>\n",
       "      <td>0.0597075</td>\n",
       "      <td>0.109832</td>\n",
       "      <td>0.0386345</td>\n",
       "      <td>0.0762749</td>\n",
       "      <td>0.148787</td>\n",
       "      <td>0.0258445</td>\n",
       "      <td>0.0193383</td>\n",
       "      <td>0.114269</td>\n",
       "      <td>0.0436853</td>\n",
       "      <td>0.0545368</td>\n",
       "      <td>0.0226073</td>\n",
       "      <td>0.0987017</td>\n",
       "      <td>0.0334354</td>\n",
       "      <td>0.0546199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.00929842</td>\n",
       "      <td>0.00953619</td>\n",
       "      <td>0.00751009</td>\n",
       "      <td>0.00718939</td>\n",
       "      <td>0.00303199</td>\n",
       "      <td>0.00308113</td>\n",
       "      <td>0.00522752</td>\n",
       "      <td>0.00503674</td>\n",
       "      <td>0.00328872</td>\n",
       "      <td>0.00844691</td>\n",
       "      <td>0.00682487</td>\n",
       "      <td>0.00470898</td>\n",
       "      <td>0.00244737</td>\n",
       "      <td>0.00562375</td>\n",
       "      <td>0.00712576</td>\n",
       "      <td>0.00425725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.000123972</td>\n",
       "      <td>0.000592665</td>\n",
       "      <td>0.000669225</td>\n",
       "      <td>0.000354761</td>\n",
       "      <td>0.000149721</td>\n",
       "      <td>0.000199324</td>\n",
       "      <td>0.000267447</td>\n",
       "      <td>0.000162938</td>\n",
       "      <td>0.00125356</td>\n",
       "      <td>0.000179515</td>\n",
       "      <td>0.000878408</td>\n",
       "      <td>0.000156513</td>\n",
       "      <td>2.17659e-05</td>\n",
       "      <td>0.00010883</td>\n",
       "      <td>0.000134238</td>\n",
       "      <td>0.000393284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_n_estimators</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_max_depth</th>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_criterion</th>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'n_estimators': 200, 'max_depth': None, 'crit...</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 15, 'criter...</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': None, 'crit...</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 15, 'criter...</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': None, 'crite...</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 15, 'criteri...</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': None, 'crit...</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 15, 'criter...</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 10, 'criteri...</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 10, 'criter...</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 10, 'criter...</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 10, 'criter...</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 5, 'criterio...</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-321.781</td>\n",
       "      <td>-324.607</td>\n",
       "      <td>-321.931</td>\n",
       "      <td>-325.77</td>\n",
       "      <td>-321.548</td>\n",
       "      <td>-326.317</td>\n",
       "      <td>-319.673</td>\n",
       "      <td>-323.788</td>\n",
       "      <td>-332.144</td>\n",
       "      <td>-329.481</td>\n",
       "      <td>-329.609</td>\n",
       "      <td>-329.442</td>\n",
       "      <td>-362.628</td>\n",
       "      <td>-361.92</td>\n",
       "      <td>-363.107</td>\n",
       "      <td>-362.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-318.122</td>\n",
       "      <td>-319.375</td>\n",
       "      <td>-319.303</td>\n",
       "      <td>-322.253</td>\n",
       "      <td>-316.419</td>\n",
       "      <td>-321.503</td>\n",
       "      <td>-321.636</td>\n",
       "      <td>-322.56</td>\n",
       "      <td>-323.08</td>\n",
       "      <td>-322.867</td>\n",
       "      <td>-324.257</td>\n",
       "      <td>-323.187</td>\n",
       "      <td>-385.128</td>\n",
       "      <td>-380.425</td>\n",
       "      <td>-379.116</td>\n",
       "      <td>-382.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-283.927</td>\n",
       "      <td>-276.133</td>\n",
       "      <td>-282.616</td>\n",
       "      <td>-275.469</td>\n",
       "      <td>-275.692</td>\n",
       "      <td>-271.065</td>\n",
       "      <td>-284.694</td>\n",
       "      <td>-277.566</td>\n",
       "      <td>-276.546</td>\n",
       "      <td>-276.539</td>\n",
       "      <td>-276.846</td>\n",
       "      <td>-278.988</td>\n",
       "      <td>-299.894</td>\n",
       "      <td>-303.758</td>\n",
       "      <td>-303.612</td>\n",
       "      <td>-305.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-271.96</td>\n",
       "      <td>-269.74</td>\n",
       "      <td>-273.002</td>\n",
       "      <td>-270.402</td>\n",
       "      <td>-270.571</td>\n",
       "      <td>-271.643</td>\n",
       "      <td>-271.711</td>\n",
       "      <td>-267.628</td>\n",
       "      <td>-270.416</td>\n",
       "      <td>-276.374</td>\n",
       "      <td>-275.154</td>\n",
       "      <td>-273.791</td>\n",
       "      <td>-321.979</td>\n",
       "      <td>-324.351</td>\n",
       "      <td>-325.605</td>\n",
       "      <td>-324.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-281.587</td>\n",
       "      <td>-285.605</td>\n",
       "      <td>-282.26</td>\n",
       "      <td>-286.879</td>\n",
       "      <td>-290.469</td>\n",
       "      <td>-288.041</td>\n",
       "      <td>-286.617</td>\n",
       "      <td>-287.1</td>\n",
       "      <td>-292.809</td>\n",
       "      <td>-290.632</td>\n",
       "      <td>-292.686</td>\n",
       "      <td>-292.651</td>\n",
       "      <td>-356.815</td>\n",
       "      <td>-355.871</td>\n",
       "      <td>-355.361</td>\n",
       "      <td>-356.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>-265.897</td>\n",
       "      <td>-266.228</td>\n",
       "      <td>-264.279</td>\n",
       "      <td>-265.065</td>\n",
       "      <td>-273.234</td>\n",
       "      <td>-274.498</td>\n",
       "      <td>-269.178</td>\n",
       "      <td>-272.393</td>\n",
       "      <td>-274.597</td>\n",
       "      <td>-273.674</td>\n",
       "      <td>-272.85</td>\n",
       "      <td>-276.949</td>\n",
       "      <td>-361.232</td>\n",
       "      <td>-362.812</td>\n",
       "      <td>-364.37</td>\n",
       "      <td>-363.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>-290.175</td>\n",
       "      <td>-288.786</td>\n",
       "      <td>-293.141</td>\n",
       "      <td>-292.743</td>\n",
       "      <td>-289.803</td>\n",
       "      <td>-290.381</td>\n",
       "      <td>-293.46</td>\n",
       "      <td>-294.743</td>\n",
       "      <td>-293.478</td>\n",
       "      <td>-291.723</td>\n",
       "      <td>-296.167</td>\n",
       "      <td>-297.944</td>\n",
       "      <td>-350.982</td>\n",
       "      <td>-349.961</td>\n",
       "      <td>-349.147</td>\n",
       "      <td>-352.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>-296.854</td>\n",
       "      <td>-298.97</td>\n",
       "      <td>-296.641</td>\n",
       "      <td>-299.216</td>\n",
       "      <td>-300.981</td>\n",
       "      <td>-302.852</td>\n",
       "      <td>-298.069</td>\n",
       "      <td>-300.614</td>\n",
       "      <td>-301.994</td>\n",
       "      <td>-301.436</td>\n",
       "      <td>-302.006</td>\n",
       "      <td>-303.742</td>\n",
       "      <td>-358.8</td>\n",
       "      <td>-363.187</td>\n",
       "      <td>-361.447</td>\n",
       "      <td>-360.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>-275.202</td>\n",
       "      <td>-277.25</td>\n",
       "      <td>-274.191</td>\n",
       "      <td>-275.355</td>\n",
       "      <td>-271.45</td>\n",
       "      <td>-277.063</td>\n",
       "      <td>-274.163</td>\n",
       "      <td>-278.029</td>\n",
       "      <td>-275.984</td>\n",
       "      <td>-280.308</td>\n",
       "      <td>-279.426</td>\n",
       "      <td>-279.572</td>\n",
       "      <td>-323.485</td>\n",
       "      <td>-319.849</td>\n",
       "      <td>-319.391</td>\n",
       "      <td>-318.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>-244.32</td>\n",
       "      <td>-243.548</td>\n",
       "      <td>-245.256</td>\n",
       "      <td>-243.733</td>\n",
       "      <td>-247.539</td>\n",
       "      <td>-246.63</td>\n",
       "      <td>-251.074</td>\n",
       "      <td>-249.945</td>\n",
       "      <td>-246.752</td>\n",
       "      <td>-253.57</td>\n",
       "      <td>-251.544</td>\n",
       "      <td>-253.26</td>\n",
       "      <td>-305.396</td>\n",
       "      <td>-309.648</td>\n",
       "      <td>-312.96</td>\n",
       "      <td>-309.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-284.982</td>\n",
       "      <td>-285.024</td>\n",
       "      <td>-285.262</td>\n",
       "      <td>-285.688</td>\n",
       "      <td>-285.771</td>\n",
       "      <td>-286.999</td>\n",
       "      <td>-287.027</td>\n",
       "      <td>-287.437</td>\n",
       "      <td>-288.78</td>\n",
       "      <td>-289.66</td>\n",
       "      <td>-290.055</td>\n",
       "      <td>-290.953</td>\n",
       "      <td>-342.634</td>\n",
       "      <td>-343.178</td>\n",
       "      <td>-343.412</td>\n",
       "      <td>-343.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>22.1718</td>\n",
       "      <td>23.2431</td>\n",
       "      <td>22.4158</td>\n",
       "      <td>24.1002</td>\n",
       "      <td>21.5537</td>\n",
       "      <td>23.1833</td>\n",
       "      <td>21.0802</td>\n",
       "      <td>22.3438</td>\n",
       "      <td>24.2653</td>\n",
       "      <td>21.9691</td>\n",
       "      <td>22.8255</td>\n",
       "      <td>22.1806</td>\n",
       "      <td>26.6275</td>\n",
       "      <td>25.1167</td>\n",
       "      <td>24.5119</td>\n",
       "      <td>25.3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-104.799</td>\n",
       "      <td>-108.088</td>\n",
       "      <td>-105.405</td>\n",
       "      <td>-109.053</td>\n",
       "      <td>-107.686</td>\n",
       "      <td>-111.43</td>\n",
       "      <td>-106.61</td>\n",
       "      <td>-110.712</td>\n",
       "      <td>-141.054</td>\n",
       "      <td>-139.211</td>\n",
       "      <td>-139.579</td>\n",
       "      <td>-141.542</td>\n",
       "      <td>-289.706</td>\n",
       "      <td>-290.295</td>\n",
       "      <td>-289.882</td>\n",
       "      <td>-292.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-103.507</td>\n",
       "      <td>-107.947</td>\n",
       "      <td>-104.135</td>\n",
       "      <td>-108.348</td>\n",
       "      <td>-106.064</td>\n",
       "      <td>-110.946</td>\n",
       "      <td>-104.703</td>\n",
       "      <td>-109.305</td>\n",
       "      <td>-142.434</td>\n",
       "      <td>-139.499</td>\n",
       "      <td>-140.278</td>\n",
       "      <td>-141.025</td>\n",
       "      <td>-285.541</td>\n",
       "      <td>-285.899</td>\n",
       "      <td>-285.334</td>\n",
       "      <td>-287.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-108.028</td>\n",
       "      <td>-111.986</td>\n",
       "      <td>-108.549</td>\n",
       "      <td>-112.961</td>\n",
       "      <td>-109.945</td>\n",
       "      <td>-114.41</td>\n",
       "      <td>-110.59</td>\n",
       "      <td>-115.95</td>\n",
       "      <td>-144.301</td>\n",
       "      <td>-145.32</td>\n",
       "      <td>-145.923</td>\n",
       "      <td>-147.352</td>\n",
       "      <td>-298.96</td>\n",
       "      <td>-303.093</td>\n",
       "      <td>-302.338</td>\n",
       "      <td>-302.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-103.199</td>\n",
       "      <td>-106.522</td>\n",
       "      <td>-103.958</td>\n",
       "      <td>-106.772</td>\n",
       "      <td>-107.556</td>\n",
       "      <td>-110.806</td>\n",
       "      <td>-105.401</td>\n",
       "      <td>-108.363</td>\n",
       "      <td>-141.91</td>\n",
       "      <td>-139.179</td>\n",
       "      <td>-139.502</td>\n",
       "      <td>-139.849</td>\n",
       "      <td>-292.099</td>\n",
       "      <td>-294.005</td>\n",
       "      <td>-293.389</td>\n",
       "      <td>-292.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-106.236</td>\n",
       "      <td>-109.813</td>\n",
       "      <td>-105.932</td>\n",
       "      <td>-109.68</td>\n",
       "      <td>-110.334</td>\n",
       "      <td>-113.384</td>\n",
       "      <td>-107.87</td>\n",
       "      <td>-110.912</td>\n",
       "      <td>-145.049</td>\n",
       "      <td>-143.684</td>\n",
       "      <td>-143.76</td>\n",
       "      <td>-144.259</td>\n",
       "      <td>-287.783</td>\n",
       "      <td>-284.267</td>\n",
       "      <td>-284.65</td>\n",
       "      <td>-285.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>-108.486</td>\n",
       "      <td>-112.647</td>\n",
       "      <td>-108.963</td>\n",
       "      <td>-113.76</td>\n",
       "      <td>-112.644</td>\n",
       "      <td>-116.182</td>\n",
       "      <td>-110.849</td>\n",
       "      <td>-115.779</td>\n",
       "      <td>-148.758</td>\n",
       "      <td>-144.958</td>\n",
       "      <td>-146.687</td>\n",
       "      <td>-148.222</td>\n",
       "      <td>-295.455</td>\n",
       "      <td>-293.942</td>\n",
       "      <td>-294.021</td>\n",
       "      <td>-293.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>-106.547</td>\n",
       "      <td>-110.43</td>\n",
       "      <td>-105.642</td>\n",
       "      <td>-109.882</td>\n",
       "      <td>-108.483</td>\n",
       "      <td>-112.256</td>\n",
       "      <td>-105.821</td>\n",
       "      <td>-110.482</td>\n",
       "      <td>-141.668</td>\n",
       "      <td>-142.203</td>\n",
       "      <td>-141.379</td>\n",
       "      <td>-140.418</td>\n",
       "      <td>-291.302</td>\n",
       "      <td>-290.628</td>\n",
       "      <td>-292.508</td>\n",
       "      <td>-291.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>-107.39</td>\n",
       "      <td>-112.387</td>\n",
       "      <td>-107.127</td>\n",
       "      <td>-111.957</td>\n",
       "      <td>-111.067</td>\n",
       "      <td>-115.001</td>\n",
       "      <td>-108.052</td>\n",
       "      <td>-113.233</td>\n",
       "      <td>-150.084</td>\n",
       "      <td>-147.795</td>\n",
       "      <td>-147.718</td>\n",
       "      <td>-147.88</td>\n",
       "      <td>-298.608</td>\n",
       "      <td>-298.268</td>\n",
       "      <td>-299.212</td>\n",
       "      <td>-296.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>-105.092</td>\n",
       "      <td>-109.539</td>\n",
       "      <td>-105.666</td>\n",
       "      <td>-110.256</td>\n",
       "      <td>-108.407</td>\n",
       "      <td>-114.043</td>\n",
       "      <td>-106.732</td>\n",
       "      <td>-112.312</td>\n",
       "      <td>-146.279</td>\n",
       "      <td>-144.017</td>\n",
       "      <td>-144.031</td>\n",
       "      <td>-145.055</td>\n",
       "      <td>-290.623</td>\n",
       "      <td>-292.526</td>\n",
       "      <td>-293.143</td>\n",
       "      <td>-290.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>-106.074</td>\n",
       "      <td>-110.548</td>\n",
       "      <td>-105.874</td>\n",
       "      <td>-110.191</td>\n",
       "      <td>-107.831</td>\n",
       "      <td>-111.745</td>\n",
       "      <td>-106.112</td>\n",
       "      <td>-111.338</td>\n",
       "      <td>-145.951</td>\n",
       "      <td>-144.427</td>\n",
       "      <td>-143.334</td>\n",
       "      <td>-143.625</td>\n",
       "      <td>-296.954</td>\n",
       "      <td>-295.119</td>\n",
       "      <td>-297.598</td>\n",
       "      <td>-292.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-105.936</td>\n",
       "      <td>-109.991</td>\n",
       "      <td>-106.125</td>\n",
       "      <td>-110.286</td>\n",
       "      <td>-109.002</td>\n",
       "      <td>-113.02</td>\n",
       "      <td>-107.274</td>\n",
       "      <td>-111.839</td>\n",
       "      <td>-144.749</td>\n",
       "      <td>-143.029</td>\n",
       "      <td>-143.219</td>\n",
       "      <td>-143.923</td>\n",
       "      <td>-292.703</td>\n",
       "      <td>-292.804</td>\n",
       "      <td>-293.208</td>\n",
       "      <td>-292.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>1.69913</td>\n",
       "      <td>1.93244</td>\n",
       "      <td>1.57004</td>\n",
       "      <td>2.00455</td>\n",
       "      <td>1.86125</td>\n",
       "      <td>1.75988</td>\n",
       "      <td>1.97612</td>\n",
       "      <td>2.39399</td>\n",
       "      <td>2.91844</td>\n",
       "      <td>2.78539</td>\n",
       "      <td>2.82223</td>\n",
       "      <td>3.00547</td>\n",
       "      <td>4.36815</td>\n",
       "      <td>5.24875</td>\n",
       "      <td>5.34935</td>\n",
       "      <td>4.43678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   15  \\\n",
       "mean_fit_time                                                 4.59149   \n",
       "std_fit_time                                                 0.161362   \n",
       "mean_score_time                                            0.00929842   \n",
       "std_score_time                                            0.000123972   \n",
       "param_n_estimators                                                200   \n",
       "param_max_depth                                                  None   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 200, 'max_depth': None, 'crit...   \n",
       "split0_test_score                                            -321.781   \n",
       "split1_test_score                                            -318.122   \n",
       "split2_test_score                                            -283.927   \n",
       "split3_test_score                                             -271.96   \n",
       "split4_test_score                                            -281.587   \n",
       "split5_test_score                                            -265.897   \n",
       "split6_test_score                                            -290.175   \n",
       "split7_test_score                                            -296.854   \n",
       "split8_test_score                                            -275.202   \n",
       "split9_test_score                                             -244.32   \n",
       "mean_test_score                                              -284.982   \n",
       "std_test_score                                                22.1718   \n",
       "rank_test_score                                                     1   \n",
       "split0_train_score                                           -104.799   \n",
       "split1_train_score                                           -103.507   \n",
       "split2_train_score                                           -108.028   \n",
       "split3_train_score                                           -103.199   \n",
       "split4_train_score                                           -106.236   \n",
       "split5_train_score                                           -108.486   \n",
       "split6_train_score                                           -106.547   \n",
       "split7_train_score                                            -107.39   \n",
       "split8_train_score                                           -105.092   \n",
       "split9_train_score                                           -106.074   \n",
       "mean_train_score                                             -105.936   \n",
       "std_train_score                                               1.69913   \n",
       "\n",
       "                                                                   11  \\\n",
       "mean_fit_time                                                 4.47198   \n",
       "std_fit_time                                                 0.157715   \n",
       "mean_score_time                                            0.00953619   \n",
       "std_score_time                                            0.000592665   \n",
       "param_n_estimators                                                200   \n",
       "param_max_depth                                                    15   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 200, 'max_depth': 15, 'criter...   \n",
       "split0_test_score                                            -324.607   \n",
       "split1_test_score                                            -319.375   \n",
       "split2_test_score                                            -276.133   \n",
       "split3_test_score                                             -269.74   \n",
       "split4_test_score                                            -285.605   \n",
       "split5_test_score                                            -266.228   \n",
       "split6_test_score                                            -288.786   \n",
       "split7_test_score                                             -298.97   \n",
       "split8_test_score                                             -277.25   \n",
       "split9_test_score                                            -243.548   \n",
       "mean_test_score                                              -285.024   \n",
       "std_test_score                                                23.2431   \n",
       "rank_test_score                                                     2   \n",
       "split0_train_score                                           -108.088   \n",
       "split1_train_score                                           -107.947   \n",
       "split2_train_score                                           -111.986   \n",
       "split3_train_score                                           -106.522   \n",
       "split4_train_score                                           -109.813   \n",
       "split5_train_score                                           -112.647   \n",
       "split6_train_score                                            -110.43   \n",
       "split7_train_score                                           -112.387   \n",
       "split8_train_score                                           -109.539   \n",
       "split9_train_score                                           -110.548   \n",
       "mean_train_score                                             -109.991   \n",
       "std_train_score                                               1.93244   \n",
       "\n",
       "                                                                   14  \\\n",
       "mean_fit_time                                                 3.43167   \n",
       "std_fit_time                                                0.0597075   \n",
       "mean_score_time                                            0.00751009   \n",
       "std_score_time                                            0.000669225   \n",
       "param_n_estimators                                                150   \n",
       "param_max_depth                                                  None   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 150, 'max_depth': None, 'crit...   \n",
       "split0_test_score                                            -321.931   \n",
       "split1_test_score                                            -319.303   \n",
       "split2_test_score                                            -282.616   \n",
       "split3_test_score                                            -273.002   \n",
       "split4_test_score                                             -282.26   \n",
       "split5_test_score                                            -264.279   \n",
       "split6_test_score                                            -293.141   \n",
       "split7_test_score                                            -296.641   \n",
       "split8_test_score                                            -274.191   \n",
       "split9_test_score                                            -245.256   \n",
       "mean_test_score                                              -285.262   \n",
       "std_test_score                                                22.4158   \n",
       "rank_test_score                                                     3   \n",
       "split0_train_score                                           -105.405   \n",
       "split1_train_score                                           -104.135   \n",
       "split2_train_score                                           -108.549   \n",
       "split3_train_score                                           -103.958   \n",
       "split4_train_score                                           -105.932   \n",
       "split5_train_score                                           -108.963   \n",
       "split6_train_score                                           -105.642   \n",
       "split7_train_score                                           -107.127   \n",
       "split8_train_score                                           -105.666   \n",
       "split9_train_score                                           -105.874   \n",
       "mean_train_score                                             -106.125   \n",
       "std_train_score                                               1.57004   \n",
       "\n",
       "                                                                   10  \\\n",
       "mean_fit_time                                                 3.33439   \n",
       "std_fit_time                                                 0.109832   \n",
       "mean_score_time                                            0.00718939   \n",
       "std_score_time                                            0.000354761   \n",
       "param_n_estimators                                                150   \n",
       "param_max_depth                                                    15   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 150, 'max_depth': 15, 'criter...   \n",
       "split0_test_score                                             -325.77   \n",
       "split1_test_score                                            -322.253   \n",
       "split2_test_score                                            -275.469   \n",
       "split3_test_score                                            -270.402   \n",
       "split4_test_score                                            -286.879   \n",
       "split5_test_score                                            -265.065   \n",
       "split6_test_score                                            -292.743   \n",
       "split7_test_score                                            -299.216   \n",
       "split8_test_score                                            -275.355   \n",
       "split9_test_score                                            -243.733   \n",
       "mean_test_score                                              -285.688   \n",
       "std_test_score                                                24.1002   \n",
       "rank_test_score                                                     4   \n",
       "split0_train_score                                           -109.053   \n",
       "split1_train_score                                           -108.348   \n",
       "split2_train_score                                           -112.961   \n",
       "split3_train_score                                           -106.772   \n",
       "split4_train_score                                            -109.68   \n",
       "split5_train_score                                            -113.76   \n",
       "split6_train_score                                           -109.882   \n",
       "split7_train_score                                           -111.957   \n",
       "split8_train_score                                           -110.256   \n",
       "split9_train_score                                           -110.191   \n",
       "mean_train_score                                             -110.286   \n",
       "std_train_score                                               2.00455   \n",
       "\n",
       "                                                                   12  \\\n",
       "mean_fit_time                                                 1.14177   \n",
       "std_fit_time                                                0.0386345   \n",
       "mean_score_time                                            0.00303199   \n",
       "std_score_time                                            0.000149721   \n",
       "param_n_estimators                                                 50   \n",
       "param_max_depth                                                  None   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 50, 'max_depth': None, 'crite...   \n",
       "split0_test_score                                            -321.548   \n",
       "split1_test_score                                            -316.419   \n",
       "split2_test_score                                            -275.692   \n",
       "split3_test_score                                            -270.571   \n",
       "split4_test_score                                            -290.469   \n",
       "split5_test_score                                            -273.234   \n",
       "split6_test_score                                            -289.803   \n",
       "split7_test_score                                            -300.981   \n",
       "split8_test_score                                             -271.45   \n",
       "split9_test_score                                            -247.539   \n",
       "mean_test_score                                              -285.771   \n",
       "std_test_score                                                21.5537   \n",
       "rank_test_score                                                     5   \n",
       "split0_train_score                                           -107.686   \n",
       "split1_train_score                                           -106.064   \n",
       "split2_train_score                                           -109.945   \n",
       "split3_train_score                                           -107.556   \n",
       "split4_train_score                                           -110.334   \n",
       "split5_train_score                                           -112.644   \n",
       "split6_train_score                                           -108.483   \n",
       "split7_train_score                                           -111.067   \n",
       "split8_train_score                                           -108.407   \n",
       "split9_train_score                                           -107.831   \n",
       "mean_train_score                                             -109.002   \n",
       "std_train_score                                               1.86125   \n",
       "\n",
       "                                                                   8   \\\n",
       "mean_fit_time                                                 1.15142   \n",
       "std_fit_time                                                0.0762749   \n",
       "mean_score_time                                            0.00308113   \n",
       "std_score_time                                            0.000199324   \n",
       "param_n_estimators                                                 50   \n",
       "param_max_depth                                                    15   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 50, 'max_depth': 15, 'criteri...   \n",
       "split0_test_score                                            -326.317   \n",
       "split1_test_score                                            -321.503   \n",
       "split2_test_score                                            -271.065   \n",
       "split3_test_score                                            -271.643   \n",
       "split4_test_score                                            -288.041   \n",
       "split5_test_score                                            -274.498   \n",
       "split6_test_score                                            -290.381   \n",
       "split7_test_score                                            -302.852   \n",
       "split8_test_score                                            -277.063   \n",
       "split9_test_score                                             -246.63   \n",
       "mean_test_score                                              -286.999   \n",
       "std_test_score                                                23.1833   \n",
       "rank_test_score                                                     6   \n",
       "split0_train_score                                            -111.43   \n",
       "split1_train_score                                           -110.946   \n",
       "split2_train_score                                            -114.41   \n",
       "split3_train_score                                           -110.806   \n",
       "split4_train_score                                           -113.384   \n",
       "split5_train_score                                           -116.182   \n",
       "split6_train_score                                           -112.256   \n",
       "split7_train_score                                           -115.001   \n",
       "split8_train_score                                           -114.043   \n",
       "split9_train_score                                           -111.745   \n",
       "mean_train_score                                              -113.02   \n",
       "std_train_score                                               1.75988   \n",
       "\n",
       "                                                                   13  \\\n",
       "mean_fit_time                                                 2.37445   \n",
       "std_fit_time                                                 0.148787   \n",
       "mean_score_time                                            0.00522752   \n",
       "std_score_time                                            0.000267447   \n",
       "param_n_estimators                                                100   \n",
       "param_max_depth                                                  None   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 100, 'max_depth': None, 'crit...   \n",
       "split0_test_score                                            -319.673   \n",
       "split1_test_score                                            -321.636   \n",
       "split2_test_score                                            -284.694   \n",
       "split3_test_score                                            -271.711   \n",
       "split4_test_score                                            -286.617   \n",
       "split5_test_score                                            -269.178   \n",
       "split6_test_score                                             -293.46   \n",
       "split7_test_score                                            -298.069   \n",
       "split8_test_score                                            -274.163   \n",
       "split9_test_score                                            -251.074   \n",
       "mean_test_score                                              -287.027   \n",
       "std_test_score                                                21.0802   \n",
       "rank_test_score                                                     7   \n",
       "split0_train_score                                            -106.61   \n",
       "split1_train_score                                           -104.703   \n",
       "split2_train_score                                            -110.59   \n",
       "split3_train_score                                           -105.401   \n",
       "split4_train_score                                            -107.87   \n",
       "split5_train_score                                           -110.849   \n",
       "split6_train_score                                           -105.821   \n",
       "split7_train_score                                           -108.052   \n",
       "split8_train_score                                           -106.732   \n",
       "split9_train_score                                           -106.112   \n",
       "mean_train_score                                             -107.274   \n",
       "std_train_score                                               1.97612   \n",
       "\n",
       "                                                                   9   \\\n",
       "mean_fit_time                                                 2.16108   \n",
       "std_fit_time                                                0.0258445   \n",
       "mean_score_time                                            0.00503674   \n",
       "std_score_time                                            0.000162938   \n",
       "param_n_estimators                                                100   \n",
       "param_max_depth                                                    15   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 100, 'max_depth': 15, 'criter...   \n",
       "split0_test_score                                            -323.788   \n",
       "split1_test_score                                             -322.56   \n",
       "split2_test_score                                            -277.566   \n",
       "split3_test_score                                            -267.628   \n",
       "split4_test_score                                              -287.1   \n",
       "split5_test_score                                            -272.393   \n",
       "split6_test_score                                            -294.743   \n",
       "split7_test_score                                            -300.614   \n",
       "split8_test_score                                            -278.029   \n",
       "split9_test_score                                            -249.945   \n",
       "mean_test_score                                              -287.437   \n",
       "std_test_score                                                22.3438   \n",
       "rank_test_score                                                     8   \n",
       "split0_train_score                                           -110.712   \n",
       "split1_train_score                                           -109.305   \n",
       "split2_train_score                                            -115.95   \n",
       "split3_train_score                                           -108.363   \n",
       "split4_train_score                                           -110.912   \n",
       "split5_train_score                                           -115.779   \n",
       "split6_train_score                                           -110.482   \n",
       "split7_train_score                                           -113.233   \n",
       "split8_train_score                                           -112.312   \n",
       "split9_train_score                                           -111.338   \n",
       "mean_train_score                                             -111.839   \n",
       "std_train_score                                               2.39399   \n",
       "\n",
       "                                                                   4   \\\n",
       "mean_fit_time                                                 0.97817   \n",
       "std_fit_time                                                0.0193383   \n",
       "mean_score_time                                            0.00328872   \n",
       "std_score_time                                             0.00125356   \n",
       "param_n_estimators                                                 50   \n",
       "param_max_depth                                                    10   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 50, 'max_depth': 10, 'criteri...   \n",
       "split0_test_score                                            -332.144   \n",
       "split1_test_score                                             -323.08   \n",
       "split2_test_score                                            -276.546   \n",
       "split3_test_score                                            -270.416   \n",
       "split4_test_score                                            -292.809   \n",
       "split5_test_score                                            -274.597   \n",
       "split6_test_score                                            -293.478   \n",
       "split7_test_score                                            -301.994   \n",
       "split8_test_score                                            -275.984   \n",
       "split9_test_score                                            -246.752   \n",
       "mean_test_score                                               -288.78   \n",
       "std_test_score                                                24.2653   \n",
       "rank_test_score                                                     9   \n",
       "split0_train_score                                           -141.054   \n",
       "split1_train_score                                           -142.434   \n",
       "split2_train_score                                           -144.301   \n",
       "split3_train_score                                            -141.91   \n",
       "split4_train_score                                           -145.049   \n",
       "split5_train_score                                           -148.758   \n",
       "split6_train_score                                           -141.668   \n",
       "split7_train_score                                           -150.084   \n",
       "split8_train_score                                           -146.279   \n",
       "split9_train_score                                           -145.951   \n",
       "mean_train_score                                             -144.749   \n",
       "std_train_score                                               2.91844   \n",
       "\n",
       "                                                                   7   \\\n",
       "mean_fit_time                                                 4.00686   \n",
       "std_fit_time                                                 0.114269   \n",
       "mean_score_time                                            0.00844691   \n",
       "std_score_time                                            0.000179515   \n",
       "param_n_estimators                                                200   \n",
       "param_max_depth                                                    10   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 200, 'max_depth': 10, 'criter...   \n",
       "split0_test_score                                            -329.481   \n",
       "split1_test_score                                            -322.867   \n",
       "split2_test_score                                            -276.539   \n",
       "split3_test_score                                            -276.374   \n",
       "split4_test_score                                            -290.632   \n",
       "split5_test_score                                            -273.674   \n",
       "split6_test_score                                            -291.723   \n",
       "split7_test_score                                            -301.436   \n",
       "split8_test_score                                            -280.308   \n",
       "split9_test_score                                             -253.57   \n",
       "mean_test_score                                               -289.66   \n",
       "std_test_score                                                21.9691   \n",
       "rank_test_score                                                    10   \n",
       "split0_train_score                                           -139.211   \n",
       "split1_train_score                                           -139.499   \n",
       "split2_train_score                                            -145.32   \n",
       "split3_train_score                                           -139.179   \n",
       "split4_train_score                                           -143.684   \n",
       "split5_train_score                                           -144.958   \n",
       "split6_train_score                                           -142.203   \n",
       "split7_train_score                                           -147.795   \n",
       "split8_train_score                                           -144.017   \n",
       "split9_train_score                                           -144.427   \n",
       "mean_train_score                                             -143.029   \n",
       "std_train_score                                               2.78539   \n",
       "\n",
       "                                                                   6   \\\n",
       "mean_fit_time                                                 2.96848   \n",
       "std_fit_time                                                0.0436853   \n",
       "mean_score_time                                            0.00682487   \n",
       "std_score_time                                            0.000878408   \n",
       "param_n_estimators                                                150   \n",
       "param_max_depth                                                    10   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 150, 'max_depth': 10, 'criter...   \n",
       "split0_test_score                                            -329.609   \n",
       "split1_test_score                                            -324.257   \n",
       "split2_test_score                                            -276.846   \n",
       "split3_test_score                                            -275.154   \n",
       "split4_test_score                                            -292.686   \n",
       "split5_test_score                                             -272.85   \n",
       "split6_test_score                                            -296.167   \n",
       "split7_test_score                                            -302.006   \n",
       "split8_test_score                                            -279.426   \n",
       "split9_test_score                                            -251.544   \n",
       "mean_test_score                                              -290.055   \n",
       "std_test_score                                                22.8255   \n",
       "rank_test_score                                                    11   \n",
       "split0_train_score                                           -139.579   \n",
       "split1_train_score                                           -140.278   \n",
       "split2_train_score                                           -145.923   \n",
       "split3_train_score                                           -139.502   \n",
       "split4_train_score                                            -143.76   \n",
       "split5_train_score                                           -146.687   \n",
       "split6_train_score                                           -141.379   \n",
       "split7_train_score                                           -147.718   \n",
       "split8_train_score                                           -144.031   \n",
       "split9_train_score                                           -143.334   \n",
       "mean_train_score                                             -143.219   \n",
       "std_train_score                                               2.82223   \n",
       "\n",
       "                                                                   5   \\\n",
       "mean_fit_time                                                 2.05906   \n",
       "std_fit_time                                                0.0545368   \n",
       "mean_score_time                                            0.00470898   \n",
       "std_score_time                                            0.000156513   \n",
       "param_n_estimators                                                100   \n",
       "param_max_depth                                                    10   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 100, 'max_depth': 10, 'criter...   \n",
       "split0_test_score                                            -329.442   \n",
       "split1_test_score                                            -323.187   \n",
       "split2_test_score                                            -278.988   \n",
       "split3_test_score                                            -273.791   \n",
       "split4_test_score                                            -292.651   \n",
       "split5_test_score                                            -276.949   \n",
       "split6_test_score                                            -297.944   \n",
       "split7_test_score                                            -303.742   \n",
       "split8_test_score                                            -279.572   \n",
       "split9_test_score                                             -253.26   \n",
       "mean_test_score                                              -290.953   \n",
       "std_test_score                                                22.1806   \n",
       "rank_test_score                                                    12   \n",
       "split0_train_score                                           -141.542   \n",
       "split1_train_score                                           -141.025   \n",
       "split2_train_score                                           -147.352   \n",
       "split3_train_score                                           -139.849   \n",
       "split4_train_score                                           -144.259   \n",
       "split5_train_score                                           -148.222   \n",
       "split6_train_score                                           -140.418   \n",
       "split7_train_score                                            -147.88   \n",
       "split8_train_score                                           -145.055   \n",
       "split9_train_score                                           -143.625   \n",
       "mean_train_score                                             -143.923   \n",
       "std_train_score                                               3.00547   \n",
       "\n",
       "                                                                   0   \\\n",
       "mean_fit_time                                                0.725026   \n",
       "std_fit_time                                                0.0226073   \n",
       "mean_score_time                                            0.00244737   \n",
       "std_score_time                                            2.17659e-05   \n",
       "param_n_estimators                                                 50   \n",
       "param_max_depth                                                     5   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 50, 'max_depth': 5, 'criterio...   \n",
       "split0_test_score                                            -362.628   \n",
       "split1_test_score                                            -385.128   \n",
       "split2_test_score                                            -299.894   \n",
       "split3_test_score                                            -321.979   \n",
       "split4_test_score                                            -356.815   \n",
       "split5_test_score                                            -361.232   \n",
       "split6_test_score                                            -350.982   \n",
       "split7_test_score                                              -358.8   \n",
       "split8_test_score                                            -323.485   \n",
       "split9_test_score                                            -305.396   \n",
       "mean_test_score                                              -342.634   \n",
       "std_test_score                                                26.6275   \n",
       "rank_test_score                                                    13   \n",
       "split0_train_score                                           -289.706   \n",
       "split1_train_score                                           -285.541   \n",
       "split2_train_score                                            -298.96   \n",
       "split3_train_score                                           -292.099   \n",
       "split4_train_score                                           -287.783   \n",
       "split5_train_score                                           -295.455   \n",
       "split6_train_score                                           -291.302   \n",
       "split7_train_score                                           -298.608   \n",
       "split8_train_score                                           -290.623   \n",
       "split9_train_score                                           -296.954   \n",
       "mean_train_score                                             -292.703   \n",
       "std_train_score                                               4.36815   \n",
       "\n",
       "                                                                   2   \\\n",
       "mean_fit_time                                                 2.19304   \n",
       "std_fit_time                                                0.0987017   \n",
       "mean_score_time                                            0.00562375   \n",
       "std_score_time                                             0.00010883   \n",
       "param_n_estimators                                                150   \n",
       "param_max_depth                                                     5   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 150, 'max_depth': 5, 'criteri...   \n",
       "split0_test_score                                             -361.92   \n",
       "split1_test_score                                            -380.425   \n",
       "split2_test_score                                            -303.758   \n",
       "split3_test_score                                            -324.351   \n",
       "split4_test_score                                            -355.871   \n",
       "split5_test_score                                            -362.812   \n",
       "split6_test_score                                            -349.961   \n",
       "split7_test_score                                            -363.187   \n",
       "split8_test_score                                            -319.849   \n",
       "split9_test_score                                            -309.648   \n",
       "mean_test_score                                              -343.178   \n",
       "std_test_score                                                25.1167   \n",
       "rank_test_score                                                    14   \n",
       "split0_train_score                                           -290.295   \n",
       "split1_train_score                                           -285.899   \n",
       "split2_train_score                                           -303.093   \n",
       "split3_train_score                                           -294.005   \n",
       "split4_train_score                                           -284.267   \n",
       "split5_train_score                                           -293.942   \n",
       "split6_train_score                                           -290.628   \n",
       "split7_train_score                                           -298.268   \n",
       "split8_train_score                                           -292.526   \n",
       "split9_train_score                                           -295.119   \n",
       "mean_train_score                                             -292.804   \n",
       "std_train_score                                               5.24875   \n",
       "\n",
       "                                                                   3   \\\n",
       "mean_fit_time                                                 2.82138   \n",
       "std_fit_time                                                0.0334354   \n",
       "mean_score_time                                            0.00712576   \n",
       "std_score_time                                            0.000134238   \n",
       "param_n_estimators                                                200   \n",
       "param_max_depth                                                     5   \n",
       "param_criterion                                                   mae   \n",
       "params              {'n_estimators': 200, 'max_depth': 5, 'criteri...   \n",
       "split0_test_score                                            -363.107   \n",
       "split1_test_score                                            -379.116   \n",
       "split2_test_score                                            -303.612   \n",
       "split3_test_score                                            -325.605   \n",
       "split4_test_score                                            -355.361   \n",
       "split5_test_score                                             -364.37   \n",
       "split6_test_score                                            -349.147   \n",
       "split7_test_score                                            -361.447   \n",
       "split8_test_score                                            -319.391   \n",
       "split9_test_score                                             -312.96   \n",
       "mean_test_score                                              -343.412   \n",
       "std_test_score                                                24.5119   \n",
       "rank_test_score                                                    15   \n",
       "split0_train_score                                           -289.882   \n",
       "split1_train_score                                           -285.334   \n",
       "split2_train_score                                           -302.338   \n",
       "split3_train_score                                           -293.389   \n",
       "split4_train_score                                            -284.65   \n",
       "split5_train_score                                           -294.021   \n",
       "split6_train_score                                           -292.508   \n",
       "split7_train_score                                           -299.212   \n",
       "split8_train_score                                           -293.143   \n",
       "split9_train_score                                           -297.598   \n",
       "mean_train_score                                             -293.208   \n",
       "std_train_score                                               5.34935   \n",
       "\n",
       "                                                                   1   \n",
       "mean_fit_time                                                 1.46448  \n",
       "std_fit_time                                                0.0546199  \n",
       "mean_score_time                                            0.00425725  \n",
       "std_score_time                                            0.000393284  \n",
       "param_n_estimators                                                100  \n",
       "param_max_depth                                                     5  \n",
       "param_criterion                                                   mae  \n",
       "params              {'n_estimators': 100, 'max_depth': 5, 'criteri...  \n",
       "split0_test_score                                            -362.654  \n",
       "split1_test_score                                            -382.132  \n",
       "split2_test_score                                             -305.62  \n",
       "split3_test_score                                            -324.547  \n",
       "split4_test_score                                            -356.723  \n",
       "split5_test_score                                            -363.922  \n",
       "split6_test_score                                            -352.202  \n",
       "split7_test_score                                            -360.523  \n",
       "split8_test_score                                             -318.24  \n",
       "split9_test_score                                            -309.053  \n",
       "mean_test_score                                              -343.562  \n",
       "std_test_score                                                25.3682  \n",
       "rank_test_score                                                    16  \n",
       "split0_train_score                                           -292.688  \n",
       "split1_train_score                                           -287.797  \n",
       "split2_train_score                                            -302.56  \n",
       "split3_train_score                                            -292.72  \n",
       "split4_train_score                                           -285.367  \n",
       "split5_train_score                                           -293.472  \n",
       "split6_train_score                                           -291.322  \n",
       "split7_train_score                                           -296.271  \n",
       "split8_train_score                                           -290.046  \n",
       "split9_train_score                                           -292.445  \n",
       "mean_train_score                                             -292.469  \n",
       "std_train_score                                               4.43678  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to test our new encodings:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = daily.drop(columns='Total')\n",
    "y = daily['Total']\n",
    "\n",
    "X = ned_wrangle(jake_wrangle(X))\n",
    "\n",
    "# Split Train, Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params= {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'criterion' : ['mae']\n",
    "}\n",
    "\n",
    "gridsearch = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_distributions = params,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_iter = 20,\n",
    "    cv=10,\n",
    "    n_jobs = -1,\n",
    "    verbose=10,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "results = pd.DataFrame(gridsearch.cv_results_)\n",
    "results.sort_values(by='rank_test_score').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
       "            max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       " 282.55037558685444)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gridsearch.best_estimator_.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "# gridsearch.best_estimator_.score([y_pred], y_test)\n",
    "\n",
    "gridsearch.best_estimator_, mean_absolute_error(y_pred, y_test)\n",
    "\n",
    "# so our best random forrest producest a MEA of 282.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   XGBClassifier(max_depth=depth, n_estimators = n,\n",
    "                        n_jobs=-1, random_state=randseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cv',\n",
       " 'error_score',\n",
       " 'estimator',\n",
       " 'estimator__base_score',\n",
       " 'estimator__booster',\n",
       " 'estimator__colsample_bylevel',\n",
       " 'estimator__colsample_bytree',\n",
       " 'estimator__gamma',\n",
       " 'estimator__learning_rate',\n",
       " 'estimator__max_delta_step',\n",
       " 'estimator__max_depth',\n",
       " 'estimator__min_child_weight',\n",
       " 'estimator__missing',\n",
       " 'estimator__n_estimators',\n",
       " 'estimator__n_jobs',\n",
       " 'estimator__nthread',\n",
       " 'estimator__objective',\n",
       " 'estimator__random_state',\n",
       " 'estimator__reg_alpha',\n",
       " 'estimator__reg_lambda',\n",
       " 'estimator__scale_pos_weight',\n",
       " 'estimator__seed',\n",
       " 'estimator__silent',\n",
       " 'estimator__subsample',\n",
       " 'fit_params',\n",
       " 'iid',\n",
       " 'n_iter',\n",
       " 'n_jobs',\n",
       " 'param_distributions',\n",
       " 'pre_dispatch',\n",
       " 'random_state',\n",
       " 'refit',\n",
       " 'return_train_score',\n",
       " 'scoring',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(gridsearch.get_params().keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   43.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1, gamma=0, learning_rate=0.07, max_delta_step=0,\n",
       "        max_depth=5, min_child_weight=1, missing=None, n_estimators=150,\n",
       "        n_jobs=1, nthread=4, objective='reg:linear', random_state=0,\n",
       "        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "        subsample=1, tree_method='gpu_exact'), 246.61857884366748)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to test our new encodings:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = daily.drop(columns='Total')\n",
    "y = daily['Total']\n",
    "\n",
    "X = ned_wrangle(jake_wrangle(X))\n",
    "\n",
    "# Split Train, Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params= {\n",
    "    'learning_rate' : [.03, 0.05, .07],\n",
    "    'nthread':[4],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "#     'criterion' : ['mae']\n",
    "}\n",
    "\n",
    "gridsearch = RandomizedSearchCV(\n",
    "    XGBRegressor(seed=42, tree_method='gpu_exact'),\n",
    "    param_distributions = params,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_iter = 20,\n",
    "    cv=5,\n",
    "    n_jobs = -1,\n",
    "    verbose=10,\n",
    "    random_state=42,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "results = pd.DataFrame(gridsearch.cv_results_)\n",
    "results.sort_values(by='rank_test_score').T\n",
    "y_pred = gridsearch.best_estimator_.predict(X_test)\n",
    "gridsearch.best_estimator_, mean_absolute_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oux-dd-5FD6p"
   },
   "source": [
    "**3.** Experiment with the Categorical Encoding notebook.\n",
    "\n",
    "**4.** At the end of the day, take the last step in the \"universal workflow of machine learning\" — \"You can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\"\n",
    "\n",
    "See the [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) documentation for the `refit` parameter, `best_estimator_` attribute, and `predict` method:\n",
    "\n",
    "> **refit : boolean, or string, default=True**\n",
    "\n",
    "> Refit an estimator using the best found parameters on the whole dataset.\n",
    "\n",
    "> The refitted estimator is made available at the `best_estimator_` attribute and permits using `predict` directly on this `GridSearchCV` instance.\n",
    "\n",
    "### STRETCH\n",
    "\n",
    "**A.** Apply this lesson other datasets you've worked with, like Ames Housing, Bank Marketing, or others.\n",
    "\n",
    "**B.** In additon to `RandomizedSearchCV`, scikit-learn has [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Another library called scikit-optimize has [`BayesSearchCV`](https://scikit-optimize.github.io/notebooks/sklearn-gridsearchcv-replacement.html). Experiment with these alternatives.\n",
    "\n",
    "**C.** _[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)_ discusses options for \"Grid-Searching Which Model To Use\" in Chapter 6:\n",
    "\n",
    "> You can even go further in combining GridSearchCV and Pipeline: it is also possible to search over the actual steps being performed in the pipeline (say whether to use StandardScaler or MinMaxScaler). This leads to an even bigger search space and should be considered carefully. Trying all possible solutions is usually not a viable machine learning strategy. However, here is an example comparing a RandomForestClassifier and an SVC ...\n",
    "\n",
    "The example is shown in [the accompanying notebook](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb), code cells 35-37. Could you apply this concept to your own pipelines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of LS_DS_243_Select_models_and_parameters.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
