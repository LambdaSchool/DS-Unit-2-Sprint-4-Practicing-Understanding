{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_243_Select_models_and_parameters.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O67uhlT4MExK"
      },
      "source": [
        "_Lambda School Data Science — Practicing & Understanding Predictive Modeling_\n",
        "\n",
        "# Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VE4rfZd4NUGA"
      },
      "source": [
        "Today we'll use this process:\n",
        "\n",
        "## \"A universal workflow of machine learning\"\n",
        "\n",
        "_Excerpt from Francois Chollet, [Deep Learning with Python](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/README.md), Chapter 4: Fundamentals of machine learning_\n",
        " \n",
        "**1. Define the problem at hand and the data on which you’ll train.** Collect this data, or annotate it with labels if need be.\n",
        "\n",
        "**2. Choose how you’ll measure success on your problem.** Which metrics will you monitor on your validation data?\n",
        "\n",
        "**3. Determine your evaluation protocol:** hold-out validation? K-fold validation? Which portion of the data should you use for validation?\n",
        "\n",
        "**4. Develop a first model that does better than a basic baseline:** a model with statistical power.\n",
        "\n",
        "**5. Develop a model that overfits.** The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
        "\n",
        "**6. Regularize your model and tune its hyperparameters, based on performance on the validation data.** Repeatedly modify your model, train it, evaluate on your validation data (not the test data, at this point), modify it again, and repeat, until the model is as good as it can get. \n",
        "\n",
        "**Iterate on feature engineering: add new features, or remove features that don’t seem to be informative.** \n",
        "\n",
        "Once you’ve developed a satisfactory model configuration, you can **train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3kt6bzEcOIaa"
      },
      "source": [
        "## 1. Define the problem at hand and the data on which you'll train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "di16k7vpRg67"
      },
      "source": [
        "We'll apply the workflow to a [project from _Python Data Science Handbook_](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic) by Jake VanderPlas:\n",
        "\n",
        "> **Predicting Bicycle Traffic**\n",
        "\n",
        "> As an example, let's take a look at whether we can predict the number of bicycle trips across Seattle's Fremont Bridge based on weather, season, and other factors.\n",
        "\n",
        "> We will join the bike data with another dataset, and try to determine the extent to which weather and seasonal factors—temperature, precipitation, and daylight hours—affect the volume of bicycle traffic through this corridor. Fortunately, the NOAA makes available their daily [weather station data](http://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND) (I used station ID USW00024233) and we can easily use Pandas to join the two data sources.\n",
        "\n",
        "> Let's start by loading the two datasets, indexing by date:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "19dpb_d0R1A6"
      },
      "source": [
        "So this is a regression problem, not a classification problem. We'll define the target, choose an evaluation metric, and choose models that are appropriate for regression problems.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "os1zruXQ30KM"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5XVu-HSeMDtV",
        "outputId": "589c3ce1-91a6-49eb-ceff-3ca562794ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1616k    0 1616k    0     0  1058k      0 --:--:--  0:00:01 --:--:-- 1057k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sih_7mTzMdfr",
        "outputId": "12325e9e-060a-41f9-93d3-67f0e771a890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-14 09:31:50--  https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 234945 (229K) [text/plain]\n",
            "Saving to: ‘BicycleWeather.csv.4’\n",
            "\n",
            "\rBicycleWeather.csv.   0%[                    ]       0  --.-KB/s               \rBicycleWeather.csv. 100%[===================>] 229.44K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-05-14 09:31:50 (7.86 MB/s) - ‘BicycleWeather.csv.4’ saved [234945/234945]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9GYm74kD34OQ"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BfQ7gE28MNdF",
        "colab": {}
      },
      "source": [
        "# Modified from cells 15, 16, and 20, at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Download and join data into a dataframe\n",
        "def load(): \n",
        "    fremont_bridge = 'https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD'\n",
        "    \n",
        "    bicycle_weather = 'https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv'\n",
        "\n",
        "    counts = pd.read_csv(fremont_bridge, index_col='Date', parse_dates=True, \n",
        "                         infer_datetime_format=True)\n",
        "\n",
        "    weather = pd.read_csv(bicycle_weather, index_col='DATE', parse_dates=True, \n",
        "                          infer_datetime_format=True)\n",
        "\n",
        "    daily = counts.resample('d').sum()\n",
        "    daily['Total'] = daily.sum(axis=1)\n",
        "    daily = daily[['Total']] # remove other columns\n",
        "\n",
        "    weather_columns = ['PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND']\n",
        "    daily = daily.join(weather[weather_columns], how='inner')\n",
        "    \n",
        "    # Make a feature for yesterday's total\n",
        "    daily['Total_yesterday'] = daily.Total.shift(1)\n",
        "    daily = daily.drop(index=daily.index[0])\n",
        "    \n",
        "    return daily\n",
        "\n",
        "daily = load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtbqbd29U-ju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X_IPvYxRSq2",
        "colab_type": "code",
        "outputId": "e1cd8447-8242-4729-a119-72e8c3ad5284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2000
        }
      },
      "source": [
        "fremont_bridge = 'https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD'\n",
        "pd.read_csv(fremont_bridge, index_col='Date', parse_dates=True, \n",
        "                         infer_datetime_format=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fremont Bridge East Sidewalk</th>\n",
              "      <th>Fremont Bridge West Sidewalk</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-04-30 23:00:00</th>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 22:00:00</th>\n",
              "      <td>15.0</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 21:00:00</th>\n",
              "      <td>17.0</td>\n",
              "      <td>54.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 20:00:00</th>\n",
              "      <td>58.0</td>\n",
              "      <td>91.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 19:00:00</th>\n",
              "      <td>106.0</td>\n",
              "      <td>175.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 18:00:00</th>\n",
              "      <td>142.0</td>\n",
              "      <td>371.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 17:00:00</th>\n",
              "      <td>214.0</td>\n",
              "      <td>587.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 16:00:00</th>\n",
              "      <td>113.0</td>\n",
              "      <td>346.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 15:00:00</th>\n",
              "      <td>68.0</td>\n",
              "      <td>113.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 14:00:00</th>\n",
              "      <td>59.0</td>\n",
              "      <td>88.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 13:00:00</th>\n",
              "      <td>39.0</td>\n",
              "      <td>78.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 12:00:00</th>\n",
              "      <td>52.0</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 11:00:00</th>\n",
              "      <td>49.0</td>\n",
              "      <td>53.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 10:00:00</th>\n",
              "      <td>64.0</td>\n",
              "      <td>74.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 09:00:00</th>\n",
              "      <td>148.0</td>\n",
              "      <td>195.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 08:00:00</th>\n",
              "      <td>318.0</td>\n",
              "      <td>399.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 07:00:00</th>\n",
              "      <td>234.0</td>\n",
              "      <td>254.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 06:00:00</th>\n",
              "      <td>96.0</td>\n",
              "      <td>82.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 05:00:00</th>\n",
              "      <td>31.0</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 04:00:00</th>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 03:00:00</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 02:00:00</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 01:00:00</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-30 00:00:00</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-29 23:00:00</th>\n",
              "      <td>9.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-29 22:00:00</th>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-29 21:00:00</th>\n",
              "      <td>22.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-29 20:00:00</th>\n",
              "      <td>32.0</td>\n",
              "      <td>54.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-29 19:00:00</th>\n",
              "      <td>71.0</td>\n",
              "      <td>158.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-29 18:00:00</th>\n",
              "      <td>133.0</td>\n",
              "      <td>349.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-04 05:00:00</th>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-04 04:00:00</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-04 03:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-04 02:00:00</th>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-04 01:00:00</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-04 00:00:00</th>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 23:00:00</th>\n",
              "      <td>5.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 22:00:00</th>\n",
              "      <td>24.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 21:00:00</th>\n",
              "      <td>25.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 20:00:00</th>\n",
              "      <td>29.0</td>\n",
              "      <td>51.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 19:00:00</th>\n",
              "      <td>59.0</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 18:00:00</th>\n",
              "      <td>122.0</td>\n",
              "      <td>258.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 17:00:00</th>\n",
              "      <td>192.0</td>\n",
              "      <td>391.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 16:00:00</th>\n",
              "      <td>133.0</td>\n",
              "      <td>182.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 15:00:00</th>\n",
              "      <td>72.0</td>\n",
              "      <td>92.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 14:00:00</th>\n",
              "      <td>77.0</td>\n",
              "      <td>51.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 13:00:00</th>\n",
              "      <td>42.0</td>\n",
              "      <td>48.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 12:00:00</th>\n",
              "      <td>35.0</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 11:00:00</th>\n",
              "      <td>10.0</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 10:00:00</th>\n",
              "      <td>72.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 09:00:00</th>\n",
              "      <td>172.0</td>\n",
              "      <td>104.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 08:00:00</th>\n",
              "      <td>291.0</td>\n",
              "      <td>146.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 07:00:00</th>\n",
              "      <td>257.0</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 06:00:00</th>\n",
              "      <td>105.0</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 05:00:00</th>\n",
              "      <td>21.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 04:00:00</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 03:00:00</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 02:00:00</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 01:00:00</th>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-03 00:00:00</th>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57624 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Fremont Bridge East Sidewalk  \\\n",
              "Date                                                \n",
              "2019-04-30 23:00:00                           8.0   \n",
              "2019-04-30 22:00:00                          15.0   \n",
              "2019-04-30 21:00:00                          17.0   \n",
              "2019-04-30 20:00:00                          58.0   \n",
              "2019-04-30 19:00:00                         106.0   \n",
              "2019-04-30 18:00:00                         142.0   \n",
              "2019-04-30 17:00:00                         214.0   \n",
              "2019-04-30 16:00:00                         113.0   \n",
              "2019-04-30 15:00:00                          68.0   \n",
              "2019-04-30 14:00:00                          59.0   \n",
              "2019-04-30 13:00:00                          39.0   \n",
              "2019-04-30 12:00:00                          52.0   \n",
              "2019-04-30 11:00:00                          49.0   \n",
              "2019-04-30 10:00:00                          64.0   \n",
              "2019-04-30 09:00:00                         148.0   \n",
              "2019-04-30 08:00:00                         318.0   \n",
              "2019-04-30 07:00:00                         234.0   \n",
              "2019-04-30 06:00:00                          96.0   \n",
              "2019-04-30 05:00:00                          31.0   \n",
              "2019-04-30 04:00:00                           7.0   \n",
              "2019-04-30 03:00:00                           1.0   \n",
              "2019-04-30 02:00:00                           1.0   \n",
              "2019-04-30 01:00:00                           2.0   \n",
              "2019-04-30 00:00:00                           2.0   \n",
              "2019-04-29 23:00:00                           9.0   \n",
              "2019-04-29 22:00:00                          12.0   \n",
              "2019-04-29 21:00:00                          22.0   \n",
              "2019-04-29 20:00:00                          32.0   \n",
              "2019-04-29 19:00:00                          71.0   \n",
              "2019-04-29 18:00:00                         133.0   \n",
              "...                                           ...   \n",
              "2012-10-04 05:00:00                          15.0   \n",
              "2012-10-04 04:00:00                           7.0   \n",
              "2012-10-04 03:00:00                           0.0   \n",
              "2012-10-04 02:00:00                           3.0   \n",
              "2012-10-04 01:00:00                           3.0   \n",
              "2012-10-04 00:00:00                           7.0   \n",
              "2012-10-03 23:00:00                           5.0   \n",
              "2012-10-03 22:00:00                          24.0   \n",
              "2012-10-03 21:00:00                          25.0   \n",
              "2012-10-03 20:00:00                          29.0   \n",
              "2012-10-03 19:00:00                          59.0   \n",
              "2012-10-03 18:00:00                         122.0   \n",
              "2012-10-03 17:00:00                         192.0   \n",
              "2012-10-03 16:00:00                         133.0   \n",
              "2012-10-03 15:00:00                          72.0   \n",
              "2012-10-03 14:00:00                          77.0   \n",
              "2012-10-03 13:00:00                          42.0   \n",
              "2012-10-03 12:00:00                          35.0   \n",
              "2012-10-03 11:00:00                          10.0   \n",
              "2012-10-03 10:00:00                          72.0   \n",
              "2012-10-03 09:00:00                         172.0   \n",
              "2012-10-03 08:00:00                         291.0   \n",
              "2012-10-03 07:00:00                         257.0   \n",
              "2012-10-03 06:00:00                         105.0   \n",
              "2012-10-03 05:00:00                          21.0   \n",
              "2012-10-03 04:00:00                           6.0   \n",
              "2012-10-03 03:00:00                           2.0   \n",
              "2012-10-03 02:00:00                           1.0   \n",
              "2012-10-03 01:00:00                           4.0   \n",
              "2012-10-03 00:00:00                           4.0   \n",
              "\n",
              "                     Fremont Bridge West Sidewalk  \n",
              "Date                                               \n",
              "2019-04-30 23:00:00                          16.0  \n",
              "2019-04-30 22:00:00                          29.0  \n",
              "2019-04-30 21:00:00                          54.0  \n",
              "2019-04-30 20:00:00                          91.0  \n",
              "2019-04-30 19:00:00                         175.0  \n",
              "2019-04-30 18:00:00                         371.0  \n",
              "2019-04-30 17:00:00                         587.0  \n",
              "2019-04-30 16:00:00                         346.0  \n",
              "2019-04-30 15:00:00                         113.0  \n",
              "2019-04-30 14:00:00                          88.0  \n",
              "2019-04-30 13:00:00                          78.0  \n",
              "2019-04-30 12:00:00                          47.0  \n",
              "2019-04-30 11:00:00                          53.0  \n",
              "2019-04-30 10:00:00                          74.0  \n",
              "2019-04-30 09:00:00                         195.0  \n",
              "2019-04-30 08:00:00                         399.0  \n",
              "2019-04-30 07:00:00                         254.0  \n",
              "2019-04-30 06:00:00                          82.0  \n",
              "2019-04-30 05:00:00                          21.0  \n",
              "2019-04-30 04:00:00                           3.0  \n",
              "2019-04-30 03:00:00                           2.0  \n",
              "2019-04-30 02:00:00                           0.0  \n",
              "2019-04-30 01:00:00                           2.0  \n",
              "2019-04-30 00:00:00                           4.0  \n",
              "2019-04-29 23:00:00                          12.0  \n",
              "2019-04-29 22:00:00                          10.0  \n",
              "2019-04-29 21:00:00                          26.0  \n",
              "2019-04-29 20:00:00                          54.0  \n",
              "2019-04-29 19:00:00                         158.0  \n",
              "2019-04-29 18:00:00                         349.0  \n",
              "...                                           ...  \n",
              "2012-10-04 05:00:00                          11.0  \n",
              "2012-10-04 04:00:00                           1.0  \n",
              "2012-10-04 03:00:00                           3.0  \n",
              "2012-10-04 02:00:00                           6.0  \n",
              "2012-10-04 01:00:00                           0.0  \n",
              "2012-10-04 00:00:00                          11.0  \n",
              "2012-10-03 23:00:00                          12.0  \n",
              "2012-10-03 22:00:00                          25.0  \n",
              "2012-10-03 21:00:00                          38.0  \n",
              "2012-10-03 20:00:00                          51.0  \n",
              "2012-10-03 19:00:00                          69.0  \n",
              "2012-10-03 18:00:00                         258.0  \n",
              "2012-10-03 17:00:00                         391.0  \n",
              "2012-10-03 16:00:00                         182.0  \n",
              "2012-10-03 15:00:00                          92.0  \n",
              "2012-10-03 14:00:00                          51.0  \n",
              "2012-10-03 13:00:00                          48.0  \n",
              "2012-10-03 12:00:00                          41.0  \n",
              "2012-10-03 11:00:00                          32.0  \n",
              "2012-10-03 10:00:00                          46.0  \n",
              "2012-10-03 09:00:00                         104.0  \n",
              "2012-10-03 08:00:00                         146.0  \n",
              "2012-10-03 07:00:00                          95.0  \n",
              "2012-10-03 06:00:00                          50.0  \n",
              "2012-10-03 05:00:00                          10.0  \n",
              "2012-10-03 04:00:00                           1.0  \n",
              "2012-10-03 03:00:00                           3.0  \n",
              "2012-10-03 02:00:00                           1.0  \n",
              "2012-10-03 01:00:00                           6.0  \n",
              "2012-10-03 00:00:00                           9.0  \n",
              "\n",
              "[57624 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VVB3g4704An5"
      },
      "source": [
        "### First fast look at the data\n",
        "- What's the shape?\n",
        "- What's the date range?\n",
        "- What's the target and the features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t50E2fTUWBBU",
        "outputId": "2a4ed3ce-a23a-400e-ec94-62855c4c5a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "daily.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1063, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28tkkRDk9rX_",
        "colab_type": "code",
        "outputId": "9d5a6cc2-6bb8-43e9-aa46-7da722201797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "print(daily.iloc[0])\n",
        "daily.iloc[1062]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total              3475.0\n",
            "PRCP                  0.0\n",
            "SNOW                  0.0\n",
            "SNWD                  0.0\n",
            "TMAX                189.0\n",
            "TMIN                 83.0\n",
            "AWND                 65.0\n",
            "Total_yesterday    3521.0\n",
            "Name: 2012-10-04 00:00:00, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Total              2876.0\n",
              "PRCP                 58.0\n",
              "SNOW                  0.0\n",
              "SNWD                  0.0\n",
              "TMAX                194.0\n",
              "TMIN                139.0\n",
              "AWND              -9999.0\n",
              "Total_yesterday    2823.0\n",
              "Name: 2015-09-01 00:00:00, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvLC7ZiL-NS_",
        "colab_type": "code",
        "outputId": "6d7c3b15-f9d1-4a71-9fc9-0a790fab3db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "daily.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>3475.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>83</td>\n",
              "      <td>65</td>\n",
              "      <td>3521.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>3148.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>217</td>\n",
              "      <td>89</td>\n",
              "      <td>57</td>\n",
              "      <td>3475.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>2006.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>51</td>\n",
              "      <td>3148.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>2142.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>13</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>3537.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211</td>\n",
              "      <td>78</td>\n",
              "      <td>19</td>\n",
              "      <td>2142.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2012-10-04  3475.0     0     0     0   189    83    65           3521.0\n",
              "2012-10-05  3148.0     0     0     0   217    89    57           3475.0\n",
              "2012-10-06  2006.0     0     0     0   239    78    51           3148.0\n",
              "2012-10-07  2142.0     0     0     0   239    78    13           2006.0\n",
              "2012-10-08  3537.0     0     0     0   211    78    19           2142.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XgMvCsaWJR7Q"
      },
      "source": [
        "Target\n",
        "- Total : Daily total number of bicycle trips across Seattle's Fremont Bridge\n",
        "\n",
        "Features\n",
        "- Date (index) : from 2012-10-04 to 2015-09-01\n",
        "- Total_yesterday : Total trips yesterday\n",
        "- PRCP : Precipitation (1/10 mm)\n",
        "- SNOW : Snowfall (1/10 mm)\n",
        "- SNWD : Snow depth (1/10 mm)\n",
        "- TMAX : Maximum temperature (1/10 Celsius)\n",
        "- TMIN : Minimum temperature (1/10 Celsius)\n",
        "- AWND : Average daily wind speed (1/10 meters per second)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lenL-przSYCo"
      },
      "source": [
        "## 2. Choose how you’ll measure success on your problem.\n",
        "\n",
        "Which metrics will you monitor on your validation data?\n",
        "\n",
        "This is a regression problem, so we need to choose a regression [metric](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
        "\n",
        "\n",
        "\n",
        "I'll choose mean absolute error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1TqbomapSyRP",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IRHrB3rsS5hF"
      },
      "source": [
        "## 3. Determine your evaluation protocol \n",
        "\n",
        "We're doing model selection, hyperparameter optimization, and performance estimation. So generally we have two ideal [options](https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg) to choose from:\n",
        "\n",
        "- 3-way holdout method (train/validation/test split)\n",
        "- Cross-validation with independent test set\n",
        "\n",
        "I'll choose cross-validation with independent test set. Scikit-learn makes cross-validation convenient for us!\n",
        "\n",
        "Specifically, I will use random shuffled cross validation to train and validate, but I will hold out an \"out-of-time\" test set, from the last 100 days of data:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A3xo6HgbPMFm",
        "colab": {}
      },
      "source": [
        "train = daily[:-100]\n",
        "test = daily[-100:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZK0i1XkAu11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train.drop(columns='Total')\n",
        "y_train = train['Total']\n",
        "\n",
        "X_test = test.drop(columns='Total')\n",
        "y_test = test['Total']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vH6IsORQTvTU"
      },
      "source": [
        "## 4. Develop a first model that does better than a basic baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DJBs2nQkj7oB"
      },
      "source": [
        "### Look at the target's distribution and descriptive stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P5peakv9Zs71",
        "outputId": "139a718b-e216-42b4-e1fd-a52a4d922eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.distplot(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa0fca9c550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUCoUIiIS1P8Hd41s336jLrkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fEjxxgV9kExY"
      },
      "source": [
        "### Basic baseline 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6GepKdQjYcEP",
        "outputId": "5c3f1995-02cc-48c8-b950-a12bd7f11fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = [y_train.median()] *len(y_train)\n",
        "mean_absolute_error(y_train,y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "971.9376947040498"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tN2I_F3FkIHb"
      },
      "source": [
        "### Basic baseline 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZW8bhZFtTunV",
        "outputId": "cada0084-f12f-422f-9280-398b87444e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = X_train['Total_yesterday']\n",
        "mean_absolute_error(y_train,y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "708.061266874351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ggf3VpxwkJ0T"
      },
      "source": [
        "### First model that does better than a basic baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KfaqL1Ezer2-"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OeBtU68skfW-",
        "outputId": "8145322c-eb49-42ba-a3d6-850bd659da47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "scores = cross_validate(LinearRegression(), X_train, y_train, \n",
        "                        scoring='neg_mean_absolute_error', cv=3, \n",
        "                        return_train_score=True, return_estimator=True)\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.009171</td>\n",
              "      <td>0.001542</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-555.186275</td>\n",
              "      <td>-619.509206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.002802</td>\n",
              "      <td>0.001158</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-651.126513</td>\n",
              "      <td>-583.427702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002661</td>\n",
              "      <td>0.001158</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-615.965800</td>\n",
              "      <td>-589.341301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.009171    0.001542  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "1  0.002802    0.001158  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "2  0.002661    0.001158  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -555.186275  -619.509206  \n",
              "1 -651.126513  -583.427702  \n",
              "2 -615.965800  -589.341301  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x81OScf-E-6U",
        "colab_type": "code",
        "outputId": "c69dba32-f32d-4aea-ec5e-99f202b02188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "-scores['test_score'].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "607.4261958631806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5OQD20dFi3Z",
        "colab_type": "code",
        "outputId": "127288a6-d92e-4e30-f152-cf25ec7ff20c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "for i, model in enumerate(scores['estimator']):\n",
        "  coefficients = model.coef_\n",
        "  intercept = model.intercept_\n",
        "  feature_names = X_train.columns\n",
        "  print(f'Model from cross_validation fold #{i}')\n",
        "  print('Intercept', intercept)\n",
        "  print(pd.Series(coefficients, feature_names).to_string())\n",
        "  print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model from cross_validation fold #0\n",
            "Intercept 566.7766337283679\n",
            "PRCP               -3.525103\n",
            "SNOW               -0.082029\n",
            "SNWD              -12.045027\n",
            "TMAX                9.475238\n",
            "TMIN               -4.607775\n",
            "AWND               -2.745191\n",
            "Total_yesterday     0.417360\n",
            "\n",
            "\n",
            "Model from cross_validation fold #1\n",
            "Intercept 671.9064515706045\n",
            "PRCP               -2.772253\n",
            "SNOW               -0.000995\n",
            "SNWD               20.800688\n",
            "TMAX                8.804948\n",
            "TMIN               -3.741386\n",
            "AWND               -6.108300\n",
            "Total_yesterday     0.405074\n",
            "\n",
            "\n",
            "Model from cross_validation fold #2\n",
            "Intercept 465.84525362296563\n",
            "PRCP               -2.876196\n",
            "SNOW               -0.016432\n",
            "SNWD               -8.809696\n",
            "TMAX               10.419441\n",
            "TMIN               -5.862868\n",
            "AWND               -2.398991\n",
            "Total_yesterday     0.423493\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fg1YI4X8n9nI"
      },
      "source": [
        "## 5. Develop a model that overfits. \n",
        "\n",
        "\"The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\" —Chollet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lodd6UPOoy89"
      },
      "source": [
        "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.03-validation-curve.png\">\n",
        "\n",
        "Diagram Source: https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xj82P0VdwYlh"
      },
      "source": [
        "### Random Forest?\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_yYXpk99C4cM",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, max_depth=4, n_jobs=-1)\n",
        "\n",
        "scores = cross_validate(model, X_train,y_train,\n",
        "                       scoring='neg_mean_absolute_error',\n",
        "                       cv=3, return_train_score=True,\n",
        "                       return_estimator=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTKJMCjJKhCV",
        "colab_type": "code",
        "outputId": "da2fd6f2-476a-45b9-cd9a-fd3e8fa7446e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.438840</td>\n",
              "      <td>0.104273</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-553.637523</td>\n",
              "      <td>-568.469010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.141504</td>\n",
              "      <td>0.103155</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-640.802484</td>\n",
              "      <td>-529.983411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.145489</td>\n",
              "      <td>0.103074</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-624.565145</td>\n",
              "      <td>-533.604557</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  1.438840    0.104273  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "1  0.141504    0.103155  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "2  0.145489    0.103074  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -553.637523  -568.469010  \n",
              "1 -640.802484  -529.983411  \n",
              "2 -624.565145  -533.604557  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMCfCRtuK4L6",
        "colab_type": "code",
        "outputId": "afa93bf3-fff2-4bae-95aa-bb7ac3fdf818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "-scores['train_score'].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "544.0189925994404"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X5A9zYPLizV",
        "colab_type": "code",
        "outputId": "4dd6291c-50d2-46ab-e8bc-308d352c74b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "model = XGBRegressor(n_estimators=200)\n",
        "\n",
        "scores = cross_validate(model, X_train,y_train,\n",
        "                       scoring='neg_mean_absolute_error',\n",
        "                       cv=3, return_train_score=True,\n",
        "                       return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.080803</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
              "      <td>-556.460066</td>\n",
              "      <td>-409.202939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.081261</td>\n",
              "      <td>0.003660</td>\n",
              "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
              "      <td>-635.474330</td>\n",
              "      <td>-371.498096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.082506</td>\n",
              "      <td>0.003670</td>\n",
              "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
              "      <td>-654.437817</td>\n",
              "      <td>-369.759112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.080803    0.003795  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
              "1  0.081261    0.003660  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
              "2  0.082506    0.003670  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -556.460066  -409.202939  \n",
              "1 -635.474330  -371.498096  \n",
              "2 -654.437817  -369.759112  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ryO1hVKr-6f"
      },
      "source": [
        "### Validation Curve\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html\n",
        "\n",
        "> Validation curve. Determine training and test scores for varying parameter values. This is similar to grid search with one parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apKk4vKiwgtM",
        "outputId": "23b134eb-8da3-4292-cae3-ade79bf9634d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Modified from cell 13 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100)\n",
        "\n",
        "depth = [2, 3, 4, 5, 6]\n",
        "train_score, val_score = validation_curve(\n",
        "    model, X_train, y_train,\n",
        "    param_name='max_depth', param_range=depth, \n",
        "    scoring='neg_mean_absolute_error', cv=3)\n",
        "\n",
        "plt.plot(depth, np.median(train_score, 1), color='blue', label='training score')\n",
        "plt.plot(depth, np.median(val_score, 1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('depth');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou6argpINeWT",
        "colab_type": "code",
        "outputId": "3831ce14-883d-4985-e28e-edff275d198b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "model = RandomForestRegressor(n_estimators=100)\n",
        "\n",
        "depth = [2, 3, 4, 5, 6]\n",
        "train_score, val_score = validation_curve(\n",
        "    model, X_train, y_train,\n",
        "    param_name='max_depth', param_range=depth, \n",
        "    scoring='neg_mean_absolute_error', cv=3)\n",
        "\n",
        "plt.plot(depth, np.median(train_score, 1), color='blue', label='training score')\n",
        "plt.plot(depth, np.median(val_score, 1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('depth');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DQoMvZ7-yCAQ"
      },
      "source": [
        "### `RandomizedSearchCV`\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/grid_search.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bk_dX_mByKm7",
        "outputId": "d7e3f7d4-2714-4b5b-bbfd-8588f052164f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "param_distributions = {\n",
        "    'n_estimators':[100,200],\n",
        "    'max_depth': [4,5],\n",
        "    'criterion':['mse','mae'],\n",
        "    \n",
        "}\n",
        "\n",
        "gridsearch = RandomizedSearchCV(\n",
        "    RandomForestRegressor(n_jobs=-1, random_state=42),\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=8,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    verbose=10,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "gridsearch.fit(X_train,y_train)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    4.8s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   10.5s\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   14.0s finished\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   14.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=8, n_jobs=-1,\n",
              "          param_distributions={'n_estimators': [100, 200], 'max_depth': [4, 5], 'criterion': ['mse', 'mae']},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o98imXNvR77O",
        "colab_type": "code",
        "outputId": "35af1610-44c1-4816-873a-ae6c3ac05e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "gridsearch.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=5,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFkoLcrGSz1-",
        "colab_type": "code",
        "outputId": "07bf47b6-3b6f-4980-960a-d5ad30729c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        }
      },
      "source": [
        "results = pd.DataFrame(gridsearch.cv_results_)\n",
        "results.sort_values(by='rank_test_score')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.789726</td>\n",
              "      <td>0.409276</td>\n",
              "      <td>0.108001</td>\n",
              "      <td>0.006767</td>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-537.343224</td>\n",
              "      <td>-633.188069</td>\n",
              "      <td>-611.812399</td>\n",
              "      <td>-594.114564</td>\n",
              "      <td>41.080965</td>\n",
              "      <td>1</td>\n",
              "      <td>-514.399139</td>\n",
              "      <td>-476.132208</td>\n",
              "      <td>-486.784755</td>\n",
              "      <td>-492.438701</td>\n",
              "      <td>16.125856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.024991</td>\n",
              "      <td>0.067070</td>\n",
              "      <td>0.107074</td>\n",
              "      <td>0.005207</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-539.744330</td>\n",
              "      <td>-635.247773</td>\n",
              "      <td>-610.870031</td>\n",
              "      <td>-595.287378</td>\n",
              "      <td>40.516179</td>\n",
              "      <td>2</td>\n",
              "      <td>-513.924961</td>\n",
              "      <td>-475.585023</td>\n",
              "      <td>-489.148606</td>\n",
              "      <td>-492.886197</td>\n",
              "      <td>15.873771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.942822</td>\n",
              "      <td>0.023191</td>\n",
              "      <td>0.111283</td>\n",
              "      <td>0.005794</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-545.553738</td>\n",
              "      <td>-635.478629</td>\n",
              "      <td>-609.898505</td>\n",
              "      <td>-596.976957</td>\n",
              "      <td>37.831612</td>\n",
              "      <td>3</td>\n",
              "      <td>-554.610927</td>\n",
              "      <td>-515.603583</td>\n",
              "      <td>-525.162173</td>\n",
              "      <td>-531.792227</td>\n",
              "      <td>16.600431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.835187</td>\n",
              "      <td>0.072470</td>\n",
              "      <td>0.116574</td>\n",
              "      <td>0.003918</td>\n",
              "      <td>200</td>\n",
              "      <td>4</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-545.615950</td>\n",
              "      <td>-634.226674</td>\n",
              "      <td>-611.571316</td>\n",
              "      <td>-597.137980</td>\n",
              "      <td>37.587285</td>\n",
              "      <td>4</td>\n",
              "      <td>-554.012714</td>\n",
              "      <td>-515.754478</td>\n",
              "      <td>-524.948497</td>\n",
              "      <td>-531.571896</td>\n",
              "      <td>16.305934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.398206</td>\n",
              "      <td>0.041301</td>\n",
              "      <td>0.105335</td>\n",
              "      <td>0.001793</td>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-545.774354</td>\n",
              "      <td>-637.307005</td>\n",
              "      <td>-627.616934</td>\n",
              "      <td>-603.566098</td>\n",
              "      <td>41.055966</td>\n",
              "      <td>5</td>\n",
              "      <td>-524.163469</td>\n",
              "      <td>-490.204130</td>\n",
              "      <td>-490.472466</td>\n",
              "      <td>-501.613355</td>\n",
              "      <td>15.945715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.271920</td>\n",
              "      <td>0.002575</td>\n",
              "      <td>0.103942</td>\n",
              "      <td>0.000612</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-546.995243</td>\n",
              "      <td>-639.080607</td>\n",
              "      <td>-629.837818</td>\n",
              "      <td>-605.304556</td>\n",
              "      <td>41.403214</td>\n",
              "      <td>6</td>\n",
              "      <td>-526.882336</td>\n",
              "      <td>-490.560190</td>\n",
              "      <td>-492.252512</td>\n",
              "      <td>-503.231679</td>\n",
              "      <td>16.737805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.365530</td>\n",
              "      <td>0.036394</td>\n",
              "      <td>0.103579</td>\n",
              "      <td>0.000474</td>\n",
              "      <td>200</td>\n",
              "      <td>4</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-555.634757</td>\n",
              "      <td>-640.866167</td>\n",
              "      <td>-625.853913</td>\n",
              "      <td>-607.451613</td>\n",
              "      <td>37.149085</td>\n",
              "      <td>7</td>\n",
              "      <td>-572.252550</td>\n",
              "      <td>-529.625674</td>\n",
              "      <td>-536.655286</td>\n",
              "      <td>-546.177836</td>\n",
              "      <td>18.659615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.276537</td>\n",
              "      <td>0.004941</td>\n",
              "      <td>0.104220</td>\n",
              "      <td>0.001232</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-557.174302</td>\n",
              "      <td>-642.450417</td>\n",
              "      <td>-629.072181</td>\n",
              "      <td>-609.565633</td>\n",
              "      <td>37.446700</td>\n",
              "      <td>8</td>\n",
              "      <td>-574.472102</td>\n",
              "      <td>-530.248079</td>\n",
              "      <td>-538.576526</td>\n",
              "      <td>-547.765569</td>\n",
              "      <td>19.188016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "7       1.789726      0.409276         0.108001        0.006767   \n",
              "6       1.024991      0.067070         0.107074        0.005207   \n",
              "4       0.942822      0.023191         0.111283        0.005794   \n",
              "5       1.835187      0.072470         0.116574        0.003918   \n",
              "3       0.398206      0.041301         0.105335        0.001793   \n",
              "2       0.271920      0.002575         0.103942        0.000612   \n",
              "1       0.365530      0.036394         0.103579        0.000474   \n",
              "0       0.276537      0.004941         0.104220        0.001232   \n",
              "\n",
              "  param_n_estimators param_max_depth param_criterion  \\\n",
              "7                200               5             mae   \n",
              "6                100               5             mae   \n",
              "4                100               4             mae   \n",
              "5                200               4             mae   \n",
              "3                200               5             mse   \n",
              "2                100               5             mse   \n",
              "1                200               4             mse   \n",
              "0                100               4             mse   \n",
              "\n",
              "                                              params  split0_test_score  \\\n",
              "7  {'n_estimators': 200, 'max_depth': 5, 'criteri...        -537.343224   \n",
              "6  {'n_estimators': 100, 'max_depth': 5, 'criteri...        -539.744330   \n",
              "4  {'n_estimators': 100, 'max_depth': 4, 'criteri...        -545.553738   \n",
              "5  {'n_estimators': 200, 'max_depth': 4, 'criteri...        -545.615950   \n",
              "3  {'n_estimators': 200, 'max_depth': 5, 'criteri...        -545.774354   \n",
              "2  {'n_estimators': 100, 'max_depth': 5, 'criteri...        -546.995243   \n",
              "1  {'n_estimators': 200, 'max_depth': 4, 'criteri...        -555.634757   \n",
              "0  {'n_estimators': 100, 'max_depth': 4, 'criteri...        -557.174302   \n",
              "\n",
              "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "7        -633.188069        -611.812399      -594.114564       41.080965   \n",
              "6        -635.247773        -610.870031      -595.287378       40.516179   \n",
              "4        -635.478629        -609.898505      -596.976957       37.831612   \n",
              "5        -634.226674        -611.571316      -597.137980       37.587285   \n",
              "3        -637.307005        -627.616934      -603.566098       41.055966   \n",
              "2        -639.080607        -629.837818      -605.304556       41.403214   \n",
              "1        -640.866167        -625.853913      -607.451613       37.149085   \n",
              "0        -642.450417        -629.072181      -609.565633       37.446700   \n",
              "\n",
              "   rank_test_score  split0_train_score  split1_train_score  \\\n",
              "7                1         -514.399139         -476.132208   \n",
              "6                2         -513.924961         -475.585023   \n",
              "4                3         -554.610927         -515.603583   \n",
              "5                4         -554.012714         -515.754478   \n",
              "3                5         -524.163469         -490.204130   \n",
              "2                6         -526.882336         -490.560190   \n",
              "1                7         -572.252550         -529.625674   \n",
              "0                8         -574.472102         -530.248079   \n",
              "\n",
              "   split2_train_score  mean_train_score  std_train_score  \n",
              "7         -486.784755       -492.438701        16.125856  \n",
              "6         -489.148606       -492.886197        15.873771  \n",
              "4         -525.162173       -531.792227        16.600431  \n",
              "5         -524.948497       -531.571896        16.305934  \n",
              "3         -490.472466       -501.613355        15.945715  \n",
              "2         -492.252512       -503.231679        16.737805  \n",
              "1         -536.655286       -546.177836        18.659615  \n",
              "0         -538.576526       -547.765569        19.188016  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZW5HfYtU0GW2"
      },
      "source": [
        "## FEATURE ENGINEERING!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ms-eoOHFvPG"
      },
      "source": [
        "Jake VanderPlas demonstrates this feature engineering: \n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sEwME8wR3A5g",
        "colab": {}
      },
      "source": [
        "# Modified from code cells 17-21 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "def jake_wrangle(X):  \n",
        "    X = X.copy()\n",
        "\n",
        "    # patterns of use generally vary from day to day; \n",
        "    # let's add binary columns that indicate the day of the week:\n",
        "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "    for i, day in enumerate(days):\n",
        "        X[day] = (X.index.dayofweek == i).astype(float)\n",
        "\n",
        "\n",
        "    # we might expect riders to behave differently on holidays; \n",
        "    # let's add an indicator of this as well:\n",
        "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "    cal = USFederalHolidayCalendar()\n",
        "    holidays = cal.holidays('2012', '2016')\n",
        "    X = X.join(pd.Series(1, index=holidays, name='holiday'))\n",
        "    X['holiday'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "    # We also might suspect that the hours of daylight would affect \n",
        "    # how many people ride; let's use the standard astronomical calculation \n",
        "    # to add this information:\n",
        "    def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
        "        \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
        "        days = (date - pd.datetime(2000, 12, 21)).days\n",
        "        m = (1. - np.tan(np.radians(latitude))\n",
        "             * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
        "        return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
        "\n",
        "    X['daylight_hrs'] = list(map(hours_of_daylight, X.index))\n",
        "\n",
        "    \n",
        "    # temperatures are in 1/10 deg C; convert to C\n",
        "    X['TMIN'] /= 10\n",
        "    X['TMAX'] /= 10\n",
        "    \n",
        "    # We can also calcuate the average temperature.\n",
        "    X['Temp (C)'] = 0.5 * (X['TMIN'] + X['TMAX'])\n",
        "\n",
        "    # precip is in 1/10 mm; convert to inches\n",
        "    X['PRCP'] /= 254\n",
        "\n",
        "    # In addition to the inches of precipitation, let's add a flag that \n",
        "    # indicates whether a day is dry (has zero precipitation):\n",
        "    X['dry day'] = (X['PRCP'] == 0).astype(int)\n",
        "\n",
        "\n",
        "    # Let's add a counter that increases from day 1, and measures how many \n",
        "    # years have passed. This will let us measure any observed annual increase \n",
        "    # or decrease in daily crossings:\n",
        "    X['annual'] = (X.index - X.index[0]).days / 365.\n",
        "\n",
        "    return X\n",
        "\n",
        "X_train = jake_wrangle(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dDGkAv813Wtj"
      },
      "source": [
        "### Linear Regression (with new features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cj3HTM6p5F1A",
        "outputId": "2c88ac34-c0a8-4abb-c5f2-b37180419f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "scores = cross_validate(LinearRegression(), X_train,y_train,\n",
        "                       scoring='neg_mean_absolute_error', cv=3,\n",
        "                       return_train_score=True, return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.011510</td>\n",
              "      <td>0.001682</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-309.384920</td>\n",
              "      <td>-305.714955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.006053</td>\n",
              "      <td>0.001537</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-330.535591</td>\n",
              "      <td>-294.371882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.003810</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-319.122321</td>\n",
              "      <td>-300.638173</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.011510    0.001682  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "1  0.006053    0.001537  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "2  0.003810    0.001465  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -309.384920  -305.714955  \n",
              "1 -330.535591  -294.371882  \n",
              "2 -319.122321  -300.638173  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b6zxN2xB3bX_"
      },
      "source": [
        "### Random Forest (with new features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3sWUDZIz1-kk",
        "outputId": "c1e9bd55-1e52-4193-d713-e8fdbfb362d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "param_distributions={\n",
        "    'n_estimators':[100],\n",
        "    'max_depth':[5,10,15,None],\n",
        "    'criterion':['mae']\n",
        "}\n",
        "\n",
        "gridsearch = RandomizedSearchCV(\n",
        "    RandomForestRegressor(n_jobs=-1, random_state=42),\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=8,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    verbose=10,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "gridsearch.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 4 is smaller than n_iter=8. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   14.8s\n",
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:   18.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=8, n_jobs=-1,\n",
              "          param_distributions={'n_estimators': [100], 'max_depth': [5, 10, 15, None], 'criterion': ['mae']},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKmHxE9FVcdO",
        "colab_type": "code",
        "outputId": "5b347b4b-b838-4bd3-c97f-0649068ac95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "gridsearch.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=10,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzSMg91gVhyr",
        "colab_type": "code",
        "outputId": "fda70fe9-dc96-4207-f8d9-e1e999689dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "pd.DataFrame(gridsearch.cv_results_).sort_values(by='rank_test_score').head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.990987</td>\n",
              "      <td>0.06237</td>\n",
              "      <td>0.118831</td>\n",
              "      <td>0.005135</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 10, 'criter...</td>\n",
              "      <td>-369.520717</td>\n",
              "      <td>-342.040016</td>\n",
              "      <td>-330.346308</td>\n",
              "      <td>-347.302347</td>\n",
              "      <td>16.420062</td>\n",
              "      <td>1</td>\n",
              "      <td>-154.649813</td>\n",
              "      <td>-146.522399</td>\n",
              "      <td>-158.590514</td>\n",
              "      <td>-153.254242</td>\n",
              "      <td>5.024644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "1       2.990987       0.06237         0.118831        0.005135   \n",
              "\n",
              "  param_n_estimators param_max_depth param_criterion  \\\n",
              "1                100              10             mae   \n",
              "\n",
              "                                              params  split0_test_score  \\\n",
              "1  {'n_estimators': 100, 'max_depth': 10, 'criter...        -369.520717   \n",
              "\n",
              "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "1        -342.040016        -330.346308      -347.302347       16.420062   \n",
              "\n",
              "   rank_test_score  split0_train_score  split1_train_score  \\\n",
              "1                1         -154.649813         -146.522399   \n",
              "\n",
              "   split2_train_score  mean_train_score  std_train_score  \n",
              "1         -158.590514       -153.254242         5.024644  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F8RtzEksPwx",
        "colab_type": "text"
      },
      "source": [
        "##Assignment \n",
        "Add more features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8A7730IIrWNN",
        "outputId": "31bf29a3-6061-4ee6-97c5-3d8bd374abf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>holiday</th>\n",
              "      <th>daylight_hrs</th>\n",
              "      <th>Temp (C)</th>\n",
              "      <th>dry day</th>\n",
              "      <th>annual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.014540</td>\n",
              "      <td>3521.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.219142</td>\n",
              "      <td>13.60</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.012751</td>\n",
              "      <td>3475.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.161038</td>\n",
              "      <td>15.30</td>\n",
              "      <td>1</td>\n",
              "      <td>0.002740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011408</td>\n",
              "      <td>3148.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.103056</td>\n",
              "      <td>15.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0.005479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002908</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.045208</td>\n",
              "      <td>15.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0.008219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.004250</td>\n",
              "      <td>2142.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.987503</td>\n",
              "      <td>14.45</td>\n",
              "      <td>1</td>\n",
              "      <td>0.010959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            PRCP  SNOW  SNWD      AWND  Total_yesterday  Mon  Tue  Wed  Thu  \\\n",
              "2012-10-04   0.0     0     0  0.014540           3521.0  0.0  0.0  0.0  1.0   \n",
              "2012-10-05   0.0     0     0  0.012751           3475.0  0.0  0.0  0.0  0.0   \n",
              "2012-10-06   0.0     0     0  0.011408           3148.0  0.0  0.0  0.0  0.0   \n",
              "2012-10-07   0.0     0     0  0.002908           2006.0  0.0  0.0  0.0  0.0   \n",
              "2012-10-08   0.0     0     0  0.004250           2142.0  1.0  0.0  0.0  0.0   \n",
              "\n",
              "            Fri  Sat  Sun  holiday  daylight_hrs  Temp (C)  dry day    annual  \n",
              "2012-10-04  0.0  0.0  0.0      0.0     11.219142     13.60        1  0.000000  \n",
              "2012-10-05  1.0  0.0  0.0      0.0     11.161038     15.30        1  0.002740  \n",
              "2012-10-06  0.0  1.0  0.0      0.0     11.103056     15.85        1  0.005479  \n",
              "2012-10-07  0.0  0.0  1.0      0.0     11.045208     15.85        1  0.008219  \n",
              "2012-10-08  0.0  0.0  0.0      1.0     10.987503     14.45        1  0.010959  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLKpMYkZEb-U",
        "colab_type": "code",
        "outputId": "74630ce9-ef17-458f-f1aa-7ba49b6118e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "import statsmodels.api as sm\n",
        "model = sm.OLS(y_train, X_train.astype('float'))\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  Total   R-squared:                       0.892\n",
            "Model:                            OLS   Adj. R-squared:                  0.890\n",
            "Method:                 Least Squares   F-statistic:                     487.4\n",
            "Date:                Tue, 14 May 2019   Prob (F-statistic):               0.00\n",
            "Time:                        09:38:31   Log-Likelihood:                -7142.0\n",
            "No. Observations:                 963   AIC:                         1.432e+04\n",
            "Df Residuals:                     946   BIC:                         1.440e+04\n",
            "Df Model:                          16                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "===================================================================================\n",
            "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------\n",
            "PRCP             -586.3898     59.466     -9.861      0.000    -703.090    -469.690\n",
            "SNOW                5.8413      4.952      1.180      0.238      -3.878      15.560\n",
            "SNWD               -2.1664      4.889     -0.443      0.658     -11.761       7.428\n",
            "AWND            -1.028e+04   4279.227     -2.402      0.017   -1.87e+04   -1880.430\n",
            "Total_yesterday     0.3236      0.022     14.443      0.000       0.280       0.368\n",
            "Mon               943.6370     91.622     10.299      0.000     763.831    1123.443\n",
            "Tue               520.0218     84.893      6.126      0.000     353.422     686.622\n",
            "Wed               444.6201     85.038      5.229      0.000     277.736     611.504\n",
            "Thu               348.7343     84.951      4.105      0.000     182.021     515.448\n",
            "Fri               126.1192     85.174      1.481      0.139     -41.033     293.272\n",
            "Sat             -1028.2676     86.103    -11.942      0.000   -1197.243    -859.292\n",
            "Sun              -673.8965     91.498     -7.365      0.000    -853.459    -494.334\n",
            "holiday         -1004.3208     82.229    -12.214      0.000   -1165.694    -842.948\n",
            "daylight_hrs       77.4441      8.777      8.823      0.000      60.219      94.669\n",
            "Temp (C)           49.8494      3.820     13.051      0.000      42.353      57.345\n",
            "dry day           429.0753     33.194     12.926      0.000     363.932     494.218\n",
            "annual             47.9486     17.484      2.742      0.006      13.637      82.260\n",
            "==============================================================================\n",
            "Omnibus:                       33.064   Durbin-Watson:                   1.723\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               76.758\n",
            "Skew:                           0.129   Prob(JB):                     2.15e-17\n",
            "Kurtosis:                       4.359   Cond. No.                     9.21e+05\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 9.21e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmf49vDLeQsx",
        "colab_type": "code",
        "outputId": "4d0093e5-416b-416f-feda-52c887c7b523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "X=sm.add_constant(X_train)\n",
        "vif=[variance_inflation_factor(X.values,i) for i in range(len(X.columns))]\n",
        "pd.Series(vif,X.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py:1543: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return 1 - self.ssr/self.centered_tss\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/stats/outliers_influence.py:181: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "const              0.000000\n",
              "PRCP               1.447399\n",
              "SNOW               1.017140\n",
              "SNWD               1.014901\n",
              "TMAX                    inf\n",
              "TMIN                    inf\n",
              "AWND               1.147795\n",
              "Total_yesterday    4.485024\n",
              "Mon                     inf\n",
              "Tue                     inf\n",
              "Wed                     inf\n",
              "Thu                     inf\n",
              "Fri                     inf\n",
              "Sat                     inf\n",
              "Sun                     inf\n",
              "holiday            1.077422\n",
              "daylight_hrs       3.007627\n",
              "Temp (C)                inf\n",
              "dry day            1.837379\n",
              "annual             1.036220\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4tnARvazEej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train['AWND']=X_train['AWND']/10*0.00223694\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq2J9kzhsvNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEsusOIJmgm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3jCP6WPdGj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train=X_train.drop(['TMAX','TMIN'],axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_EMJdNY-nuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train['SNOW']=X_train.SNOW.replace({-9999:0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "edpJ87A8A8sd"
      },
      "source": [
        "\n",
        "### Feature engineering, explained by Francois Chollet\n",
        "\n",
        "> _Feature engineering_ is the process of using your own knowledge about the data and about the machine learning algorithm at hand to make the algorithm work better by applying hardcoded (nonlearned) transformations to the data before it goes into the model. In many cases, it isn’t reasonable to expect a machine-learning model to be able to learn from completely arbitrary data. The data needs to be presented to the model in a way that will make the model’s job easier.\n",
        "\n",
        "> Let’s look at an intuitive example. Suppose you’re trying to develop a model that can take as input an image of a clock and can output the time of day.\n",
        "\n",
        "> If you choose to use the raw pixels of the image as input data, then you have a difficult machine-learning problem on your hands. You’ll need a convolutional neural network to solve it, and you’ll have to expend quite a bit of computational resources to train the network.\n",
        "\n",
        "> But if you already understand the problem at a high level (you understand how humans read time on a clock face), then you can come up with much better input features for a machine-learning algorithm: for instance, write a Python script to follow the black pixels of the clock hands and output the (x, y) coordinates of the tip of each hand. Then a simple machine-learning algorithm can learn to associate these coordinates with the appropriate time of day.\n",
        "\n",
        "> You can go even further: do a coordinate change, and express the (x, y) coordinates as polar coordinates with regard to the center of the image. Your input will become the angle theta of each clock hand. At this point, your features are making the problem so easy that no machine learning is required; a simple rounding operation and dictionary lookup are enough to recover the approximate time of day.\n",
        "\n",
        "> That’s the essence of feature engineering: making a problem easier by expressing it in a simpler way. It usually requires understanding the problem in depth.\n",
        "\n",
        "> Before convolutional neural networks became successful on the MNIST digit-classification problem, solutions were typically based on hardcoded features such as the number of loops in a digit image, the height of each digit in an image, a histogram of pixel values, and so on.\n",
        "\n",
        "> Neural networks are capable of automatically extracting useful features from raw data. Does this mean you don’t have to worry about feature engineering as long as you’re using deep neural networks? No, for two reasons:\n",
        "\n",
        "> - Good features still allow you to solve problems more elegantly while using fewer resources. For instance, it would be ridiculous to solve the problem of reading a clock face using a convolutional neural network.\n",
        "> - Good features let you solve a problem with far less data. The ability of deep-learning models to learn features on their own relies on having lots of training data available; if you have only a few samples, then the information value in their features becomes critical.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oux-dd-5FD6p"
      },
      "source": [
        "# ASSIGNMENT\n",
        "\n",
        "**1.** Complete the notebook cells that were originally commented **`TODO`**. \n",
        "\n",
        "**2.** Then, focus on feature engineering to improve your cross validation scores. Collaborate with your cohort on Slack. You could start with the ideas [Jake VanderPlas suggests:](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic)\n",
        "\n",
        "> Our model is almost certainly missing some relevant information. For example, nonlinear effects (such as effects of precipitation and cold temperature) and nonlinear trends within each variable (such as disinclination to ride at very cold and very hot temperatures) cannot be accounted for in this model. Additionally, we have thrown away some of the finer-grained information (such as the difference between a rainy morning and a rainy afternoon), and we have ignored correlations between days (such as the possible effect of a rainy Tuesday on Wednesday's numbers, or the effect of an unexpected sunny day after a streak of rainy days). These are all potentially interesting effects, and you now have the tools to begin exploring them if you wish!\n",
        "\n",
        "**3.** Experiment with the Categorical Encoding notebook.\n",
        "\n",
        "**4.** At the end of the day, take the last step in the \"universal workflow of machine learning\" — \"You can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\"\n",
        "\n",
        "See the [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) documentation for the `refit` parameter, `best_estimator_` attribute, and `predict` method:\n",
        "\n",
        "> **refit : boolean, or string, default=True**\n",
        "\n",
        "> Refit an estimator using the best found parameters on the whole dataset.\n",
        "\n",
        "> The refitted estimator is made available at the `best_estimator_` attribute and permits using `predict` directly on this `GridSearchCV` instance.\n",
        "\n",
        "### STRETCH\n",
        "\n",
        "**A.** Apply this lesson other datasets you've worked with, like Ames Housing, Bank Marketing, or others.\n",
        "\n",
        "**B.** In additon to `RandomizedSearchCV`, scikit-learn has [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Another library called scikit-optimize has [`BayesSearchCV`](https://scikit-optimize.github.io/notebooks/sklearn-gridsearchcv-replacement.html). Experiment with these alternatives.\n",
        "\n",
        "**C.** _[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)_ discusses options for \"Grid-Searching Which Model To Use\" in Chapter 6:\n",
        "\n",
        "> You can even go further in combining GridSearchCV and Pipeline: it is also possible to search over the actual steps being performed in the pipeline (say whether to use StandardScaler or MinMaxScaler). This leads to an even bigger search space and should be considered carefully. Trying all possible solutions is usually not a viable machine learning strategy. However, here is an example comparing a RandomForestClassifier and an SVC ...\n",
        "\n",
        "The example is shown in [the accompanying notebook](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb), code cells 35-37. Could you apply this concept to your own pipelines?"
      ]
    }
  ]
}