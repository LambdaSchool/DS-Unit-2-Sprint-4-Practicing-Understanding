{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_243_Select_models_and_parameters.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/livjab/DS-Unit-2-Sprint-4-Practicing-Understanding/blob/master/module1-hyperparameter-optimization/LS_DS_241_Hyperparameter_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O67uhlT4MExK"
      },
      "source": [
        "_Lambda School Data Science — Practicing & Understanding Predictive Modeling_\n",
        "\n",
        "# Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VE4rfZd4NUGA"
      },
      "source": [
        "Today we'll use this process:\n",
        "\n",
        "## \"A universal workflow of machine learning\"\n",
        "\n",
        "_Excerpt from Francois Chollet, [Deep Learning with Python](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/README.md), Chapter 4: Fundamentals of machine learning_\n",
        " \n",
        "**1. Define the problem at hand and the data on which you’ll train.** Collect this data, or annotate it with labels if need be.\n",
        "\n",
        "**2. Choose how you’ll measure success on your problem.** Which metrics will you monitor on your validation data?\n",
        "\n",
        "**3. Determine your evaluation protocol:** hold-out validation? K-fold validation? Which portion of the data should you use for validation?\n",
        "\n",
        "**4. Develop a first model that does better than a basic baseline:** a model with statistical power.\n",
        "\n",
        "**5. Develop a model that overfits.** The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
        "\n",
        "**6. Regularize your model and tune its hyperparameters, based on performance on the validation data.** Repeatedly modify your model, train it, evaluate on your validation data (not the test data, at this point), modify it again, and repeat, until the model is as good as it can get. \n",
        "\n",
        "**Iterate on feature engineering: add new features, or remove features that don’t seem to be informative.** \n",
        "\n",
        "Once you’ve developed a satisfactory model configuration, you can **train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3kt6bzEcOIaa"
      },
      "source": [
        "## 1. Define the problem at hand and the data on which you'll train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "di16k7vpRg67"
      },
      "source": [
        "We'll apply the workflow to a [project from _Python Data Science Handbook_](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic) by Jake VanderPlas:\n",
        "\n",
        "> **Predicting Bicycle Traffic**\n",
        "\n",
        "> As an example, let's take a look at whether we can predict the number of bicycle trips across Seattle's Fremont Bridge based on weather, season, and other factors.\n",
        "\n",
        "> We will join the bike data with another dataset, and try to determine the extent to which weather and seasonal factors—temperature, precipitation, and daylight hours—affect the volume of bicycle traffic through this corridor. Fortunately, the NOAA makes available their daily [weather station data](http://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND) (I used station ID USW00024233) and we can easily use Pandas to join the two data sources.\n",
        "\n",
        "> Let's start by loading the two datasets, indexing by date:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "19dpb_d0R1A6"
      },
      "source": [
        "So this is a regression problem, not a classification problem. We'll define the target, choose an evaluation metric, and choose models that are appropriate for regression problems.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "os1zruXQ30KM"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5XVu-HSeMDtV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3babfb8b-bd49-4564-da5a-d856fd2eb6c8"
      },
      "source": [
        "!curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1616k    0 1616k    0     0   802k      0 --:--:--  0:00:02 --:--:--  803k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sih_7mTzMdfr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "266974ee-27f3-43cc-e7cd-328902bd11d1"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-13 16:08:26--  https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 234945 (229K) [text/plain]\n",
            "Saving to: ‘BicycleWeather.csv’\n",
            "\n",
            "\rBicycleWeather.csv    0%[                    ]       0  --.-KB/s               \rBicycleWeather.csv  100%[===================>] 229.44K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-05-13 16:08:26 (7.92 MB/s) - ‘BicycleWeather.csv’ saved [234945/234945]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9GYm74kD34OQ"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BfQ7gE28MNdF",
        "colab": {}
      },
      "source": [
        "# Modified from cells 15, 16, and 20, at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Download and join data into a dataframe\n",
        "def load(): \n",
        "    fremont_bridge = 'https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD'\n",
        "    \n",
        "    bicycle_weather = 'https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv'\n",
        "\n",
        "    counts = pd.read_csv(fremont_bridge, index_col='Date', parse_dates=True, \n",
        "                         infer_datetime_format=True)\n",
        "\n",
        "    weather = pd.read_csv(bicycle_weather, index_col='DATE', parse_dates=True, \n",
        "                          infer_datetime_format=True)\n",
        "\n",
        "    daily = counts.resample('d').sum()\n",
        "    daily['Total'] = daily.sum(axis=1)\n",
        "    daily = daily[['Total']] # remove other columns\n",
        "\n",
        "    weather_columns = ['PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND']\n",
        "    daily = daily.join(weather[weather_columns], how='inner')\n",
        "    \n",
        "    # Make a feature for yesterday's total\n",
        "    daily['Total_yesterday'] = daily.Total.shift(1)\n",
        "    daily = daily.drop(index=daily.index[0])\n",
        "    \n",
        "    return daily\n",
        "\n",
        "daily = load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VVB3g4704An5"
      },
      "source": [
        "### First fast look at the data\n",
        "- What's the shape?\n",
        "- What's the date range?\n",
        "- What's the target and the features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t50E2fTUWBBU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d145a509-1758-4829-fe54-5f49a7fa6be1"
      },
      "source": [
        "# TODO\n",
        "\n",
        "daily.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1063, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_7SR2sr9psF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "cafa95a6-878a-4bee-aaaf-011c37f7d894"
      },
      "source": [
        "daily.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>3475.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>83</td>\n",
              "      <td>65</td>\n",
              "      <td>3521.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>3148.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>217</td>\n",
              "      <td>89</td>\n",
              "      <td>57</td>\n",
              "      <td>3475.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>2006.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>51</td>\n",
              "      <td>3148.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>2142.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>13</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>3537.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211</td>\n",
              "      <td>78</td>\n",
              "      <td>19</td>\n",
              "      <td>2142.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2012-10-04  3475.0     0     0     0   189    83    65           3521.0\n",
              "2012-10-05  3148.0     0     0     0   217    89    57           3475.0\n",
              "2012-10-06  2006.0     0     0     0   239    78    51           3148.0\n",
              "2012-10-07  2142.0     0     0     0   239    78    13           2006.0\n",
              "2012-10-08  3537.0     0     0     0   211    78    19           2142.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJCk1dLK9t6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "7865e729-5a3e-4a1c-bb27-29bb64a93b48"
      },
      "source": [
        "daily.tail()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-08-28</th>\n",
              "      <td>2653.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>233</td>\n",
              "      <td>156</td>\n",
              "      <td>26</td>\n",
              "      <td>4336.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-29</th>\n",
              "      <td>699.0</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>222</td>\n",
              "      <td>133</td>\n",
              "      <td>58</td>\n",
              "      <td>2653.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-30</th>\n",
              "      <td>1213.0</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>128</td>\n",
              "      <td>47</td>\n",
              "      <td>699.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-31</th>\n",
              "      <td>2823.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>161</td>\n",
              "      <td>58</td>\n",
              "      <td>1213.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-01</th>\n",
              "      <td>2876.0</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>194</td>\n",
              "      <td>139</td>\n",
              "      <td>-9999</td>\n",
              "      <td>2823.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2015-08-28  2653.0     5     0     0   233   156    26           4336.0\n",
              "2015-08-29   699.0   325     0     0   222   133    58           2653.0\n",
              "2015-08-30  1213.0   102     0     0   200   128    47            699.0\n",
              "2015-08-31  2823.0     0     0     0   189   161    58           1213.0\n",
              "2015-09-01  2876.0    58     0     0   194   139 -9999           2823.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XgMvCsaWJR7Q"
      },
      "source": [
        "Target\n",
        "- Total : Daily total number of bicycle trips across Seattle's Fremont Bridge\n",
        "\n",
        "Features\n",
        "- Date (index) : from 2012-10-04 to 2015-09-01\n",
        "- Total_yesterday : Total trips yesterday\n",
        "- PRCP : Precipitation (1/10 mm)\n",
        "- SNOW : Snowfall (1/10 mm)\n",
        "- SNWD : Snow depth (1/10 mm)\n",
        "- TMAX : Maximum temperature (1/10 Celsius)\n",
        "- TMIN : Minimum temperature (1/10 Celsius)\n",
        "- AWND : Average daily wind speed (1/10 meters per second)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lenL-przSYCo"
      },
      "source": [
        "## 2. Choose how you’ll measure success on your problem.\n",
        "\n",
        "Which metrics will you monitor on your validation data?\n",
        "\n",
        "This is a regression problem, so we need to choose a regression [metric](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
        "\n",
        "\n",
        "\n",
        "I'll choose mean absolute error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1TqbomapSyRP",
        "colab": {}
      },
      "source": [
        "# TODO\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IRHrB3rsS5hF"
      },
      "source": [
        "## 3. Determine your evaluation protocol \n",
        "\n",
        "We're doing model selection, hyperparameter optimization, and performance estimation. So generally we have two ideal [options](https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg) to choose from:\n",
        "\n",
        "- 3-way holdout method (train/validation/test split)\n",
        "- Cross-validation with independent test set\n",
        "\n",
        "I'll choose cross-validation with independent test set. Scikit-learn makes cross-validation convenient for us!\n",
        "\n",
        "Specifically, I will use random shuffled cross validation to train and validate, but I will hold out an \"out-of-time\" test set, from the last 100 days of data:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A3xo6HgbPMFm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0448b56b-8d18-4fed-852d-c7ba90efd165"
      },
      "source": [
        "# TODO\n",
        "\n",
        "test = daily[-100:]\n",
        "train = daily[:-100]\n",
        "train.shape, test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((963, 8), (100, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89ObSMlVAImz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train.drop(columns=\"Total\")\n",
        "y_train = train[\"Total\"]\n",
        "\n",
        "X_test = test.drop(columns=\"Total\")\n",
        "y_test = test[\"Total\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfWdNJIYAXBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "936734ae-0932-4027-c7a0-6a0eee374828"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((963, 7), (963,), (100, 7), (100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vH6IsORQTvTU"
      },
      "source": [
        "## 4. Develop a first model that does better than a basic baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DJBs2nQkj7oB"
      },
      "source": [
        "### Look at the target's distribution and descriptive stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P5peakv9Zs71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "95edc245-dab0-4ce7-f836-5663ec9fe104"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.distplot(y_train);"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUCoUIiIS1P8Hd41s336jLrkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaZ0hF6hAwk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "c320e46f-a66d-4a84-dd78-d5fbd18be2b7"
      },
      "source": [
        "y_train.describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     963.000000\n",
              "mean     2534.329180\n",
              "std      1224.065027\n",
              "min        98.000000\n",
              "25%      1755.000000\n",
              "50%      2381.000000\n",
              "75%      3317.500000\n",
              "max      6088.000000\n",
              "Name: Total, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fEjxxgV9kExY"
      },
      "source": [
        "### Basic baseline 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6GepKdQjYcEP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b576f094-184e-4db5-9755-04c73f48d93c"
      },
      "source": [
        "y_pred = [y_train.median()] * len(y_train)\n",
        "mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "971.9376947040498"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tN2I_F3FkIHb"
      },
      "source": [
        "### Basic baseline 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZW8bhZFtTunV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cb0e784-161b-4426-ef9c-6cf4da33a579"
      },
      "source": [
        "y_pred = X_train[\"Total_yesterday\"]\n",
        "mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "708.061266874351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ggf3VpxwkJ0T"
      },
      "source": [
        "### First model that does better than a basic baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KfaqL1Ezer2-"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OeBtU68skfW-",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "scores = cross_validate(LinearRegression(), \n",
        "                        X_train, \n",
        "                        y_train, \n",
        "                        scoring=\"neg_mean_absolute_error\",\n",
        "                        cv=3, \n",
        "                        return_train_score=True, \n",
        "                        return_estimator=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiuuAsgiELIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "4c7bced9-03a8-4ba9-b4da-08e54a72a785"
      },
      "source": [
        "pd.DataFrame(scores)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.029605</td>\n",
              "      <td>0.001853</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-555.186275</td>\n",
              "      <td>-619.509206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003031</td>\n",
              "      <td>0.001298</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-651.126513</td>\n",
              "      <td>-583.427702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002951</td>\n",
              "      <td>0.001262</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-615.965800</td>\n",
              "      <td>-589.341301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.029605    0.001853  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "1  0.003031    0.001298  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "2  0.002951    0.001262  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -555.186275  -619.509206  \n",
              "1 -651.126513  -583.427702  \n",
              "2 -615.965800  -589.341301  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgszx5QSE-x8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ec03f38-5a77-4496-bbac-381461679d38"
      },
      "source": [
        "scores[\"test_score\"].mean()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-607.4261958631806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1G0yme1FUKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e2db94c4-0d3a-4166-e262-c8d7fc0d3a12"
      },
      "source": [
        "scores[\"estimator\"][0].coef_"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -3.52510306,  -0.08202866, -12.04502742,   9.4752378 ,\n",
              "        -4.6077746 ,  -2.74519066,   0.41736022])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NknzuAxFh2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "267ea15a-494a-41fe-e55d-a42d65407b53"
      },
      "source": [
        "for i, model in enumerate(scores[\"estimator\"]):\n",
        "  coefficients = model.coef_\n",
        "  intercept = model.intercept_\n",
        "  feature_names = X_train.columns\n",
        "  \n",
        "  print(f'Model from cross-validation fols #{i}')\n",
        "  print(\"Intercept\", intercept)\n",
        "  print(pd.Series(coefficients, feature_names).to_string())\n",
        "  print('\\n')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model from cross-validation fols #0\n",
            "Intercept 566.7766337283679\n",
            "PRCP               -3.525103\n",
            "SNOW               -0.082029\n",
            "SNWD              -12.045027\n",
            "TMAX                9.475238\n",
            "TMIN               -4.607775\n",
            "AWND               -2.745191\n",
            "Total_yesterday     0.417360\n",
            "\n",
            "\n",
            "Model from cross-validation fols #1\n",
            "Intercept 671.9064515706045\n",
            "PRCP               -2.772253\n",
            "SNOW               -0.000995\n",
            "SNWD               20.800688\n",
            "TMAX                8.804948\n",
            "TMIN               -3.741386\n",
            "AWND               -6.108300\n",
            "Total_yesterday     0.405074\n",
            "\n",
            "\n",
            "Model from cross-validation fols #2\n",
            "Intercept 465.84525362296563\n",
            "PRCP               -2.876196\n",
            "SNOW               -0.016432\n",
            "SNWD               -8.809696\n",
            "TMAX               10.419441\n",
            "TMIN               -5.862868\n",
            "AWND               -2.398991\n",
            "Total_yesterday     0.423493\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fg1YI4X8n9nI"
      },
      "source": [
        "## 5. Develop a model that overfits. \n",
        "\n",
        "\"The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\" —Chollet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lodd6UPOoy89"
      },
      "source": [
        "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.03-validation-curve.png\">\n",
        "\n",
        "Diagram Source: https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xj82P0VdwYlh"
      },
      "source": [
        "### Random Forest?\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_yYXpk99C4cM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "b429a6c2-1c85-496b-e8fb-402fee8ffea9"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, max_depth=None, n_jobs=-1)\n",
        "\n",
        "scores = cross_validate(model, \n",
        "                        X_train, \n",
        "                        y_train, \n",
        "                        scoring=\"neg_mean_absolute_error\", \n",
        "                        cv=3, \n",
        "                        return_train_score=True, \n",
        "                        return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.934788</td>\n",
              "      <td>0.110633</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-555.723489</td>\n",
              "      <td>-242.541153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.247864</td>\n",
              "      <td>0.103744</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-636.544330</td>\n",
              "      <td>-224.631713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.240312</td>\n",
              "      <td>0.103894</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-641.955888</td>\n",
              "      <td>-223.761059</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  1.934788    0.110633  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "1  0.247864    0.103744  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "2  0.240312    0.103894  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -555.723489  -242.541153  \n",
              "1 -636.544330  -224.631713  \n",
              "2 -641.955888  -223.761059  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl0fikO_KVrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fda70f37-fe48-442e-991a-1210d67abc24"
      },
      "source": [
        "scores[\"test_score\"].mean()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-611.4079023883696"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ryO1hVKr-6f"
      },
      "source": [
        "### Validation Curve\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html\n",
        "\n",
        "> Validation curve. Determine training and test scores for varying parameter values. This is similar to grid search with one parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU_a2qKBMSQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apKk4vKiwgtM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "1b475b39-f00c-4168-94e7-3fd2ed607e88"
      },
      "source": [
        "# Modified from cell 13 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100)\n",
        "\n",
        "depth = [2, 3, 4, 5, 6]\n",
        "train_score, val_score = validation_curve(\n",
        "    model, X_train, y_train,\n",
        "    param_name='max_depth', param_range=depth, \n",
        "    scoring='neg_mean_absolute_error', cv=3)\n",
        "\n",
        "plt.plot(depth, np.median(train_score, 1), color='blue', label='training score')\n",
        "plt.plot(depth, np.median(val_score, 1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('depth');"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DQoMvZ7-yCAQ"
      },
      "source": [
        "### `RandomizedSearchCV`\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/grid_search.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bk_dX_mByKm7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1296
        },
        "outputId": "889a99ca-fafc-4264-ce7e-94b407380cbe"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distributions = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [4, 5],\n",
        "    \"criterion\": [\"mse\", \"mae\"]\n",
        "}\n",
        "\n",
        "gridsearch = RandomizedSearchCV(\n",
        "    RandomForestRegressor(n_jobs=-1, random_state=42),\n",
        "    param_distributions=param_distributions, \n",
        "    n_iter=8, \n",
        "    cv=3, scoring=\"neg_mean_absolute_error\", \n",
        "    verbose=10, \n",
        "    return_train_score=True)\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "[CV] n_estimators=100, max_depth=4, criterion=mse ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=4, criterion=mse, score=-557.1743021370869, total=   1.5s\n",
            "[CV] n_estimators=100, max_depth=4, criterion=mse ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=4, criterion=mse, score=-642.4504167086614, total=   0.3s\n",
            "[CV] n_estimators=100, max_depth=4, criterion=mse ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=4, criterion=mse, score=-629.0721811500209, total=   0.2s\n",
            "[CV] n_estimators=200, max_depth=4, criterion=mse ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=200, max_depth=4, criterion=mse, score=-555.6347573401181, total=   0.4s\n",
            "[CV] n_estimators=200, max_depth=4, criterion=mse ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=200, max_depth=4, criterion=mse, score=-640.8661669345674, total=   0.4s\n",
            "[CV] n_estimators=200, max_depth=4, criterion=mse ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=200, max_depth=4, criterion=mse, score=-625.8539134711979, total=   0.4s\n",
            "[CV] n_estimators=100, max_depth=5, criterion=mse ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    3.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=5, criterion=mse, score=-546.9952434097576, total=   0.3s\n",
            "[CV] n_estimators=100, max_depth=5, criterion=mse ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    4.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=5, criterion=mse, score=-639.080606571682, total=   0.3s\n",
            "[CV] n_estimators=100, max_depth=5, criterion=mse ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    4.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=5, criterion=mse, score=-629.8378176759683, total=   0.3s\n",
            "[CV] n_estimators=200, max_depth=5, criterion=mse ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    4.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=200, max_depth=5, criterion=mse, score=-545.7743543381565, total=   0.4s\n",
            "[CV] n_estimators=200, max_depth=5, criterion=mse ....................\n",
            "[CV]  n_estimators=200, max_depth=5, criterion=mse, score=-637.3070047031199, total=   0.4s\n",
            "[CV] n_estimators=200, max_depth=5, criterion=mse ....................\n",
            "[CV]  n_estimators=200, max_depth=5, criterion=mse, score=-627.6169342065701, total=   0.4s\n",
            "[CV] n_estimators=100, max_depth=4, criterion=mae ....................\n",
            "[CV]  n_estimators=100, max_depth=4, criterion=mae, score=-545.553738317757, total=   0.7s\n",
            "[CV] n_estimators=100, max_depth=4, criterion=mae ....................\n",
            "[CV]  n_estimators=100, max_depth=4, criterion=mae, score=-635.4786292834891, total=   0.7s\n",
            "[CV] n_estimators=100, max_depth=4, criterion=mae ....................\n",
            "[CV]  n_estimators=100, max_depth=4, criterion=mae, score=-609.8985046728972, total=   0.7s\n",
            "[CV] n_estimators=200, max_depth=4, criterion=mae ....................\n",
            "[CV]  n_estimators=200, max_depth=4, criterion=mae, score=-545.6159501557632, total=   1.2s\n",
            "[CV] n_estimators=200, max_depth=4, criterion=mae ....................\n",
            "[CV]  n_estimators=200, max_depth=4, criterion=mae, score=-634.2266744548288, total=   1.2s\n",
            "[CV] n_estimators=200, max_depth=4, criterion=mae ....................\n",
            "[CV]  n_estimators=200, max_depth=4, criterion=mae, score=-611.571316199377, total=   1.2s\n",
            "[CV] n_estimators=100, max_depth=5, criterion=mae ....................\n",
            "[CV]  n_estimators=100, max_depth=5, criterion=mae, score=-539.7443302180685, total=   0.7s\n",
            "[CV] n_estimators=100, max_depth=5, criterion=mae ....................\n",
            "[CV]  n_estimators=100, max_depth=5, criterion=mae, score=-635.2477725856697, total=   0.7s\n",
            "[CV] n_estimators=100, max_depth=5, criterion=mae ....................\n",
            "[CV]  n_estimators=100, max_depth=5, criterion=mae, score=-610.8700311526479, total=   0.7s\n",
            "[CV] n_estimators=200, max_depth=5, criterion=mae ....................\n",
            "[CV]  n_estimators=200, max_depth=5, criterion=mae, score=-537.3432242990654, total=   1.4s\n",
            "[CV] n_estimators=200, max_depth=5, criterion=mae ....................\n",
            "[CV]  n_estimators=200, max_depth=5, criterion=mae, score=-633.1880685358257, total=   1.3s\n",
            "[CV] n_estimators=200, max_depth=5, criterion=mae ....................\n",
            "[CV]  n_estimators=200, max_depth=5, criterion=mae, score=-611.8123987538942, total=   1.3s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   19.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=8, n_jobs=None,\n",
              "          param_distributions={'n_estimators': [100, 200], 'max_depth': [4, 5], 'criterion': ['mse', 'mae']},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-MfiSuNQ_F8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "outputId": "6c14895e-2438-43a8-99dc-f03c44f0ea2d"
      },
      "source": [
        "results = pd.DataFrame(gridsearch.cv_results_)\n",
        "results.sort_values(by=\"rank_test_score\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.233693</td>\n",
              "      <td>0.025806</td>\n",
              "      <td>0.103823</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-537.343224</td>\n",
              "      <td>-633.188069</td>\n",
              "      <td>-611.812399</td>\n",
              "      <td>-594.114564</td>\n",
              "      <td>41.080965</td>\n",
              "      <td>1</td>\n",
              "      <td>-514.399139</td>\n",
              "      <td>-476.132208</td>\n",
              "      <td>-486.784755</td>\n",
              "      <td>-492.438701</td>\n",
              "      <td>16.125856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.608001</td>\n",
              "      <td>0.009922</td>\n",
              "      <td>0.103627</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-539.744330</td>\n",
              "      <td>-635.247773</td>\n",
              "      <td>-610.870031</td>\n",
              "      <td>-595.287378</td>\n",
              "      <td>40.516179</td>\n",
              "      <td>2</td>\n",
              "      <td>-513.924961</td>\n",
              "      <td>-475.585023</td>\n",
              "      <td>-489.148606</td>\n",
              "      <td>-492.886197</td>\n",
              "      <td>15.873771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.564941</td>\n",
              "      <td>0.010909</td>\n",
              "      <td>0.103741</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-545.553738</td>\n",
              "      <td>-635.478629</td>\n",
              "      <td>-609.898505</td>\n",
              "      <td>-596.976957</td>\n",
              "      <td>37.831612</td>\n",
              "      <td>3</td>\n",
              "      <td>-554.610927</td>\n",
              "      <td>-515.603583</td>\n",
              "      <td>-525.162173</td>\n",
              "      <td>-531.792227</td>\n",
              "      <td>16.600431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.079268</td>\n",
              "      <td>0.013937</td>\n",
              "      <td>0.103753</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>200</td>\n",
              "      <td>4</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-545.615950</td>\n",
              "      <td>-634.226674</td>\n",
              "      <td>-611.571316</td>\n",
              "      <td>-597.137980</td>\n",
              "      <td>37.587285</td>\n",
              "      <td>4</td>\n",
              "      <td>-554.012714</td>\n",
              "      <td>-515.754478</td>\n",
              "      <td>-524.948497</td>\n",
              "      <td>-531.571896</td>\n",
              "      <td>16.305934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.301892</td>\n",
              "      <td>0.001192</td>\n",
              "      <td>0.103781</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-545.774354</td>\n",
              "      <td>-637.307005</td>\n",
              "      <td>-627.616934</td>\n",
              "      <td>-603.566098</td>\n",
              "      <td>41.055966</td>\n",
              "      <td>5</td>\n",
              "      <td>-524.163469</td>\n",
              "      <td>-490.204130</td>\n",
              "      <td>-490.472466</td>\n",
              "      <td>-501.613355</td>\n",
              "      <td>15.945715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.163688</td>\n",
              "      <td>0.005008</td>\n",
              "      <td>0.103681</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-546.995243</td>\n",
              "      <td>-639.080607</td>\n",
              "      <td>-629.837818</td>\n",
              "      <td>-605.304556</td>\n",
              "      <td>41.403214</td>\n",
              "      <td>6</td>\n",
              "      <td>-526.882336</td>\n",
              "      <td>-490.560190</td>\n",
              "      <td>-492.252512</td>\n",
              "      <td>-503.231679</td>\n",
              "      <td>16.737805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.284292</td>\n",
              "      <td>0.004538</td>\n",
              "      <td>0.103700</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>200</td>\n",
              "      <td>4</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-555.634757</td>\n",
              "      <td>-640.866167</td>\n",
              "      <td>-625.853913</td>\n",
              "      <td>-607.451613</td>\n",
              "      <td>37.149085</td>\n",
              "      <td>7</td>\n",
              "      <td>-572.252550</td>\n",
              "      <td>-529.625674</td>\n",
              "      <td>-536.655286</td>\n",
              "      <td>-546.177836</td>\n",
              "      <td>18.659615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.559886</td>\n",
              "      <td>0.595996</td>\n",
              "      <td>0.104441</td>\n",
              "      <td>0.000740</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-557.174302</td>\n",
              "      <td>-642.450417</td>\n",
              "      <td>-629.072181</td>\n",
              "      <td>-609.565633</td>\n",
              "      <td>37.446700</td>\n",
              "      <td>8</td>\n",
              "      <td>-574.472102</td>\n",
              "      <td>-530.248079</td>\n",
              "      <td>-538.576526</td>\n",
              "      <td>-547.765569</td>\n",
              "      <td>19.188016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "7       1.233693      0.025806         0.103823        0.000061   \n",
              "6       0.608001      0.009922         0.103627        0.000043   \n",
              "4       0.564941      0.010909         0.103741        0.000055   \n",
              "5       1.079268      0.013937         0.103753        0.000050   \n",
              "3       0.301892      0.001192         0.103781        0.000079   \n",
              "2       0.163688      0.005008         0.103681        0.000098   \n",
              "1       0.284292      0.004538         0.103700        0.000098   \n",
              "0       0.559886      0.595996         0.104441        0.000740   \n",
              "\n",
              "  param_n_estimators param_max_depth param_criterion  \\\n",
              "7                200               5             mae   \n",
              "6                100               5             mae   \n",
              "4                100               4             mae   \n",
              "5                200               4             mae   \n",
              "3                200               5             mse   \n",
              "2                100               5             mse   \n",
              "1                200               4             mse   \n",
              "0                100               4             mse   \n",
              "\n",
              "                                              params  split0_test_score  \\\n",
              "7  {'n_estimators': 200, 'max_depth': 5, 'criteri...        -537.343224   \n",
              "6  {'n_estimators': 100, 'max_depth': 5, 'criteri...        -539.744330   \n",
              "4  {'n_estimators': 100, 'max_depth': 4, 'criteri...        -545.553738   \n",
              "5  {'n_estimators': 200, 'max_depth': 4, 'criteri...        -545.615950   \n",
              "3  {'n_estimators': 200, 'max_depth': 5, 'criteri...        -545.774354   \n",
              "2  {'n_estimators': 100, 'max_depth': 5, 'criteri...        -546.995243   \n",
              "1  {'n_estimators': 200, 'max_depth': 4, 'criteri...        -555.634757   \n",
              "0  {'n_estimators': 100, 'max_depth': 4, 'criteri...        -557.174302   \n",
              "\n",
              "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "7        -633.188069        -611.812399      -594.114564       41.080965   \n",
              "6        -635.247773        -610.870031      -595.287378       40.516179   \n",
              "4        -635.478629        -609.898505      -596.976957       37.831612   \n",
              "5        -634.226674        -611.571316      -597.137980       37.587285   \n",
              "3        -637.307005        -627.616934      -603.566098       41.055966   \n",
              "2        -639.080607        -629.837818      -605.304556       41.403214   \n",
              "1        -640.866167        -625.853913      -607.451613       37.149085   \n",
              "0        -642.450417        -629.072181      -609.565633       37.446700   \n",
              "\n",
              "   rank_test_score  split0_train_score  split1_train_score  \\\n",
              "7                1         -514.399139         -476.132208   \n",
              "6                2         -513.924961         -475.585023   \n",
              "4                3         -554.610927         -515.603583   \n",
              "5                4         -554.012714         -515.754478   \n",
              "3                5         -524.163469         -490.204130   \n",
              "2                6         -526.882336         -490.560190   \n",
              "1                7         -572.252550         -529.625674   \n",
              "0                8         -574.472102         -530.248079   \n",
              "\n",
              "   split2_train_score  mean_train_score  std_train_score  \n",
              "7         -486.784755       -492.438701        16.125856  \n",
              "6         -489.148606       -492.886197        15.873771  \n",
              "4         -525.162173       -531.792227        16.600431  \n",
              "5         -524.948497       -531.571896        16.305934  \n",
              "3         -490.472466       -501.613355        15.945715  \n",
              "2         -492.252512       -503.231679        16.737805  \n",
              "1         -536.655286       -546.177836        18.659615  \n",
              "0         -538.576526       -547.765569        19.188016  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEbr1qLzRreP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "80a2c657-bdd4-40a3-f8ae-e125772e0044"
      },
      "source": [
        "gridsearch.best_estimator_"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=5,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZW5HfYtU0GW2"
      },
      "source": [
        "\n",
        "## FEATURE ENGINEERING!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ms-eoOHFvPG"
      },
      "source": [
        "Jake VanderPlas demonstrates this feature engineering: \n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sEwME8wR3A5g",
        "colab": {}
      },
      "source": [
        "# Modified from code cells 17-21 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "def jake_wrangle(X):  \n",
        "    X = X.copy()\n",
        "\n",
        "    # patterns of use generally vary from day to day; \n",
        "    # let's add binary columns that indicate the day of the week:\n",
        "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "    for i, day in enumerate(days):\n",
        "        X[day] = (X.index.dayofweek == i).astype(float)\n",
        "\n",
        "\n",
        "    # we might expect riders to behave differently on holidays; \n",
        "    # let's add an indicator of this as well:\n",
        "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "    cal = USFederalHolidayCalendar()\n",
        "    holidays = cal.holidays('2012', '2016')\n",
        "    X = X.join(pd.Series(1, index=holidays, name='holiday'))\n",
        "    X['holiday'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "    # We also might suspect that the hours of daylight would affect \n",
        "    # how many people ride; let's use the standard astronomical calculation \n",
        "    # to add this information:\n",
        "    def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
        "        \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
        "        days = (date - pd.datetime(2000, 12, 21)).days\n",
        "        m = (1. - np.tan(np.radians(latitude))\n",
        "             * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
        "        return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
        "\n",
        "    X['daylight_hrs'] = list(map(hours_of_daylight, X.index))\n",
        "\n",
        "    \n",
        "    # temperatures are in 1/10 deg C; convert to C\n",
        "    X['TMIN'] /= 10\n",
        "    X['TMAX'] /= 10\n",
        "    \n",
        "    # We can also calcuate the average temperature.\n",
        "    X['Temp (C)'] = 0.5 * (X['TMIN'] + X['TMAX'])\n",
        "\n",
        "    # precip is in 1/10 mm; convert to inches\n",
        "    X['PRCP'] /= 254\n",
        "\n",
        "    # In addition to the inches of precipitation, let's add a flag that \n",
        "    # indicates whether a day is dry (has zero precipitation):\n",
        "    X['dry day'] = (X['PRCP'] == 0).astype(int)\n",
        "\n",
        "\n",
        "    # Let's add a counter that increases from day 1, and measures how many \n",
        "    # years have passed. This will let us measure any observed annual increase \n",
        "    # or decrease in daily crossings:\n",
        "    X['annual'] = (X.index - X.index[0]).days / 365.\n",
        "\n",
        "    return X\n",
        "\n",
        "X_train = jake_wrangle(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dDGkAv813Wtj"
      },
      "source": [
        "### Linear Regression (with new features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cj3HTM6p5F1A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "1ef850b0-ae7c-4438-95f2-2726665021b8"
      },
      "source": [
        "scores = cross_validate(LinearRegression(), \n",
        "                        X_train, \n",
        "                        y_train, \n",
        "                        scoring=\"neg_mean_absolute_error\", \n",
        "                        cv=3, \n",
        "                        return_train_score=True, \n",
        "                        return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.016880</td>\n",
              "      <td>0.002047</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-297.692524</td>\n",
              "      <td>-294.532315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.004133</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-300.419037</td>\n",
              "      <td>-283.779461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.004251</td>\n",
              "      <td>0.001510</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-322.640378</td>\n",
              "      <td>-283.509114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.016880    0.002047  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "1  0.004133    0.001553  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "2  0.004251    0.001510  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -297.692524  -294.532315  \n",
              "1 -300.419037  -283.779461  \n",
              "2 -322.640378  -283.509114  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMCtOt4OUnOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0232a6be-b2d0-4482-d009-fa77a8f16cb4"
      },
      "source": [
        "scores[\"test_score\"].mean()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-306.9173130794428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b6zxN2xB3bX_"
      },
      "source": [
        "### Random Forest (with new features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3sWUDZIz1-kk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "f14d655a-772a-4e49-8241-68ba4ffc912f"
      },
      "source": [
        "param_distributions = {\n",
        "    'n_estimators': [100],\n",
        "    'max_depth': [5, 10, 15, None],\n",
        "    'criterion': [\"mae\"]\n",
        "}\n",
        "\n",
        "gridsearch = RandomizedSearchCV(\n",
        "    RandomForestRegressor(n_jobs=-1, random_state=42), \n",
        "    param_distributions=param_distributions, \n",
        "    n_iter=2, \n",
        "    cv=3, \n",
        "    scoring=\"neg_mean_absolute_error\", \n",
        "    verbose=10, \n",
        "    return_train_score=True)\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "[CV] n_estimators=100, max_depth=None, criterion=mae .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=None, criterion=mae, score=-358.7972897196261, total=   2.9s\n",
            "[CV] n_estimators=100, max_depth=None, criterion=mae .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=None, criterion=mae, score=-320.2685046728972, total=   2.1s\n",
            "[CV] n_estimators=100, max_depth=None, criterion=mae .................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=None, criterion=mae, score=-301.2507943925234, total=   2.1s\n",
            "[CV] n_estimators=100, max_depth=15, criterion=mae ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=15, criterion=mae, score=-347.23540498442367, total=   2.0s\n",
            "[CV] n_estimators=100, max_depth=15, criterion=mae ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    9.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=15, criterion=mae, score=-319.6513395638629, total=   1.9s\n",
            "[CV] n_estimators=100, max_depth=15, criterion=mae ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=100, max_depth=15, criterion=mae, score=-304.428753894081, total=   2.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   13.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   13.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=2, n_jobs=None,\n",
              "          param_distributions={'n_estimators': [100], 'max_depth': [5, 10, 15, None], 'criterion': ['mae']},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn281pExXJWr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "6fdda766-4edc-430d-feec-e8232399ebfc"
      },
      "source": [
        "gridsearch.best_estimator_"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=15,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "edpJ87A8A8sd"
      },
      "source": [
        "\n",
        "### Feature engineering, explained by Francois Chollet\n",
        "\n",
        "> _Feature engineering_ is the process of using your own knowledge about the data and about the machine learning algorithm at hand to make the algorithm work better by applying hardcoded (nonlearned) transformations to the data before it goes into the model. In many cases, it isn’t reasonable to expect a machine-learning model to be able to learn from completely arbitrary data. The data needs to be presented to the model in a way that will make the model’s job easier.\n",
        "\n",
        "> Let’s look at an intuitive example. Suppose you’re trying to develop a model that can take as input an image of a clock and can output the time of day.\n",
        "\n",
        "> If you choose to use the raw pixels of the image as input data, then you have a difficult machine-learning problem on your hands. You’ll need a convolutional neural network to solve it, and you’ll have to expend quite a bit of computational resources to train the network.\n",
        "\n",
        "> But if you already understand the problem at a high level (you understand how humans read time on a clock face), then you can come up with much better input features for a machine-learning algorithm: for instance, write a Python script to follow the black pixels of the clock hands and output the (x, y) coordinates of the tip of each hand. Then a simple machine-learning algorithm can learn to associate these coordinates with the appropriate time of day.\n",
        "\n",
        "> You can go even further: do a coordinate change, and express the (x, y) coordinates as polar coordinates with regard to the center of the image. Your input will become the angle theta of each clock hand. At this point, your features are making the problem so easy that no machine learning is required; a simple rounding operation and dictionary lookup are enough to recover the approximate time of day.\n",
        "\n",
        "> That’s the essence of feature engineering: making a problem easier by expressing it in a simpler way. It usually requires understanding the problem in depth.\n",
        "\n",
        "> Before convolutional neural networks became successful on the MNIST digit-classification problem, solutions were typically based on hardcoded features such as the number of loops in a digit image, the height of each digit in an image, a histogram of pixel values, and so on.\n",
        "\n",
        "> Neural networks are capable of automatically extracting useful features from raw data. Does this mean you don’t have to worry about feature engineering as long as you’re using deep neural networks? No, for two reasons:\n",
        "\n",
        "> - Good features still allow you to solve problems more elegantly while using fewer resources. For instance, it would be ridiculous to solve the problem of reading a clock face using a convolutional neural network.\n",
        "> - Good features let you solve a problem with far less data. The ability of deep-learning models to learn features on their own relies on having lots of training data available; if you have only a few samples, then the information value in their features becomes critical.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oux-dd-5FD6p"
      },
      "source": [
        "# ASSIGNMENT\n",
        "\n",
        "**1.** Complete the notebook cells that were originally commented **`TODO`**. \n",
        "\n",
        "**2.** Then, focus on feature engineering to improve your cross validation scores. Collaborate with your cohort on Slack. You could start with the ideas [Jake VanderPlas suggests:](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic)\n",
        "\n",
        "> Our model is almost certainly missing some relevant information. For example, nonlinear effects (such as effects of precipitation and cold temperature) and nonlinear trends within each variable (such as disinclination to ride at very cold and very hot temperatures) cannot be accounted for in this model. Additionally, we have thrown away some of the finer-grained information (such as the difference between a rainy morning and a rainy afternoon), and we have ignored correlations between days (such as the possible effect of a rainy Tuesday on Wednesday's numbers, or the effect of an unexpected sunny day after a streak of rainy days). These are all potentially interesting effects, and you now have the tools to begin exploring them if you wish!\n",
        "\n",
        "**3.** Experiment with the Categorical Encoding notebook.\n",
        "\n",
        "**4.** At the end of the day, take the last step in the \"universal workflow of machine learning\" — \"You can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\"\n",
        "\n",
        "See the [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) documentation for the `refit` parameter, `best_estimator_` attribute, and `predict` method:\n",
        "\n",
        "> **refit : boolean, or string, default=True**\n",
        "\n",
        "> Refit an estimator using the best found parameters on the whole dataset.\n",
        "\n",
        "> The refitted estimator is made available at the `best_estimator_` attribute and permits using `predict` directly on this `GridSearchCV` instance.\n",
        "\n",
        "### STRETCH\n",
        "\n",
        "**A.** Apply this lesson other datasets you've worked with, like Ames Housing, Bank Marketing, or others.\n",
        "\n",
        "**B.** In additon to `RandomizedSearchCV`, scikit-learn has [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Another library called scikit-optimize has [`BayesSearchCV`](https://scikit-optimize.github.io/notebooks/sklearn-gridsearchcv-replacement.html). Experiment with these alternatives.\n",
        "\n",
        "**C.** _[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)_ discusses options for \"Grid-Searching Which Model To Use\" in Chapter 6:\n",
        "\n",
        "> You can even go further in combining GridSearchCV and Pipeline: it is also possible to search over the actual steps being performed in the pipeline (say whether to use StandardScaler or MinMaxScaler). This leads to an even bigger search space and should be considered carefully. Trying all possible solutions is usually not a viable machine learning strategy. However, here is an example comparing a RandomForestClassifier and an SVC ...\n",
        "\n",
        "The example is shown in [the accompanying notebook](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb), code cells 35-37. Could you apply this concept to your own pipelines?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EbfxyqVv1M6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "08a4ec76-5a39-47a4-d337-9f14816a2860"
      },
      "source": [
        "X_train.describe()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>holiday</th>\n",
              "      <th>daylight_hrs</th>\n",
              "      <th>Temp (C)</th>\n",
              "      <th>dry day</th>\n",
              "      <th>annual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "      <td>963.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.123576</td>\n",
              "      <td>-41.390447</td>\n",
              "      <td>0.109034</td>\n",
              "      <td>15.673209</td>\n",
              "      <td>7.830737</td>\n",
              "      <td>31.888889</td>\n",
              "      <td>2536.141225</td>\n",
              "      <td>0.142264</td>\n",
              "      <td>0.142264</td>\n",
              "      <td>0.142264</td>\n",
              "      <td>0.143302</td>\n",
              "      <td>0.143302</td>\n",
              "      <td>0.143302</td>\n",
              "      <td>0.143302</td>\n",
              "      <td>0.028037</td>\n",
              "      <td>11.677381</td>\n",
              "      <td>11.751973</td>\n",
              "      <td>0.554517</td>\n",
              "      <td>1.317808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.264611</td>\n",
              "      <td>643.435674</td>\n",
              "      <td>2.700110</td>\n",
              "      <td>6.994807</td>\n",
              "      <td>4.914016</td>\n",
              "      <td>14.643764</td>\n",
              "      <td>1224.232861</td>\n",
              "      <td>0.349502</td>\n",
              "      <td>0.349502</td>\n",
              "      <td>0.349502</td>\n",
              "      <td>0.350563</td>\n",
              "      <td>0.350563</td>\n",
              "      <td>0.350563</td>\n",
              "      <td>0.350563</td>\n",
              "      <td>0.165165</td>\n",
              "      <td>2.568741</td>\n",
              "      <td>5.756242</td>\n",
              "      <td>0.497277</td>\n",
              "      <td>0.762023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-9999.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.600000</td>\n",
              "      <td>-7.100000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.218894</td>\n",
              "      <td>-3.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1755.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.206870</td>\n",
              "      <td>7.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.658904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>7.800000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2381.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.364878</td>\n",
              "      <td>10.850000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.317808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.129921</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.600000</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>3325.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.118901</td>\n",
              "      <td>16.375000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.976712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.200787</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>35.600000</td>\n",
              "      <td>18.300000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>6088.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.781095</td>\n",
              "      <td>26.700000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.635616</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             PRCP         SNOW        SNWD        TMAX        TMIN  \\\n",
              "count  963.000000   963.000000  963.000000  963.000000  963.000000   \n",
              "mean     0.123576   -41.390447    0.109034   15.673209    7.830737   \n",
              "std      0.264611   643.435674    2.700110    6.994807    4.914016   \n",
              "min      0.000000 -9999.000000    0.000000   -1.600000   -7.100000   \n",
              "25%      0.000000     0.000000    0.000000   10.600000    4.400000   \n",
              "50%      0.000000     0.000000    0.000000   14.400000    7.800000   \n",
              "75%      0.129921     0.000000    0.000000   20.600000   11.700000   \n",
              "max      2.200787    74.000000   80.000000   35.600000   18.300000   \n",
              "\n",
              "             AWND  Total_yesterday         Mon         Tue         Wed  \\\n",
              "count  963.000000       963.000000  963.000000  963.000000  963.000000   \n",
              "mean    31.888889      2536.141225    0.142264    0.142264    0.142264   \n",
              "std     14.643764      1224.232861    0.349502    0.349502    0.349502   \n",
              "min      4.000000        98.000000    0.000000    0.000000    0.000000   \n",
              "25%     22.000000      1755.000000    0.000000    0.000000    0.000000   \n",
              "50%     29.000000      2381.000000    0.000000    0.000000    0.000000   \n",
              "75%     41.000000      3325.000000    0.000000    0.000000    0.000000   \n",
              "max     95.000000      6088.000000    1.000000    1.000000    1.000000   \n",
              "\n",
              "              Thu         Fri         Sat         Sun     holiday  \\\n",
              "count  963.000000  963.000000  963.000000  963.000000  963.000000   \n",
              "mean     0.143302    0.143302    0.143302    0.143302    0.028037   \n",
              "std      0.350563    0.350563    0.350563    0.350563    0.165165   \n",
              "min      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "25%      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "50%      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "75%      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "max      1.000000    1.000000    1.000000    1.000000    1.000000   \n",
              "\n",
              "       daylight_hrs    Temp (C)     dry day      annual  \n",
              "count    963.000000  963.000000  963.000000  963.000000  \n",
              "mean      11.677381   11.751973    0.554517    1.317808  \n",
              "std        2.568741    5.756242    0.497277    0.762023  \n",
              "min        8.218894   -3.800000    0.000000    0.000000  \n",
              "25%        9.206870    7.750000    0.000000    0.658904  \n",
              "50%       11.364878   10.850000    1.000000    1.317808  \n",
              "75%       14.118901   16.375000    1.000000    1.976712  \n",
              "max       15.781095   26.700000    1.000000    2.635616  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d0tnfrHuvT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3bbefa77-4975-4a13-a736-e4d73e64994b"
      },
      "source": [
        "# Lets feature engineer a column determining if it rained yesterday.\n",
        "# We can use the feature engineered by Jake VanderPlas called \"dry day\"\n",
        "# to determine if there was rain on a given day\n",
        "\n",
        "X_train[\"dry day\"].value_counts()\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    534\n",
              "0    429\n",
              "Name: dry day, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciRUtvSovXfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train[\"yesterday dry day\"] = X_train[\"dry day\"].shift()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nsfh5Gsy-8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "767d60fc-d91e-479b-d774-8d2fb2dad6ad"
      },
      "source": [
        "X_train[[\"dry day\", \"yesterday dry day\"]].head(10)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dry day</th>\n",
              "      <th>yesterday dry day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-09</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-10</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-11</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-12</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-13</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            dry day  yesterday dry day\n",
              "2012-10-04        1                NaN\n",
              "2012-10-05        1                1.0\n",
              "2012-10-06        1                1.0\n",
              "2012-10-07        1                1.0\n",
              "2012-10-08        1                1.0\n",
              "2012-10-09        1                1.0\n",
              "2012-10-10        1                1.0\n",
              "2012-10-11        1                1.0\n",
              "2012-10-12        0                1.0\n",
              "2012-10-13        0                0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDY0NfabztLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# deal with Nan and change to int type\n",
        "\n",
        "X_train[\"yesterday dry day\"] = X_train[\"yesterday dry day\"].fillna(value=1).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXDWahgp1F7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try to make a column for the number of days since it was last sunny\n",
        "\n",
        "X_train['rainy day streak'] = X_train.groupby( (X_train['dry day'] !=1)\n",
        "                                              .cumsum()).cumcount() + ( (X_train['dry day'] != 0)\n",
        "                                                                       .cumsum() == 0).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZnuSnOO4v0u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "1c74579e-1ceb-4ffd-d7d8-8d6e11c3f6ff"
      },
      "source": [
        "X_train[[\"dry day\", \"rainy day streak\"]].head(10)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dry day</th>\n",
              "      <th>rainy day streak</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-09</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-10</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-11</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            dry day  rainy day streak\n",
              "2012-10-04        1                 0\n",
              "2012-10-05        1                 1\n",
              "2012-10-06        1                 2\n",
              "2012-10-07        1                 3\n",
              "2012-10-08        1                 4\n",
              "2012-10-09        1                 5\n",
              "2012-10-10        1                 6\n",
              "2012-10-11        1                 7\n",
              "2012-10-12        0                 0\n",
              "2012-10-13        0                 0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU0wMkYQ5pCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's make a feature for extreme cold/extreme heat\n",
        "# Anything above about 80 degrees (F) and below 40 degrees (F) counts as extreme temp\n",
        "# 80F = 26.67C, 40F = 4.44C\n",
        "\n",
        "def extreme_temps(X_train):\n",
        "  if (X_train[\"Temp (C)\"] > 26.67):\n",
        "    return 1\n",
        "  elif (X_train[\"Temp (C)\"] < 4.44):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "X_train[\"extreme temp day\"] = X_train.apply(extreme_temps, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaT7YPTzCoKQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "dd82fcd8-4048-4178-f529-2c39ae2dc40f"
      },
      "source": [
        "X_train[\"extreme temp day\"].value_counts()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    888\n",
              "1     75\n",
              "Name: extreme temp day, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjn8uBcx-45z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "f0e8c78f-b507-46ff-8cad-dd93e94885ac"
      },
      "source": [
        "X_train[[\"Temp (C)\", \"extreme temp day\"]].sort_values(\"Temp (C)\").head()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temp (C)</th>\n",
              "      <th>extreme temp day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-02-06</th>\n",
              "      <td>-3.80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-12-07</th>\n",
              "      <td>-3.55</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-02-05</th>\n",
              "      <td>-3.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-12-08</th>\n",
              "      <td>-2.20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-12-09</th>\n",
              "      <td>-1.90</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Temp (C)  extreme temp day\n",
              "2014-02-06     -3.80                 1\n",
              "2013-12-07     -3.55                 1\n",
              "2014-02-05     -3.00                 1\n",
              "2013-12-08     -2.20                 1\n",
              "2013-12-09     -1.90                 1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQqI49T9BuI8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "4110a258-8fee-43fa-8ffa-86892e46a5f7"
      },
      "source": [
        "X_train[[\"Temp (C)\", \"extreme temp day\"]].sort_values(\"Temp (C)\", ascending=False).head()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temp (C)</th>\n",
              "      <th>extreme temp day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-08-11</th>\n",
              "      <td>26.70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-06-30</th>\n",
              "      <td>25.55</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-09-11</th>\n",
              "      <td>25.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-07-01</th>\n",
              "      <td>25.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-07-01</th>\n",
              "      <td>25.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Temp (C)  extreme temp day\n",
              "2014-08-11     26.70                 1\n",
              "2013-06-30     25.55                 0\n",
              "2013-09-11     25.00                 0\n",
              "2014-07-01     25.00                 0\n",
              "2013-07-01     25.00                 0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAS_Qjl4EUk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}