{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_243_Select_models_and_parameters.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dustiny5/DS-Unit-2-Sprint-4-Practicing-Understanding/blob/master/module1-hyperparameter-optimization/LS_DS_241_Hyperparameter_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O67uhlT4MExK"
      },
      "source": [
        "_Lambda School Data Science — Practicing & Understanding Predictive Modeling_\n",
        "\n",
        "# Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VE4rfZd4NUGA"
      },
      "source": [
        "Today we'll use this process:\n",
        "\n",
        "## \"A universal workflow of machine learning\"\n",
        "\n",
        "_Excerpt from Francois Chollet, [Deep Learning with Python](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/README.md), Chapter 4: Fundamentals of machine learning_\n",
        " \n",
        "**1. Define the problem at hand and the data on which you’ll train.** Collect this data, or annotate it with labels if need be.\n",
        "\n",
        "**2. Choose how you’ll measure success on your problem.** Which metrics will you monitor on your validation data?\n",
        "\n",
        "**3. Determine your evaluation protocol:** hold-out validation? K-fold validation? Which portion of the data should you use for validation?\n",
        "\n",
        "**4. Develop a first model that does better than a basic baseline:** a model with statistical power.\n",
        "\n",
        "**5. Develop a model that overfits.** The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
        "\n",
        "**6. Regularize your model and tune its hyperparameters, based on performance on the validation data.** Repeatedly modify your model, train it, evaluate on your validation data (not the test data, at this point), modify it again, and repeat, until the model is as good as it can get. \n",
        "\n",
        "**Iterate on feature engineering: add new features, or remove features that don’t seem to be informative.** \n",
        "\n",
        "Once you’ve developed a satisfactory model configuration, you can **train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3kt6bzEcOIaa"
      },
      "source": [
        "## 1. Define the problem at hand and the data on which you'll train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "di16k7vpRg67"
      },
      "source": [
        "We'll apply the workflow to a [project from _Python Data Science Handbook_](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic) by Jake VanderPlas:\n",
        "\n",
        "> **Predicting Bicycle Traffic**\n",
        "\n",
        "> As an example, let's take a look at whether we can predict the number of bicycle trips across Seattle's Fremont Bridge based on weather, season, and other factors.\n",
        "\n",
        "> We will join the bike data with another dataset, and try to determine the extent to which weather and seasonal factors—temperature, precipitation, and daylight hours—affect the volume of bicycle traffic through this corridor. Fortunately, the NOAA makes available their daily [weather station data](http://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND) (I used station ID USW00024233) and we can easily use Pandas to join the two data sources.\n",
        "\n",
        "> Let's start by loading the two datasets, indexing by date:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "19dpb_d0R1A6"
      },
      "source": [
        "So this is a regression problem, not a classification problem. We'll define the target, choose an evaluation metric, and choose models that are appropriate for regression problems.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "os1zruXQ30KM"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5XVu-HSeMDtV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8b451e20-66ad-4f24-af49-14a767c3a582"
      },
      "source": [
        "!curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1616k    0 1616k    0     0   441k      0 --:--:--  0:00:03 --:--:--  441k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sih_7mTzMdfr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "43a80347-1d05-4fe9-a7eb-d88c7d5cd82c"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-13 20:19:33--  https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 234945 (229K) [text/plain]\n",
            "Saving to: ‘BicycleWeather.csv’\n",
            "\n",
            "\rBicycleWeather.csv    0%[                    ]       0  --.-KB/s               \rBicycleWeather.csv  100%[===================>] 229.44K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-05-13 20:19:33 (7.74 MB/s) - ‘BicycleWeather.csv’ saved [234945/234945]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9GYm74kD34OQ"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BfQ7gE28MNdF",
        "colab": {}
      },
      "source": [
        "# Modified from cells 15, 16, and 20, at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Download and join data into a dataframe\n",
        "def load(): \n",
        "    fremont_bridge = 'https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD'\n",
        "    \n",
        "    bicycle_weather = 'https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv'\n",
        "\n",
        "    counts = pd.read_csv(fremont_bridge, index_col='Date', parse_dates=True, \n",
        "                         infer_datetime_format=True)\n",
        "\n",
        "    weather = pd.read_csv(bicycle_weather, index_col='DATE', parse_dates=True, \n",
        "                          infer_datetime_format=True)\n",
        "\n",
        "    daily = counts.resample('d').sum()\n",
        "    daily['Total'] = daily.sum(axis=1)\n",
        "    daily = daily[['Total']] # remove other columns\n",
        "\n",
        "    weather_columns = ['PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND']\n",
        "    daily = daily.join(weather[weather_columns], how='inner')\n",
        "    \n",
        "    # Make a feature for yesterday's total\n",
        "    daily['Total_yesterday'] = daily.Total.shift(1)\n",
        "    daily = daily.drop(index=daily.index[0])\n",
        "    \n",
        "    return daily\n",
        "\n",
        "daily = load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VVB3g4704An5"
      },
      "source": [
        "### First fast look at the data\n",
        "- What's the shape?\n",
        "- What's the date range?\n",
        "- What's the target and the features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t50E2fTUWBBU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f748dc88-e3c0-4ca7-b3ff-a4fe22f01d75"
      },
      "source": [
        "# TODO\n",
        "daily.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1063, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5fIalWH9nrX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "781fd4bf-c72f-4c60-84ba-0b29d9714765"
      },
      "source": [
        "daily.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>3475.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>83</td>\n",
              "      <td>65</td>\n",
              "      <td>3521.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>3148.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>217</td>\n",
              "      <td>89</td>\n",
              "      <td>57</td>\n",
              "      <td>3475.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>2006.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>51</td>\n",
              "      <td>3148.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>2142.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>13</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>3537.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211</td>\n",
              "      <td>78</td>\n",
              "      <td>19</td>\n",
              "      <td>2142.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2012-10-04  3475.0     0     0     0   189    83    65           3521.0\n",
              "2012-10-05  3148.0     0     0     0   217    89    57           3475.0\n",
              "2012-10-06  2006.0     0     0     0   239    78    51           3148.0\n",
              "2012-10-07  2142.0     0     0     0   239    78    13           2006.0\n",
              "2012-10-08  3537.0     0     0     0   211    78    19           2142.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYpiPfFO9qfV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "53232232-cee9-4a72-f5d7-4a26f4198d24"
      },
      "source": [
        "daily.tail()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-08-28</th>\n",
              "      <td>2653.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>233</td>\n",
              "      <td>156</td>\n",
              "      <td>26</td>\n",
              "      <td>4336.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-29</th>\n",
              "      <td>699.0</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>222</td>\n",
              "      <td>133</td>\n",
              "      <td>58</td>\n",
              "      <td>2653.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-30</th>\n",
              "      <td>1213.0</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>128</td>\n",
              "      <td>47</td>\n",
              "      <td>699.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-31</th>\n",
              "      <td>2823.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>161</td>\n",
              "      <td>58</td>\n",
              "      <td>1213.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-01</th>\n",
              "      <td>2876.0</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>194</td>\n",
              "      <td>139</td>\n",
              "      <td>-9999</td>\n",
              "      <td>2823.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2015-08-28  2653.0     5     0     0   233   156    26           4336.0\n",
              "2015-08-29   699.0   325     0     0   222   133    58           2653.0\n",
              "2015-08-30  1213.0   102     0     0   200   128    47            699.0\n",
              "2015-08-31  2823.0     0     0     0   189   161    58           1213.0\n",
              "2015-09-01  2876.0    58     0     0   194   139 -9999           2823.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XgMvCsaWJR7Q"
      },
      "source": [
        "Target\n",
        "- Total : Daily total number of bicycle trips across Seattle's Fremont Bridge\n",
        "\n",
        "Features\n",
        "- Date (index) : from 2012-10-04 to 2015-09-01\n",
        "- Total_yesterday : Total trips yesterday\n",
        "- PRCP : Precipitation (1/10 mm)\n",
        "- SNOW : Snowfall (1/10 mm)\n",
        "- SNWD : Snow depth (1/10 mm)\n",
        "- TMAX : Maximum temperature (1/10 Celsius)\n",
        "- TMIN : Minimum temperature (1/10 Celsius)\n",
        "- AWND : Average daily wind speed (1/10 meters per second)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lenL-przSYCo"
      },
      "source": [
        "## 2. Choose how you’ll measure success on your problem.\n",
        "\n",
        "Which metrics will you monitor on your validation data?\n",
        "\n",
        "This is a regression problem, so we need to choose a regression [metric](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
        "\n",
        "\n",
        "\n",
        "I'll choose mean absolute error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1TqbomapSyRP",
        "colab": {}
      },
      "source": [
        "# TODO\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IRHrB3rsS5hF"
      },
      "source": [
        "## 3. Determine your evaluation protocol \n",
        "\n",
        "We're doing model selection, hyperparameter optimization, and performance estimation. So generally we have two ideal [options](https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg) to choose from:\n",
        "\n",
        "- 3-way holdout method (train/validation/test split)\n",
        "- Cross-validation with independent test set\n",
        "\n",
        "I'll choose cross-validation with independent test set. Scikit-learn makes cross-validation convenient for us!\n",
        "\n",
        "Specifically, I will use random shuffled cross validation to train and validate, but I will hold out an \"out-of-time\" test set, from the last 100 days of data:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A3xo6HgbPMFm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e02ad6c0-49a9-4dae-a31f-14039d0ed3ee"
      },
      "source": [
        "# TODO\n",
        "train = daily[:-100] # Everything but the last 100 days\n",
        "test = daily[-100:] # last 100 days\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((963, 8), (100, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfg2qQc9ANKW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e2db217b-5bfb-4777-9a49-82c29d65457f"
      },
      "source": [
        "X_train = train.drop(columns='Total')\n",
        "y_train = train['Total']\n",
        "\n",
        "X_test = test.drop(columns='Total')\n",
        "y_test = test['Total']\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((963, 7), (100, 7), (963,), (100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vH6IsORQTvTU"
      },
      "source": [
        "## 4. Develop a first model that does better than a basic baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DJBs2nQkj7oB"
      },
      "source": [
        "### Look at the target's distribution and descriptive stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P5peakv9Zs71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "9c648b34-d3ea-44d2-cdbb-96643f560859"
      },
      "source": [
        "# TODO\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.distplot(y_train)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd5a2613630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUCoUIiIS1P8Hd41s336jLrkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgsPJqlBA0Gp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "c2bc2daf-e3b5-491a-8a4d-41866538966d"
      },
      "source": [
        "y_train.describe()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     963.000000\n",
              "mean     2534.329180\n",
              "std      1224.065027\n",
              "min        98.000000\n",
              "25%      1755.000000\n",
              "50%      2381.000000\n",
              "75%      3317.500000\n",
              "max      6088.000000\n",
              "Name: Total, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fEjxxgV9kExY"
      },
      "source": [
        "### Basic baseline 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6GepKdQjYcEP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "736cfa8e-57b3-4686-d68b-f0ef05becf0c"
      },
      "source": [
        "# TODO - Predict using median\n",
        "y_pred = [y_train.median()] * len(y_train)\n",
        "mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "971.9376947040498"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tN2I_F3FkIHb"
      },
      "source": [
        "### Basic baseline 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZW8bhZFtTunV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "905286c0-b95f-4fb0-ee03-dec48efa9b86"
      },
      "source": [
        "# TODO - Predict today same as yesterday\n",
        "y_pred = X_train['Total_yesterday']\n",
        "mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "708.061266874351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ggf3VpxwkJ0T"
      },
      "source": [
        "### First model that does better than a basic baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KfaqL1Ezer2-"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OeBtU68skfW-",
        "colab": {}
      },
      "source": [
        "# TODO\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# 2 buckets train and 1 bucket test - train on a + b and test/predict on c\n",
        "scores = cross_validate(LinearRegression(), X_train, y_train,\n",
        "                        scoring='neg_mean_absolute_error', cv=3,\n",
        "                        return_train_score=True, return_estimator=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_hHmgNoELHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "c2e652f3-0250-4e52-c336-ffa5f9abc44c"
      },
      "source": [
        "pd.DataFrame(scores)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.007975</td>\n",
              "      <td>0.003506</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-555.186275</td>\n",
              "      <td>-619.509206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.005259</td>\n",
              "      <td>0.002436</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-651.126513</td>\n",
              "      <td>-583.427702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.003351</td>\n",
              "      <td>0.001353</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-615.965800</td>\n",
              "      <td>-589.341301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.007975    0.003506  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "1  0.005259    0.002436  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "2  0.003351    0.001353  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -555.186275  -619.509206  \n",
              "1 -651.126513  -583.427702  \n",
              "2 -615.965800  -589.341301  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xNZ7slAE9DZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b26179e-ed17-4a76-e3b1-a5178e8f99e1"
      },
      "source": [
        "-scores['test_score'].mean()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "607.4261958631806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5thFHstNFAAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "2107316d-4554-4bb1-bd37-b5323f3b0fcf"
      },
      "source": [
        "for i, model in enumerate(scores['estimator']):\n",
        "  coefficients = model.coef_\n",
        "  intercept = model.intercept_\n",
        "  features_names = X_train.columns\n",
        "  \n",
        "  print(f'Model from cross-validation fold #{i}')\n",
        "  print(f'Intercept: {intercept}')\n",
        "  print(pd.Series(coefficients, features_names).to_string())\n",
        "  print('\\n')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model from cross-validation fold #0\n",
            "Intercept: 566.7766337283679\n",
            "PRCP               -3.525103\n",
            "SNOW               -0.082029\n",
            "SNWD              -12.045027\n",
            "TMAX                9.475238\n",
            "TMIN               -4.607775\n",
            "AWND               -2.745191\n",
            "Total_yesterday     0.417360\n",
            "\n",
            "\n",
            "Model from cross-validation fold #1\n",
            "Intercept: 671.9064515706045\n",
            "PRCP               -2.772253\n",
            "SNOW               -0.000995\n",
            "SNWD               20.800688\n",
            "TMAX                8.804948\n",
            "TMIN               -3.741386\n",
            "AWND               -6.108300\n",
            "Total_yesterday     0.405074\n",
            "\n",
            "\n",
            "Model from cross-validation fold #2\n",
            "Intercept: 465.84525362296563\n",
            "PRCP               -2.876196\n",
            "SNOW               -0.016432\n",
            "SNWD               -8.809696\n",
            "TMAX               10.419441\n",
            "TMIN               -5.862868\n",
            "AWND               -2.398991\n",
            "Total_yesterday     0.423493\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fg1YI4X8n9nI"
      },
      "source": [
        "## 5. Develop a model that overfits. \n",
        "\n",
        "\"The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\" —Chollet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lodd6UPOoy89"
      },
      "source": [
        "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.03-validation-curve.png\">\n",
        "\n",
        "Diagram Source: https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xj82P0VdwYlh"
      },
      "source": [
        "### Random Forest?\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_yYXpk99C4cM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f4114121-93cf-48af-9d92-e9078f7ea660"
      },
      "source": [
        "# TODO\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, max_depth=None, n_jobs=-1)\n",
        "\n",
        "scores = cross_validate(model, X_train, y_train, scoring='neg_mean_absolute_error',\n",
        "                        cv=3, return_train_score=True, return_estimator=True)\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.779226</td>\n",
              "      <td>0.104844</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-554.042118</td>\n",
              "      <td>-239.506931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.256920</td>\n",
              "      <td>0.103721</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-631.888785</td>\n",
              "      <td>-225.198489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.242142</td>\n",
              "      <td>0.103692</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-643.843583</td>\n",
              "      <td>-225.334486</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  1.779226    0.104844  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "1  0.256920    0.103721  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "2  0.242142    0.103692  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -554.042118  -239.506931  \n",
              "1 -631.888785  -225.198489  \n",
              "2 -643.843583  -225.334486  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_yq-qaEKPb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46a03d3c-8c6e-4841-c958-44f6f342d60d"
      },
      "source": [
        "-scores['test_score'].mean(), -scores['train_score'].mean()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(609.9248286604361, 230.01330218068537)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJJu-UH0LZ2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ryO1hVKr-6f"
      },
      "source": [
        "### Validation Curve\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html\n",
        "\n",
        "> Validation curve. Determine training and test scores for varying parameter values. This is similar to grid search with one parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apKk4vKiwgtM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "2f72e263-86bb-417f-ede1-99cad72fdde8"
      },
      "source": [
        "# Modified from cell 13 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100)\n",
        "\n",
        "depth = [2, 3, 4, 5, 6]\n",
        "train_score, val_score = validation_curve(\n",
        "    model, X_train, y_train,\n",
        "    param_name='max_depth', param_range=depth,  #Param_name-what are we tuning. #Param_range-what list of numbers\n",
        "    scoring='neg_mean_absolute_error', cv=3)\n",
        "\n",
        "plt.plot(depth, np.median(train_score, 1), color='blue', label='training score')\n",
        "plt.plot(depth, np.median(val_score, 1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('depth');"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DQoMvZ7-yCAQ"
      },
      "source": [
        "### `RandomizedSearchCV`\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/grid_search.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bk_dX_mByKm7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "a17a03b0-3786-4ead-8e9c-81c42d598b80"
      },
      "source": [
        "# TODO\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distributions = {\n",
        "    'n_estimators': [100,200],\n",
        "    'max_depth': [4,5],\n",
        "    'criterion': ['mse','mae']\n",
        "}\n",
        "\n",
        "gridsearch = RandomizedSearchCV(\n",
        "    RandomForestRegressor(n_jobs=-1, random_state=42),\n",
        "    param_distributions=param_distributions, n_iter=8,\n",
        "    cv=3, scoring='neg_mean_absolute_error',verbose=10,\n",
        "    return_train_score=True, n_jobs=-1\n",
        ")\n",
        "\n",
        "gridsearch.fit(X_train,y_train)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    4.9s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   14.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   14.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=8, n_jobs=-1,\n",
              "          param_distributions={'n_estimators': [100, 200], 'max_depth': [4, 5], 'criterion': ['mse', 'mae']},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ4GjrfTQ8ih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "outputId": "06b5efb9-7d74-4b13-af1a-e1928e46cd73"
      },
      "source": [
        "result = pd.DataFrame(gridsearch.cv_results_)\n",
        "result.sort_values(by='rank_test_score')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.895683</td>\n",
              "      <td>0.382651</td>\n",
              "      <td>0.106230</td>\n",
              "      <td>0.003214</td>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-537.343224</td>\n",
              "      <td>-633.188069</td>\n",
              "      <td>-611.812399</td>\n",
              "      <td>-594.114564</td>\n",
              "      <td>41.080965</td>\n",
              "      <td>1</td>\n",
              "      <td>-514.399139</td>\n",
              "      <td>-476.132208</td>\n",
              "      <td>-486.784755</td>\n",
              "      <td>-492.438701</td>\n",
              "      <td>16.125856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.987069</td>\n",
              "      <td>0.072572</td>\n",
              "      <td>0.113894</td>\n",
              "      <td>0.003776</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-539.744330</td>\n",
              "      <td>-635.247773</td>\n",
              "      <td>-610.870031</td>\n",
              "      <td>-595.287378</td>\n",
              "      <td>40.516179</td>\n",
              "      <td>2</td>\n",
              "      <td>-513.924961</td>\n",
              "      <td>-475.585023</td>\n",
              "      <td>-489.148606</td>\n",
              "      <td>-492.886197</td>\n",
              "      <td>15.873771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.009928</td>\n",
              "      <td>0.040825</td>\n",
              "      <td>0.103754</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-545.553738</td>\n",
              "      <td>-635.478629</td>\n",
              "      <td>-609.898505</td>\n",
              "      <td>-596.976957</td>\n",
              "      <td>37.831612</td>\n",
              "      <td>3</td>\n",
              "      <td>-554.610927</td>\n",
              "      <td>-515.603583</td>\n",
              "      <td>-525.162173</td>\n",
              "      <td>-531.792227</td>\n",
              "      <td>16.600431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.938236</td>\n",
              "      <td>0.051033</td>\n",
              "      <td>0.121150</td>\n",
              "      <td>0.004834</td>\n",
              "      <td>200</td>\n",
              "      <td>4</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-545.615950</td>\n",
              "      <td>-634.226674</td>\n",
              "      <td>-611.571316</td>\n",
              "      <td>-597.137980</td>\n",
              "      <td>37.587285</td>\n",
              "      <td>4</td>\n",
              "      <td>-554.012714</td>\n",
              "      <td>-515.754478</td>\n",
              "      <td>-524.948497</td>\n",
              "      <td>-531.571896</td>\n",
              "      <td>16.305934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.403856</td>\n",
              "      <td>0.046462</td>\n",
              "      <td>0.105074</td>\n",
              "      <td>0.002042</td>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-545.774354</td>\n",
              "      <td>-637.307005</td>\n",
              "      <td>-627.616934</td>\n",
              "      <td>-603.566098</td>\n",
              "      <td>41.055966</td>\n",
              "      <td>5</td>\n",
              "      <td>-524.163469</td>\n",
              "      <td>-490.204130</td>\n",
              "      <td>-490.472466</td>\n",
              "      <td>-501.613355</td>\n",
              "      <td>15.945715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.275020</td>\n",
              "      <td>0.000816</td>\n",
              "      <td>0.103981</td>\n",
              "      <td>0.000345</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-546.995243</td>\n",
              "      <td>-639.080607</td>\n",
              "      <td>-629.837818</td>\n",
              "      <td>-605.304556</td>\n",
              "      <td>41.403214</td>\n",
              "      <td>6</td>\n",
              "      <td>-526.882336</td>\n",
              "      <td>-490.560190</td>\n",
              "      <td>-492.252512</td>\n",
              "      <td>-503.231679</td>\n",
              "      <td>16.737805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.376399</td>\n",
              "      <td>0.030497</td>\n",
              "      <td>0.104482</td>\n",
              "      <td>0.001543</td>\n",
              "      <td>200</td>\n",
              "      <td>4</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-555.634757</td>\n",
              "      <td>-640.866167</td>\n",
              "      <td>-625.853913</td>\n",
              "      <td>-607.451613</td>\n",
              "      <td>37.149085</td>\n",
              "      <td>7</td>\n",
              "      <td>-572.252550</td>\n",
              "      <td>-529.625674</td>\n",
              "      <td>-536.655286</td>\n",
              "      <td>-546.177836</td>\n",
              "      <td>18.659615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.283340</td>\n",
              "      <td>0.004971</td>\n",
              "      <td>0.104440</td>\n",
              "      <td>0.000902</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-557.174302</td>\n",
              "      <td>-642.450417</td>\n",
              "      <td>-629.072181</td>\n",
              "      <td>-609.565633</td>\n",
              "      <td>37.446700</td>\n",
              "      <td>8</td>\n",
              "      <td>-574.472102</td>\n",
              "      <td>-530.248079</td>\n",
              "      <td>-538.576526</td>\n",
              "      <td>-547.765569</td>\n",
              "      <td>19.188016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "7       1.895683      0.382651         0.106230        0.003214   \n",
              "6       0.987069      0.072572         0.113894        0.003776   \n",
              "4       1.009928      0.040825         0.103754        0.000161   \n",
              "5       1.938236      0.051033         0.121150        0.004834   \n",
              "3       0.403856      0.046462         0.105074        0.002042   \n",
              "2       0.275020      0.000816         0.103981        0.000345   \n",
              "1       0.376399      0.030497         0.104482        0.001543   \n",
              "0       0.283340      0.004971         0.104440        0.000902   \n",
              "\n",
              "  param_n_estimators param_max_depth param_criterion  \\\n",
              "7                200               5             mae   \n",
              "6                100               5             mae   \n",
              "4                100               4             mae   \n",
              "5                200               4             mae   \n",
              "3                200               5             mse   \n",
              "2                100               5             mse   \n",
              "1                200               4             mse   \n",
              "0                100               4             mse   \n",
              "\n",
              "                                              params  split0_test_score  \\\n",
              "7  {'n_estimators': 200, 'max_depth': 5, 'criteri...        -537.343224   \n",
              "6  {'n_estimators': 100, 'max_depth': 5, 'criteri...        -539.744330   \n",
              "4  {'n_estimators': 100, 'max_depth': 4, 'criteri...        -545.553738   \n",
              "5  {'n_estimators': 200, 'max_depth': 4, 'criteri...        -545.615950   \n",
              "3  {'n_estimators': 200, 'max_depth': 5, 'criteri...        -545.774354   \n",
              "2  {'n_estimators': 100, 'max_depth': 5, 'criteri...        -546.995243   \n",
              "1  {'n_estimators': 200, 'max_depth': 4, 'criteri...        -555.634757   \n",
              "0  {'n_estimators': 100, 'max_depth': 4, 'criteri...        -557.174302   \n",
              "\n",
              "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "7        -633.188069        -611.812399      -594.114564       41.080965   \n",
              "6        -635.247773        -610.870031      -595.287378       40.516179   \n",
              "4        -635.478629        -609.898505      -596.976957       37.831612   \n",
              "5        -634.226674        -611.571316      -597.137980       37.587285   \n",
              "3        -637.307005        -627.616934      -603.566098       41.055966   \n",
              "2        -639.080607        -629.837818      -605.304556       41.403214   \n",
              "1        -640.866167        -625.853913      -607.451613       37.149085   \n",
              "0        -642.450417        -629.072181      -609.565633       37.446700   \n",
              "\n",
              "   rank_test_score  split0_train_score  split1_train_score  \\\n",
              "7                1         -514.399139         -476.132208   \n",
              "6                2         -513.924961         -475.585023   \n",
              "4                3         -554.610927         -515.603583   \n",
              "5                4         -554.012714         -515.754478   \n",
              "3                5         -524.163469         -490.204130   \n",
              "2                6         -526.882336         -490.560190   \n",
              "1                7         -572.252550         -529.625674   \n",
              "0                8         -574.472102         -530.248079   \n",
              "\n",
              "   split2_train_score  mean_train_score  std_train_score  \n",
              "7         -486.784755       -492.438701        16.125856  \n",
              "6         -489.148606       -492.886197        15.873771  \n",
              "4         -525.162173       -531.792227        16.600431  \n",
              "5         -524.948497       -531.571896        16.305934  \n",
              "3         -490.472466       -501.613355        15.945715  \n",
              "2         -492.252512       -503.231679        16.737805  \n",
              "1         -536.655286       -546.177836        18.659615  \n",
              "0         -538.576526       -547.765569        19.188016  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFxdquCJRqWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c7bc7d89-b7d3-45b1-bca8-dde4eee6af3a"
      },
      "source": [
        "gridsearch.best_estimator_"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=5,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZW5HfYtU0GW2"
      },
      "source": [
        "## FEATURE ENGINEERING!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ms-eoOHFvPG"
      },
      "source": [
        "Jake VanderPlas demonstrates this feature engineering: \n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sEwME8wR3A5g",
        "colab": {}
      },
      "source": [
        "# Modified from code cells 17-21 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "def jake_wrangle(X):  \n",
        "    X = X.copy()\n",
        "\n",
        "    # patterns of use generally vary from day to day; \n",
        "    # let's add binary columns that indicate the day of the week:\n",
        "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "    for i, day in enumerate(days):\n",
        "        X[day] = (X.index.dayofweek == i).astype(float)\n",
        "\n",
        "\n",
        "    # we might expect riders to behave differently on holidays; \n",
        "    # let's add an indicator of this as well:\n",
        "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "    cal = USFederalHolidayCalendar()\n",
        "    holidays = cal.holidays('2012', '2016')\n",
        "    X = X.join(pd.Series(1, index=holidays, name='holiday'))\n",
        "    X['holiday'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "    # We also might suspect that the hours of daylight would affect \n",
        "    # how many people ride; let's use the standard astronomical calculation \n",
        "    # to add this information:\n",
        "    def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
        "        \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
        "        days = (date - pd.datetime(2000, 12, 21)).days\n",
        "        m = (1. - np.tan(np.radians(latitude))\n",
        "             * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
        "        return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
        "\n",
        "    X['daylight_hrs'] = list(map(hours_of_daylight, X.index))\n",
        "\n",
        "    \n",
        "    # temperatures are in 1/10 deg C; convert to C\n",
        "    X['TMIN'] /= 10\n",
        "    X['TMAX'] /= 10\n",
        "    \n",
        "    # We can also calcuate the average temperature.\n",
        "    X['Temp (C)'] = 0.5 * (X['TMIN'] + X['TMAX'])\n",
        "\n",
        "    # precip is in 1/10 mm; convert to inches\n",
        "    X['PRCP'] /= 254\n",
        "\n",
        "    # In addition to the inches of precipitation, let's add a flag that \n",
        "    # indicates whether a day is dry (has zero precipitation):\n",
        "    X['dry day'] = (X['PRCP'] == 0).astype(int)\n",
        "\n",
        "\n",
        "    # Let's add a counter that increases from day 1, and measures how many \n",
        "    # years have passed. This will let us measure any observed annual increase \n",
        "    # or decrease in daily crossings:\n",
        "    X['annual'] = (X.index - X.index[0]).days / 365.\n",
        "\n",
        "    return X\n",
        "\n",
        "X_train = jake_wrangle(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dDGkAv813Wtj"
      },
      "source": [
        "### Linear Regression (with new features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cj3HTM6p5F1A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "5bdd0d6c-5568-4b7d-a4c6-5c898edd613b"
      },
      "source": [
        "# TODO\n",
        "scores = cross_validate(LinearRegression(), X_train, y_train, \n",
        "                        scoring='neg_mean_absolute_error', cv=3,\n",
        "                        return_train_score=True, return_estimator=True)\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.009207</td>\n",
              "      <td>0.001852</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-297.692524</td>\n",
              "      <td>-294.532315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.006717</td>\n",
              "      <td>0.002123</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-300.419037</td>\n",
              "      <td>-283.779461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.004729</td>\n",
              "      <td>0.001690</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-322.640378</td>\n",
              "      <td>-283.509114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.009207    0.001852  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "1  0.006717    0.002123  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "2  0.004729    0.001690  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -297.692524  -294.532315  \n",
              "1 -300.419037  -283.779461  \n",
              "2 -322.640378  -283.509114  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b6zxN2xB3bX_"
      },
      "source": [
        "### Random Forest (with new features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3sWUDZIz1-kk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "7a63f7fe-bbf6-468d-93a5-e8bf9eadd73a"
      },
      "source": [
        "# TODO\n",
        "param_distributions = {\n",
        "    'n_estimators': [100],\n",
        "    'max_depth': [5, 10, 15, None],\n",
        "    'criterion': ['mae']\n",
        "}\n",
        "\n",
        "gridsearch = RandomizedSearchCV(\n",
        "    RandomForestRegressor(n_jobs=-1, random_state=42),\n",
        "    param_distributions=param_distributions, n_iter=4,\n",
        "    cv=3, scoring='neg_mean_absolute_error',verbose=10,\n",
        "    return_train_score=True, n_jobs=-1\n",
        ")\n",
        "\n",
        "gridsearch.fit(X_train,y_train)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    6.3s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   16.4s\n",
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:   20.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=4, n_jobs=-1,\n",
              "          param_distributions={'n_estimators': [100], 'max_depth': [5, 10, 15, None], 'criterion': ['mae']},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfez4xytVbQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "edpJ87A8A8sd"
      },
      "source": [
        "\n",
        "### Feature engineering, explained by Francois Chollet\n",
        "\n",
        "> _Feature engineering_ is the process of using your own knowledge about the data and about the machine learning algorithm at hand to make the algorithm work better by applying hardcoded (nonlearned) transformations to the data before it goes into the model. In many cases, it isn’t reasonable to expect a machine-learning model to be able to learn from completely arbitrary data. The data needs to be presented to the model in a way that will make the model’s job easier.\n",
        "\n",
        "> Let’s look at an intuitive example. Suppose you’re trying to develop a model that can take as input an image of a clock and can output the time of day.\n",
        "\n",
        "> If you choose to use the raw pixels of the image as input data, then you have a difficult machine-learning problem on your hands. You’ll need a convolutional neural network to solve it, and you’ll have to expend quite a bit of computational resources to train the network.\n",
        "\n",
        "> But if you already understand the problem at a high level (you understand how humans read time on a clock face), then you can come up with much better input features for a machine-learning algorithm: for instance, write a Python script to follow the black pixels of the clock hands and output the (x, y) coordinates of the tip of each hand. Then a simple machine-learning algorithm can learn to associate these coordinates with the appropriate time of day.\n",
        "\n",
        "> You can go even further: do a coordinate change, and express the (x, y) coordinates as polar coordinates with regard to the center of the image. Your input will become the angle theta of each clock hand. At this point, your features are making the problem so easy that no machine learning is required; a simple rounding operation and dictionary lookup are enough to recover the approximate time of day.\n",
        "\n",
        "> That’s the essence of feature engineering: making a problem easier by expressing it in a simpler way. It usually requires understanding the problem in depth.\n",
        "\n",
        "> Before convolutional neural networks became successful on the MNIST digit-classification problem, solutions were typically based on hardcoded features such as the number of loops in a digit image, the height of each digit in an image, a histogram of pixel values, and so on.\n",
        "\n",
        "> Neural networks are capable of automatically extracting useful features from raw data. Does this mean you don’t have to worry about feature engineering as long as you’re using deep neural networks? No, for two reasons:\n",
        "\n",
        "> - Good features still allow you to solve problems more elegantly while using fewer resources. For instance, it would be ridiculous to solve the problem of reading a clock face using a convolutional neural network.\n",
        "> - Good features let you solve a problem with far less data. The ability of deep-learning models to learn features on their own relies on having lots of training data available; if you have only a few samples, then the information value in their features becomes critical.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oux-dd-5FD6p"
      },
      "source": [
        "# ASSIGNMENT\n",
        "\n",
        "**1.** Complete the notebook cells that were originally commented **`TODO`**. \n",
        "\n",
        "**2.** Then, focus on feature engineering to improve your cross validation scores. Collaborate with your cohort on Slack. You could start with the ideas [Jake VanderPlas suggests:](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic)\n",
        "\n",
        "> Our model is almost certainly missing some relevant information. For example, nonlinear effects (such as effects of precipitation and cold temperature) and nonlinear trends within each variable (such as disinclination to ride at very cold and very hot temperatures) cannot be accounted for in this model. Additionally, we have thrown away some of the finer-grained information (such as the difference between a rainy morning and a rainy afternoon), and we have ignored correlations between days (such as the possible effect of a rainy Tuesday on Wednesday's numbers, or the effect of an unexpected sunny day after a streak of rainy days). These are all potentially interesting effects, and you now have the tools to begin exploring them if you wish!\n",
        "\n",
        "**3.** Experiment with the Categorical Encoding notebook.\n",
        "\n",
        "**4.** At the end of the day, take the last step in the \"universal workflow of machine learning\" — \"You can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\"\n",
        "\n",
        "See the [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) documentation for the `refit` parameter, `best_estimator_` attribute, and `predict` method:\n",
        "\n",
        "> **refit : boolean, or string, default=True**\n",
        "\n",
        "> Refit an estimator using the best found parameters on the whole dataset.\n",
        "\n",
        "> The refitted estimator is made available at the `best_estimator_` attribute and permits using `predict` directly on this `GridSearchCV` instance.\n",
        "\n",
        "### STRETCH\n",
        "\n",
        "**A.** Apply this lesson other datasets you've worked with, like Ames Housing, Bank Marketing, or others.\n",
        "\n",
        "**B.** In additon to `RandomizedSearchCV`, scikit-learn has [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Another library called scikit-optimize has [`BayesSearchCV`](https://scikit-optimize.github.io/notebooks/sklearn-gridsearchcv-replacement.html). Experiment with these alternatives.\n",
        "\n",
        "**C.** _[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)_ discusses options for \"Grid-Searching Which Model To Use\" in Chapter 6:\n",
        "\n",
        "> You can even go further in combining GridSearchCV and Pipeline: it is also possible to search over the actual steps being performed in the pipeline (say whether to use StandardScaler or MinMaxScaler). This leads to an even bigger search space and should be considered carefully. Trying all possible solutions is usually not a viable machine learning strategy. However, here is an example comparing a RandomForestClassifier and an SVC ...\n",
        "\n",
        "The example is shown in [the accompanying notebook](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb), code cells 35-37. Could you apply this concept to your own pipelines?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIl0MLTG7N4J",
        "colab_type": "text"
      },
      "source": [
        "##Exploratory: What does the data look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYKOB_l13fSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "55d144a9-24c4-4a95-a892-69e5b8a26996"
      },
      "source": [
        "#  What does the data look like: shape? range? targe and features?\n",
        "\n",
        "daily.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1063, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfStz1Z53uv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "33e926aa-b0c7-437a-8ea1-b4d03825a3cb"
      },
      "source": [
        "daily.head()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>3475.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>83</td>\n",
              "      <td>65</td>\n",
              "      <td>3521.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>3148.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>217</td>\n",
              "      <td>89</td>\n",
              "      <td>57</td>\n",
              "      <td>3475.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>2006.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>51</td>\n",
              "      <td>3148.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>2142.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>13</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>3537.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211</td>\n",
              "      <td>78</td>\n",
              "      <td>19</td>\n",
              "      <td>2142.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2012-10-04  3475.0     0     0     0   189    83    65           3521.0\n",
              "2012-10-05  3148.0     0     0     0   217    89    57           3475.0\n",
              "2012-10-06  2006.0     0     0     0   239    78    51           3148.0\n",
              "2012-10-07  2142.0     0     0     0   239    78    13           2006.0\n",
              "2012-10-08  3537.0     0     0     0   211    78    19           2142.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi3jXh3u3sPE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d974988a-509b-4b7b-962b-1fdcca52c228"
      },
      "source": [
        "daily.tail()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-08-28</th>\n",
              "      <td>2653.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>233</td>\n",
              "      <td>156</td>\n",
              "      <td>26</td>\n",
              "      <td>4336.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-29</th>\n",
              "      <td>699.0</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>222</td>\n",
              "      <td>133</td>\n",
              "      <td>58</td>\n",
              "      <td>2653.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-30</th>\n",
              "      <td>1213.0</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>128</td>\n",
              "      <td>47</td>\n",
              "      <td>699.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-31</th>\n",
              "      <td>2823.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>161</td>\n",
              "      <td>58</td>\n",
              "      <td>1213.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-01</th>\n",
              "      <td>2876.0</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>194</td>\n",
              "      <td>139</td>\n",
              "      <td>-9999</td>\n",
              "      <td>2823.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2015-08-28  2653.0     5     0     0   233   156    26           4336.0\n",
              "2015-08-29   699.0   325     0     0   222   133    58           2653.0\n",
              "2015-08-30  1213.0   102     0     0   200   128    47            699.0\n",
              "2015-08-31  2823.0     0     0     0   189   161    58           1213.0\n",
              "2015-09-01  2876.0    58     0     0   194   139 -9999           2823.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U51_wNKg7TXw",
        "colab_type": "text"
      },
      "source": [
        "##Choose a metric for validating the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipk3Dut73yID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose a metric for validating the data\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er4hx8CF7WYL",
        "colab_type": "text"
      },
      "source": [
        "##Determine Evaluation Protocol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGtGuV5X4apT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f8b90811-5ea6-402b-8e34-4f4b2b6e75c2"
      },
      "source": [
        "# Hyperparametrer optimization and performance estimation: 3-way, train/val/test, or cross-validation w/ indpt test set\n",
        "\n",
        "# Cross-Validation w/ independent test set\n",
        "## \"Out of time\" test set(last 100 days of the data)\n",
        "\n",
        "# Everything but the last 100 days\n",
        "train = daily[:-100]\n",
        "\n",
        "# Last 100 days\n",
        "test = daily[-100:]\n",
        "\n",
        "# Shape\n",
        "train.shape, test.shape"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((963, 8), (100, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8Iap0so5TdL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e96b9b16-0855-464c-86c9-36f549d30be7"
      },
      "source": [
        "X_train = train.drop(columns='Total')\n",
        "y_train = train['Total']\n",
        "\n",
        "X_test = test.drop(columns='Total')\n",
        "y_test = test['Total']\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, X_test.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((963, 7), (963,), (100, 7), (100, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhgIT-S07zVk",
        "colab_type": "text"
      },
      "source": [
        "##Develop a first model that does better than the basic baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5zGXgoO7yL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "1306a67a-f3a7-4d62-cc0b-fd056d19ca02"
      },
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.distplot(y_train)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd5a0b5ccc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUCoUIiIS1P8Hd41s336jLrkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1Gs-gky7628",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8d379e9f-2798-4ae1-89ee-b5d86a0f703b"
      },
      "source": [
        "y_train.describe()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     963.000000\n",
              "mean     2534.329180\n",
              "std      1224.065027\n",
              "min        98.000000\n",
              "25%      1755.000000\n",
              "50%      2381.000000\n",
              "75%      3317.500000\n",
              "max      6088.000000\n",
              "Name: Total, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHP19qsh8JMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12f7df75-33e0-45a2-fc23-691159028954"
      },
      "source": [
        "#Basic Baseline 1 - Predicting the median\n",
        "y_pred = [y_train.median()] * len(y_train)\n",
        "mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "971.9376947040498"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlmWQ3_y8UWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "152a1406-f1d4-4dcc-804d-4ea970f78622"
      },
      "source": [
        "#Basic Baseline 2 - Predicting yesterday \n",
        "y_pred = X_train['Total_yesterday']\n",
        "mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "708.061266874351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBatDaFH_2AN",
        "colab_type": "text"
      },
      "source": [
        "##First model that does better than the baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfsqUFvU8b30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "scores = cross_validate(LinearRegression(), X_train, y_train,\n",
        "                       scoring='neg_mean_absolute_error', cv=3,\n",
        "                       return_train_score=True, return_estimator=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqGqPGRXAIss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f3dc0cc7-a8e4-4c69-9f57-755903440f47"
      },
      "source": [
        "pd.DataFrame(scores)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.005666</td>\n",
              "      <td>0.007856</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-555.186275</td>\n",
              "      <td>-619.509206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.004611</td>\n",
              "      <td>0.001336</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-651.126513</td>\n",
              "      <td>-583.427702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002961</td>\n",
              "      <td>0.001231</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-615.965800</td>\n",
              "      <td>-589.341301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.005666    0.007856  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "1  0.004611    0.001336  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "2  0.002961    0.001231  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -555.186275  -619.509206  \n",
              "1 -651.126513  -583.427702  \n",
              "2 -615.965800  -589.341301  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWmpYKAcAKPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "77de1503-48f7-4247-98bb-126ba7dc55c2"
      },
      "source": [
        "# sklearn default MAE is negative so putting - will change it to positive\n",
        "-scores['test_score'].mean()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "607.4261958631806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51fxU1z0APpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "d15605fa-be49-4cd0-85f3-6fedbf50da9a"
      },
      "source": [
        "for i, model in enumerate(scores['estimator']):\n",
        "  coefficents = model.coef_\n",
        "  intercept = model.intercept_\n",
        "  features_names = X_train.columns\n",
        "  \n",
        "  print(f'Model from cross-validation fold #{i}')\n",
        "  print(f'Intercept: {intercept}')\n",
        "  print(pd.Series(coefficents, features_names).to_string(),'\\n')\n",
        "  \n",
        "# SNWD coefficents are unsure since the 3 folds show negative and positive values\n",
        "# Look for consistent coefficents"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model from cross-validation fold #0\n",
            "Intercept: 566.7766337283679\n",
            "PRCP               -3.525103\n",
            "SNOW               -0.082029\n",
            "SNWD              -12.045027\n",
            "TMAX                9.475238\n",
            "TMIN               -4.607775\n",
            "AWND               -2.745191\n",
            "Total_yesterday     0.417360 \n",
            "\n",
            "Model from cross-validation fold #1\n",
            "Intercept: 671.9064515706045\n",
            "PRCP               -2.772253\n",
            "SNOW               -0.000995\n",
            "SNWD               20.800688\n",
            "TMAX                8.804948\n",
            "TMIN               -3.741386\n",
            "AWND               -6.108300\n",
            "Total_yesterday     0.405074 \n",
            "\n",
            "Model from cross-validation fold #2\n",
            "Intercept: 465.84525362296563\n",
            "PRCP               -2.876196\n",
            "SNOW               -0.016432\n",
            "SNWD               -8.809696\n",
            "TMAX               10.419441\n",
            "TMIN               -5.862868\n",
            "AWND               -2.398991\n",
            "Total_yesterday     0.423493 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq98YnB-BmWJ",
        "colab_type": "text"
      },
      "source": [
        "##Develop Overfit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgW0R6fcA0Jd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "7f50736d-3d96-4bae-f899-937cebb94822"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# n_estimator: how many trees in the forest, max_depth controls the split\n",
        "model = RandomForestRegressor(n_estimators=100, max_depth=None, n_jobs=-1)\n",
        "\n",
        "scores = cross_validate(model, X_train, y_train,\n",
        "                       scoring='neg_mean_absolute_error',\n",
        "                       cv=3, return_train_score=True,\n",
        "                       return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.491566</td>\n",
              "      <td>0.104661</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-559.963146</td>\n",
              "      <td>-241.841838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.236545</td>\n",
              "      <td>0.103508</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-643.896978</td>\n",
              "      <td>-223.905592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.242387</td>\n",
              "      <td>0.103579</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-645.845016</td>\n",
              "      <td>-226.766526</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  1.491566    0.104661  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "1  0.236545    0.103508  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "2  0.242387    0.103579  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -559.963146  -241.841838  \n",
              "1 -643.896978  -223.905592  \n",
              "2 -645.845016  -226.766526  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWWjOQcVCbKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1fe91c9e-7ddf-4df4-9331-7d39862cdd0d"
      },
      "source": [
        "-scores['test_score'].mean(), -scores['train_score'].mean()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(616.5683800623052, 230.83798546209758)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT4A4GmiC_6O",
        "colab_type": "text"
      },
      "source": [
        "##Validation curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGCa5uzvCx0N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "df4122e1-457c-49cf-b411-a33c38f4a7f4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100)\n",
        "\n",
        "depth = [2,3,4,5,6]\n",
        "train_score, val_score = validation_curve(\n",
        "    model, X_train, y_train, param_name='max_depth', # Param-name-What are we tuning\n",
        "    param_range=depth, scoring='neg_mean_absolute_error', # Param range-How much should we tune,range.\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "plt.plot(depth, np.median(train_score, axis=1), color='blue', label='traing score')\n",
        "plt.plot(depth, np.median(val_score, axis=1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('depth')\n",
        "plt.ylabel('MAE')\n",
        "\n",
        "#From the curve we can see a depth of 4 to 6 yields similar MAE"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'MAE')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZECUxIREZECUxIREZECUxIREZEC+3+ivDlzNv8UZAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y9iWGT-Eao2",
        "colab_type": "text"
      },
      "source": [
        "##RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE0uH-lLELTV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "6723d936-2613-419b-b1c8-eaa71fe3a4f8"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Give a param distribution\n",
        "param_distributions = {\n",
        "    'n_estimators': [100,200],\n",
        "    'max_depth': [4,5,6],\n",
        "    'criterion': ['mse', 'mae']\n",
        "}\n",
        "\n",
        "# Instantiate - model => param_dist=>\n",
        "r_gridsearch = RandomizedSearchCV(\n",
        "    RandomForestRegressor(n_jobs=-1, random_state=42),\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=12, # no. of param_distributions: 2*3*2\n",
        "    cv=3, scoring='neg_mean_absolute_error',\n",
        "    verbose=10, return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "r_gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.9s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    8.2s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   15.2s\n",
            "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   22.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=12, n_jobs=-1,\n",
              "          param_distributions={'n_estimators': [100, 200], 'max_depth': [4, 5, 6], 'criterion': ['mse', 'mae']},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JaoAf2iFexd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1078
        },
        "outputId": "b05b8e60-2d91-4fb2-afc9-3eee22c411e0"
      },
      "source": [
        "results = pd.DataFrame(r_gridsearch.cv_results_)\n",
        "print(f'Best result from the search of {len(results)} parameter combinations')\n",
        "results.sort_values(by='rank_test_score')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best result from the search of 12 parameter combinations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.130136</td>\n",
              "      <td>0.073371</td>\n",
              "      <td>0.107648</td>\n",
              "      <td>0.002523</td>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-537.343224</td>\n",
              "      <td>-633.188069</td>\n",
              "      <td>-611.812399</td>\n",
              "      <td>-594.114564</td>\n",
              "      <td>41.080965</td>\n",
              "      <td>1</td>\n",
              "      <td>-514.399139</td>\n",
              "      <td>-476.132208</td>\n",
              "      <td>-486.784755</td>\n",
              "      <td>-492.438701</td>\n",
              "      <td>16.125856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.111265</td>\n",
              "      <td>0.039195</td>\n",
              "      <td>0.103321</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-539.744330</td>\n",
              "      <td>-635.247773</td>\n",
              "      <td>-610.870031</td>\n",
              "      <td>-595.287378</td>\n",
              "      <td>40.516179</td>\n",
              "      <td>2</td>\n",
              "      <td>-513.924961</td>\n",
              "      <td>-475.585023</td>\n",
              "      <td>-489.148606</td>\n",
              "      <td>-492.886197</td>\n",
              "      <td>15.873771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2.021309</td>\n",
              "      <td>0.412532</td>\n",
              "      <td>0.112571</td>\n",
              "      <td>0.006524</td>\n",
              "      <td>200</td>\n",
              "      <td>6</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 6, 'criteri...</td>\n",
              "      <td>-536.176394</td>\n",
              "      <td>-634.438964</td>\n",
              "      <td>-616.764159</td>\n",
              "      <td>-595.793172</td>\n",
              "      <td>42.768523</td>\n",
              "      <td>3</td>\n",
              "      <td>-474.152025</td>\n",
              "      <td>-436.446195</td>\n",
              "      <td>-445.245440</td>\n",
              "      <td>-451.947887</td>\n",
              "      <td>16.106406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.832654</td>\n",
              "      <td>0.028402</td>\n",
              "      <td>0.112786</td>\n",
              "      <td>0.006638</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-545.553738</td>\n",
              "      <td>-635.478629</td>\n",
              "      <td>-609.898505</td>\n",
              "      <td>-596.976957</td>\n",
              "      <td>37.831612</td>\n",
              "      <td>4</td>\n",
              "      <td>-554.610927</td>\n",
              "      <td>-515.603583</td>\n",
              "      <td>-525.162173</td>\n",
              "      <td>-531.792227</td>\n",
              "      <td>16.600431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.814703</td>\n",
              "      <td>0.056312</td>\n",
              "      <td>0.109837</td>\n",
              "      <td>0.006425</td>\n",
              "      <td>200</td>\n",
              "      <td>4</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-545.615950</td>\n",
              "      <td>-634.226674</td>\n",
              "      <td>-611.571316</td>\n",
              "      <td>-597.137980</td>\n",
              "      <td>37.587285</td>\n",
              "      <td>5</td>\n",
              "      <td>-554.012714</td>\n",
              "      <td>-515.754478</td>\n",
              "      <td>-524.948497</td>\n",
              "      <td>-531.571896</td>\n",
              "      <td>16.305934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.150622</td>\n",
              "      <td>0.167337</td>\n",
              "      <td>0.115813</td>\n",
              "      <td>0.003352</td>\n",
              "      <td>100</td>\n",
              "      <td>6</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 6, 'criteri...</td>\n",
              "      <td>-540.013660</td>\n",
              "      <td>-636.042445</td>\n",
              "      <td>-619.068287</td>\n",
              "      <td>-598.374798</td>\n",
              "      <td>41.845328</td>\n",
              "      <td>6</td>\n",
              "      <td>-474.232492</td>\n",
              "      <td>-438.072399</td>\n",
              "      <td>-448.129798</td>\n",
              "      <td>-453.478229</td>\n",
              "      <td>15.239037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.414510</td>\n",
              "      <td>0.009770</td>\n",
              "      <td>0.110578</td>\n",
              "      <td>0.007367</td>\n",
              "      <td>200</td>\n",
              "      <td>6</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 6, 'criteri...</td>\n",
              "      <td>-545.032520</td>\n",
              "      <td>-634.148296</td>\n",
              "      <td>-630.734519</td>\n",
              "      <td>-603.305112</td>\n",
              "      <td>41.228507</td>\n",
              "      <td>7</td>\n",
              "      <td>-471.657315</td>\n",
              "      <td>-444.369670</td>\n",
              "      <td>-441.991815</td>\n",
              "      <td>-452.672933</td>\n",
              "      <td>13.459040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.395130</td>\n",
              "      <td>0.043782</td>\n",
              "      <td>0.103763</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-545.774354</td>\n",
              "      <td>-637.307005</td>\n",
              "      <td>-627.616934</td>\n",
              "      <td>-603.566098</td>\n",
              "      <td>41.055966</td>\n",
              "      <td>8</td>\n",
              "      <td>-524.163469</td>\n",
              "      <td>-490.204130</td>\n",
              "      <td>-490.472466</td>\n",
              "      <td>-501.613355</td>\n",
              "      <td>15.945715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.269613</td>\n",
              "      <td>0.007289</td>\n",
              "      <td>0.104972</td>\n",
              "      <td>0.002029</td>\n",
              "      <td>100</td>\n",
              "      <td>6</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 6, 'criteri...</td>\n",
              "      <td>-547.057739</td>\n",
              "      <td>-635.494678</td>\n",
              "      <td>-632.033237</td>\n",
              "      <td>-604.861885</td>\n",
              "      <td>40.898124</td>\n",
              "      <td>9</td>\n",
              "      <td>-473.010107</td>\n",
              "      <td>-445.337172</td>\n",
              "      <td>-444.033458</td>\n",
              "      <td>-454.126912</td>\n",
              "      <td>13.363038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.233440</td>\n",
              "      <td>0.042840</td>\n",
              "      <td>0.104939</td>\n",
              "      <td>0.002281</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-546.995243</td>\n",
              "      <td>-639.080607</td>\n",
              "      <td>-629.837818</td>\n",
              "      <td>-605.304556</td>\n",
              "      <td>41.403214</td>\n",
              "      <td>10</td>\n",
              "      <td>-526.882336</td>\n",
              "      <td>-490.560190</td>\n",
              "      <td>-492.252512</td>\n",
              "      <td>-503.231679</td>\n",
              "      <td>16.737805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.361412</td>\n",
              "      <td>0.032381</td>\n",
              "      <td>0.103909</td>\n",
              "      <td>0.000591</td>\n",
              "      <td>200</td>\n",
              "      <td>4</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-555.634757</td>\n",
              "      <td>-640.866167</td>\n",
              "      <td>-625.853913</td>\n",
              "      <td>-607.451613</td>\n",
              "      <td>37.149085</td>\n",
              "      <td>11</td>\n",
              "      <td>-572.252550</td>\n",
              "      <td>-529.625674</td>\n",
              "      <td>-536.655286</td>\n",
              "      <td>-546.177836</td>\n",
              "      <td>18.659615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.229610</td>\n",
              "      <td>0.046058</td>\n",
              "      <td>0.103992</td>\n",
              "      <td>0.000654</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-557.174302</td>\n",
              "      <td>-642.450417</td>\n",
              "      <td>-629.072181</td>\n",
              "      <td>-609.565633</td>\n",
              "      <td>37.446700</td>\n",
              "      <td>12</td>\n",
              "      <td>-574.472102</td>\n",
              "      <td>-530.248079</td>\n",
              "      <td>-538.576526</td>\n",
              "      <td>-547.765569</td>\n",
              "      <td>19.188016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "9        2.130136      0.073371         0.107648        0.002523   \n",
              "8        1.111265      0.039195         0.103321        0.000051   \n",
              "11       2.021309      0.412532         0.112571        0.006524   \n",
              "6        0.832654      0.028402         0.112786        0.006638   \n",
              "7        1.814703      0.056312         0.109837        0.006425   \n",
              "10       1.150622      0.167337         0.115813        0.003352   \n",
              "5        0.414510      0.009770         0.110578        0.007367   \n",
              "3        0.395130      0.043782         0.103763        0.000342   \n",
              "4        0.269613      0.007289         0.104972        0.002029   \n",
              "2        0.233440      0.042840         0.104939        0.002281   \n",
              "1        0.361412      0.032381         0.103909        0.000591   \n",
              "0        0.229610      0.046058         0.103992        0.000654   \n",
              "\n",
              "   param_n_estimators param_max_depth param_criterion  \\\n",
              "9                 200               5             mae   \n",
              "8                 100               5             mae   \n",
              "11                200               6             mae   \n",
              "6                 100               4             mae   \n",
              "7                 200               4             mae   \n",
              "10                100               6             mae   \n",
              "5                 200               6             mse   \n",
              "3                 200               5             mse   \n",
              "4                 100               6             mse   \n",
              "2                 100               5             mse   \n",
              "1                 200               4             mse   \n",
              "0                 100               4             mse   \n",
              "\n",
              "                                               params  split0_test_score  \\\n",
              "9   {'n_estimators': 200, 'max_depth': 5, 'criteri...        -537.343224   \n",
              "8   {'n_estimators': 100, 'max_depth': 5, 'criteri...        -539.744330   \n",
              "11  {'n_estimators': 200, 'max_depth': 6, 'criteri...        -536.176394   \n",
              "6   {'n_estimators': 100, 'max_depth': 4, 'criteri...        -545.553738   \n",
              "7   {'n_estimators': 200, 'max_depth': 4, 'criteri...        -545.615950   \n",
              "10  {'n_estimators': 100, 'max_depth': 6, 'criteri...        -540.013660   \n",
              "5   {'n_estimators': 200, 'max_depth': 6, 'criteri...        -545.032520   \n",
              "3   {'n_estimators': 200, 'max_depth': 5, 'criteri...        -545.774354   \n",
              "4   {'n_estimators': 100, 'max_depth': 6, 'criteri...        -547.057739   \n",
              "2   {'n_estimators': 100, 'max_depth': 5, 'criteri...        -546.995243   \n",
              "1   {'n_estimators': 200, 'max_depth': 4, 'criteri...        -555.634757   \n",
              "0   {'n_estimators': 100, 'max_depth': 4, 'criteri...        -557.174302   \n",
              "\n",
              "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "9         -633.188069        -611.812399      -594.114564       41.080965   \n",
              "8         -635.247773        -610.870031      -595.287378       40.516179   \n",
              "11        -634.438964        -616.764159      -595.793172       42.768523   \n",
              "6         -635.478629        -609.898505      -596.976957       37.831612   \n",
              "7         -634.226674        -611.571316      -597.137980       37.587285   \n",
              "10        -636.042445        -619.068287      -598.374798       41.845328   \n",
              "5         -634.148296        -630.734519      -603.305112       41.228507   \n",
              "3         -637.307005        -627.616934      -603.566098       41.055966   \n",
              "4         -635.494678        -632.033237      -604.861885       40.898124   \n",
              "2         -639.080607        -629.837818      -605.304556       41.403214   \n",
              "1         -640.866167        -625.853913      -607.451613       37.149085   \n",
              "0         -642.450417        -629.072181      -609.565633       37.446700   \n",
              "\n",
              "    rank_test_score  split0_train_score  split1_train_score  \\\n",
              "9                 1         -514.399139         -476.132208   \n",
              "8                 2         -513.924961         -475.585023   \n",
              "11                3         -474.152025         -436.446195   \n",
              "6                 4         -554.610927         -515.603583   \n",
              "7                 5         -554.012714         -515.754478   \n",
              "10                6         -474.232492         -438.072399   \n",
              "5                 7         -471.657315         -444.369670   \n",
              "3                 8         -524.163469         -490.204130   \n",
              "4                 9         -473.010107         -445.337172   \n",
              "2                10         -526.882336         -490.560190   \n",
              "1                11         -572.252550         -529.625674   \n",
              "0                12         -574.472102         -530.248079   \n",
              "\n",
              "    split2_train_score  mean_train_score  std_train_score  \n",
              "9          -486.784755       -492.438701        16.125856  \n",
              "8          -489.148606       -492.886197        15.873771  \n",
              "11         -445.245440       -451.947887        16.106406  \n",
              "6          -525.162173       -531.792227        16.600431  \n",
              "7          -524.948497       -531.571896        16.305934  \n",
              "10         -448.129798       -453.478229        15.239037  \n",
              "5          -441.991815       -452.672933        13.459040  \n",
              "3          -490.472466       -501.613355        15.945715  \n",
              "4          -444.033458       -454.126912        13.363038  \n",
              "2          -492.252512       -503.231679        16.737805  \n",
              "1          -536.655286       -546.177836        18.659615  \n",
              "0          -538.576526       -547.765569        19.188016  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBN_3LqZGcgW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ea895ace-57be-472c-9ffe-02b11f105c40"
      },
      "source": [
        "# Get the best estimator from the randomizedsearchcv\n",
        "\n",
        "r_gridsearch.best_estimator_"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=5,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeEZyN_4G16o",
        "colab_type": "text"
      },
      "source": [
        "##Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Hwdyv9GoNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modified from code cells 17-21 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "def jake_wrangle(X):  \n",
        "    X = X.copy()\n",
        "\n",
        "    # patterns of use generally vary from day to day; \n",
        "    # let's add binary columns that indicate the day of the week:\n",
        "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "    for i, day in enumerate(days):\n",
        "        X[day] = (X.index.dayofweek == i).astype(float)\n",
        "\n",
        "\n",
        "    # we might expect riders to behave differently on holidays; \n",
        "    # let's add an indicator of this as well:\n",
        "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "    cal = USFederalHolidayCalendar()\n",
        "    holidays = cal.holidays('2012', '2016')\n",
        "    X = X.join(pd.Series(1, index=holidays, name='holiday'))\n",
        "    X['holiday'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "    # We also might suspect that the hours of daylight would affect \n",
        "    # how many people ride; let's use the standard astronomical calculation \n",
        "    # to add this information:\n",
        "    def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
        "        \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
        "        days = (date - pd.datetime(2000, 12, 21)).days\n",
        "        m = (1. - np.tan(np.radians(latitude))\n",
        "             * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
        "        return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
        "\n",
        "    X['daylight_hrs'] = list(map(hours_of_daylight, X.index))\n",
        "\n",
        "    \n",
        "    # temperatures are in 1/10 deg C; convert to C\n",
        "    X['TMIN'] /= 10\n",
        "    X['TMAX'] /= 10\n",
        "    \n",
        "    # We can also calcuate the average temperature.\n",
        "    X['Temp (C)'] = 0.5 * (X['TMIN'] + X['TMAX'])\n",
        "\n",
        "    # precip is in 1/10 mm; convert to inches\n",
        "    X['PRCP'] /= 254\n",
        "\n",
        "    # In addition to the inches of precipitation, let's add a flag that \n",
        "    # indicates whether a day is dry (has zero precipitation):\n",
        "    X['dry day'] = (X['PRCP'] == 0).astype(int)\n",
        "\n",
        "\n",
        "    # Let's add a counter that increases from day 1, and measures how many \n",
        "    # years have passed. This will let us measure any observed annual increase \n",
        "    # or decrease in daily crossings:\n",
        "    X['annual'] = (X.index - X.index[0]).days / 365.\n",
        "\n",
        "    return X\n",
        "\n",
        "X_train = jake_wrangle(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMHWb8lPG4gE",
        "colab_type": "text"
      },
      "source": [
        "##Linear Regression with new features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS_HEKMdG3i9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "fca02fac-33cf-438b-d3d2-e8ef80122d7a"
      },
      "source": [
        "scores = cross_validate(LinearRegression(), X_train, y_train,\n",
        "                       scoring='neg_mean_absolute_error', cv=3,\n",
        "                       return_train_score=True, return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.010813</td>\n",
              "      <td>0.005072</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-297.692524</td>\n",
              "      <td>-294.532315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.004387</td>\n",
              "      <td>0.001734</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-300.419037</td>\n",
              "      <td>-283.779461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.004166</td>\n",
              "      <td>0.001564</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-322.640378</td>\n",
              "      <td>-283.509114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.010813    0.005072  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "1  0.004387    0.001734  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "2  0.004166    0.001564  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -297.692524  -294.532315  \n",
              "1 -300.419037  -283.779461  \n",
              "2 -322.640378  -283.509114  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7G8rdcrHKDV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8533f93a-470a-4c00-c46b-a216ef2ac3ec"
      },
      "source": [
        "# Score improves with the features added to the model\n",
        "-scores['test_score'].mean()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "306.9173130794428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpQMqlM2HURe",
        "colab_type": "text"
      },
      "source": [
        "##Random Forest with new features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRvLxmdVHOG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "d8f3c018-c1ff-409d-a41d-549cc2e05a15"
      },
      "source": [
        "param_distributions = {\n",
        "    'n_estimators': [100, 200], \n",
        "    'max_depth': [5, 10, 15], \n",
        "    'criterion': ['mae','mse']\n",
        "}\n",
        "\n",
        "r_gridsearch = RandomizedSearchCV(\n",
        "    RandomForestRegressor(n_jobs=-1, random_state=42), \n",
        "    param_distributions=param_distributions, \n",
        "    n_iter=12, \n",
        "    cv=3, \n",
        "    scoring='neg_mean_absolute_error', \n",
        "    verbose=10, \n",
        "    return_train_score=True, \n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "r_gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   15.8s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   30.3s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   42.2s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   45.4s\n",
            "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   49.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=12, n_jobs=-1,\n",
              "          param_distributions={'n_estimators': [100, 200], 'max_depth': [5, 10, 15], 'criterion': ['mae', 'mse']},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iVj8VJtHjLm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1061
        },
        "outputId": "6aff79fc-29bc-4a2e-f5b2-1626e98d7374"
      },
      "source": [
        "pd.DataFrame(r_gridsearch.cv_results_).sort_values(by='rank_test_score')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.804096</td>\n",
              "      <td>0.043257</td>\n",
              "      <td>0.110316</td>\n",
              "      <td>0.001208</td>\n",
              "      <td>200</td>\n",
              "      <td>10</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 10, 'criter...</td>\n",
              "      <td>-315.515451</td>\n",
              "      <td>-332.720534</td>\n",
              "      <td>-298.379353</td>\n",
              "      <td>-315.538446</td>\n",
              "      <td>14.019738</td>\n",
              "      <td>1</td>\n",
              "      <td>-128.276043</td>\n",
              "      <td>-120.659238</td>\n",
              "      <td>-130.271118</td>\n",
              "      <td>-126.402133</td>\n",
              "      <td>4.141715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.881737</td>\n",
              "      <td>0.106705</td>\n",
              "      <td>0.103921</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>200</td>\n",
              "      <td>15</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 15, 'criter...</td>\n",
              "      <td>-323.149926</td>\n",
              "      <td>-329.898275</td>\n",
              "      <td>-294.720332</td>\n",
              "      <td>-315.922844</td>\n",
              "      <td>15.243467</td>\n",
              "      <td>2</td>\n",
              "      <td>-105.427318</td>\n",
              "      <td>-100.092800</td>\n",
              "      <td>-110.359711</td>\n",
              "      <td>-105.293276</td>\n",
              "      <td>4.192520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.394788</td>\n",
              "      <td>0.062286</td>\n",
              "      <td>0.107314</td>\n",
              "      <td>0.003009</td>\n",
              "      <td>100</td>\n",
              "      <td>15</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 15, 'criter...</td>\n",
              "      <td>-323.043446</td>\n",
              "      <td>-331.321099</td>\n",
              "      <td>-296.776135</td>\n",
              "      <td>-317.046893</td>\n",
              "      <td>14.726566</td>\n",
              "      <td>3</td>\n",
              "      <td>-106.595676</td>\n",
              "      <td>-101.715652</td>\n",
              "      <td>-111.778023</td>\n",
              "      <td>-106.696450</td>\n",
              "      <td>4.108564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.435907</td>\n",
              "      <td>0.034487</td>\n",
              "      <td>0.107162</td>\n",
              "      <td>0.003449</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 10, 'criter...</td>\n",
              "      <td>-316.550148</td>\n",
              "      <td>-334.938789</td>\n",
              "      <td>-302.219725</td>\n",
              "      <td>-317.902887</td>\n",
              "      <td>13.391707</td>\n",
              "      <td>4</td>\n",
              "      <td>-131.622574</td>\n",
              "      <td>-122.276241</td>\n",
              "      <td>-132.089683</td>\n",
              "      <td>-128.662832</td>\n",
              "      <td>4.520027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.381803</td>\n",
              "      <td>0.088336</td>\n",
              "      <td>0.119187</td>\n",
              "      <td>0.004369</td>\n",
              "      <td>200</td>\n",
              "      <td>10</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 10, 'criter...</td>\n",
              "      <td>-339.636059</td>\n",
              "      <td>-323.365576</td>\n",
              "      <td>-300.122492</td>\n",
              "      <td>-321.041376</td>\n",
              "      <td>16.214848</td>\n",
              "      <td>5</td>\n",
              "      <td>-141.293836</td>\n",
              "      <td>-127.463446</td>\n",
              "      <td>-143.127461</td>\n",
              "      <td>-137.294914</td>\n",
              "      <td>6.992085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.649339</td>\n",
              "      <td>0.538355</td>\n",
              "      <td>0.113289</td>\n",
              "      <td>0.004672</td>\n",
              "      <td>200</td>\n",
              "      <td>15</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 15, 'criter...</td>\n",
              "      <td>-343.774081</td>\n",
              "      <td>-319.609167</td>\n",
              "      <td>-301.557150</td>\n",
              "      <td>-321.646799</td>\n",
              "      <td>17.295111</td>\n",
              "      <td>6</td>\n",
              "      <td>-110.517449</td>\n",
              "      <td>-101.515779</td>\n",
              "      <td>-113.195125</td>\n",
              "      <td>-108.409451</td>\n",
              "      <td>4.995633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.589499</td>\n",
              "      <td>0.201782</td>\n",
              "      <td>0.119014</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>100</td>\n",
              "      <td>15</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 15, 'criter...</td>\n",
              "      <td>-347.235405</td>\n",
              "      <td>-319.651340</td>\n",
              "      <td>-304.428754</td>\n",
              "      <td>-323.771833</td>\n",
              "      <td>17.716963</td>\n",
              "      <td>7</td>\n",
              "      <td>-112.552009</td>\n",
              "      <td>-102.188061</td>\n",
              "      <td>-116.336075</td>\n",
              "      <td>-110.358715</td>\n",
              "      <td>5.980495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.165762</td>\n",
              "      <td>0.060272</td>\n",
              "      <td>0.118299</td>\n",
              "      <td>0.002345</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 10, 'criter...</td>\n",
              "      <td>-349.442196</td>\n",
              "      <td>-324.468287</td>\n",
              "      <td>-297.640561</td>\n",
              "      <td>-323.850348</td>\n",
              "      <td>21.152443</td>\n",
              "      <td>8</td>\n",
              "      <td>-143.936106</td>\n",
              "      <td>-128.380117</td>\n",
              "      <td>-145.615195</td>\n",
              "      <td>-139.310472</td>\n",
              "      <td>7.759267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.621371</td>\n",
              "      <td>0.060176</td>\n",
              "      <td>0.108151</td>\n",
              "      <td>0.004888</td>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-331.627407</td>\n",
              "      <td>-389.920862</td>\n",
              "      <td>-333.878525</td>\n",
              "      <td>-351.808932</td>\n",
              "      <td>26.964870</td>\n",
              "      <td>9</td>\n",
              "      <td>-283.867200</td>\n",
              "      <td>-259.035807</td>\n",
              "      <td>-284.651644</td>\n",
              "      <td>-275.851550</td>\n",
              "      <td>11.894838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.402234</td>\n",
              "      <td>0.033243</td>\n",
              "      <td>0.111205</td>\n",
              "      <td>0.006337</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>mse</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-333.075474</td>\n",
              "      <td>-391.966189</td>\n",
              "      <td>-338.787957</td>\n",
              "      <td>-354.609873</td>\n",
              "      <td>26.517653</td>\n",
              "      <td>10</td>\n",
              "      <td>-285.416421</td>\n",
              "      <td>-260.352104</td>\n",
              "      <td>-288.596603</td>\n",
              "      <td>-278.121709</td>\n",
              "      <td>12.631905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.548615</td>\n",
              "      <td>0.033336</td>\n",
              "      <td>0.123588</td>\n",
              "      <td>0.002833</td>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-356.324579</td>\n",
              "      <td>-383.678715</td>\n",
              "      <td>-333.667445</td>\n",
              "      <td>-357.890247</td>\n",
              "      <td>20.447009</td>\n",
              "      <td>11</td>\n",
              "      <td>-298.027368</td>\n",
              "      <td>-265.316632</td>\n",
              "      <td>-293.241772</td>\n",
              "      <td>-285.528590</td>\n",
              "      <td>14.424931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.897066</td>\n",
              "      <td>0.164504</td>\n",
              "      <td>0.119509</td>\n",
              "      <td>0.001879</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-360.615374</td>\n",
              "      <td>-387.242134</td>\n",
              "      <td>-335.736137</td>\n",
              "      <td>-361.197882</td>\n",
              "      <td>21.031269</td>\n",
              "      <td>12</td>\n",
              "      <td>-299.174914</td>\n",
              "      <td>-266.206192</td>\n",
              "      <td>-294.979984</td>\n",
              "      <td>-286.787030</td>\n",
              "      <td>14.653271</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "9        0.804096      0.043257         0.110316        0.001208   \n",
              "11       0.881737      0.106705         0.103921        0.000280   \n",
              "10       0.394788      0.062286         0.107314        0.003009   \n",
              "8        0.435907      0.034487         0.107162        0.003449   \n",
              "3        6.381803      0.088336         0.119187        0.004369   \n",
              "5        6.649339      0.538355         0.113289        0.004672   \n",
              "4        3.589499      0.201782         0.119014        0.001553   \n",
              "2        3.165762      0.060272         0.118299        0.002345   \n",
              "7        0.621371      0.060176         0.108151        0.004888   \n",
              "6        0.402234      0.033243         0.111205        0.006337   \n",
              "1        4.548615      0.033336         0.123588        0.002833   \n",
              "0        1.897066      0.164504         0.119509        0.001879   \n",
              "\n",
              "   param_n_estimators param_max_depth param_criterion  \\\n",
              "9                 200              10             mse   \n",
              "11                200              15             mse   \n",
              "10                100              15             mse   \n",
              "8                 100              10             mse   \n",
              "3                 200              10             mae   \n",
              "5                 200              15             mae   \n",
              "4                 100              15             mae   \n",
              "2                 100              10             mae   \n",
              "7                 200               5             mse   \n",
              "6                 100               5             mse   \n",
              "1                 200               5             mae   \n",
              "0                 100               5             mae   \n",
              "\n",
              "                                               params  split0_test_score  \\\n",
              "9   {'n_estimators': 200, 'max_depth': 10, 'criter...        -315.515451   \n",
              "11  {'n_estimators': 200, 'max_depth': 15, 'criter...        -323.149926   \n",
              "10  {'n_estimators': 100, 'max_depth': 15, 'criter...        -323.043446   \n",
              "8   {'n_estimators': 100, 'max_depth': 10, 'criter...        -316.550148   \n",
              "3   {'n_estimators': 200, 'max_depth': 10, 'criter...        -339.636059   \n",
              "5   {'n_estimators': 200, 'max_depth': 15, 'criter...        -343.774081   \n",
              "4   {'n_estimators': 100, 'max_depth': 15, 'criter...        -347.235405   \n",
              "2   {'n_estimators': 100, 'max_depth': 10, 'criter...        -349.442196   \n",
              "7   {'n_estimators': 200, 'max_depth': 5, 'criteri...        -331.627407   \n",
              "6   {'n_estimators': 100, 'max_depth': 5, 'criteri...        -333.075474   \n",
              "1   {'n_estimators': 200, 'max_depth': 5, 'criteri...        -356.324579   \n",
              "0   {'n_estimators': 100, 'max_depth': 5, 'criteri...        -360.615374   \n",
              "\n",
              "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "9         -332.720534        -298.379353      -315.538446       14.019738   \n",
              "11        -329.898275        -294.720332      -315.922844       15.243467   \n",
              "10        -331.321099        -296.776135      -317.046893       14.726566   \n",
              "8         -334.938789        -302.219725      -317.902887       13.391707   \n",
              "3         -323.365576        -300.122492      -321.041376       16.214848   \n",
              "5         -319.609167        -301.557150      -321.646799       17.295111   \n",
              "4         -319.651340        -304.428754      -323.771833       17.716963   \n",
              "2         -324.468287        -297.640561      -323.850348       21.152443   \n",
              "7         -389.920862        -333.878525      -351.808932       26.964870   \n",
              "6         -391.966189        -338.787957      -354.609873       26.517653   \n",
              "1         -383.678715        -333.667445      -357.890247       20.447009   \n",
              "0         -387.242134        -335.736137      -361.197882       21.031269   \n",
              "\n",
              "    rank_test_score  split0_train_score  split1_train_score  \\\n",
              "9                 1         -128.276043         -120.659238   \n",
              "11                2         -105.427318         -100.092800   \n",
              "10                3         -106.595676         -101.715652   \n",
              "8                 4         -131.622574         -122.276241   \n",
              "3                 5         -141.293836         -127.463446   \n",
              "5                 6         -110.517449         -101.515779   \n",
              "4                 7         -112.552009         -102.188061   \n",
              "2                 8         -143.936106         -128.380117   \n",
              "7                 9         -283.867200         -259.035807   \n",
              "6                10         -285.416421         -260.352104   \n",
              "1                11         -298.027368         -265.316632   \n",
              "0                12         -299.174914         -266.206192   \n",
              "\n",
              "    split2_train_score  mean_train_score  std_train_score  \n",
              "9          -130.271118       -126.402133         4.141715  \n",
              "11         -110.359711       -105.293276         4.192520  \n",
              "10         -111.778023       -106.696450         4.108564  \n",
              "8          -132.089683       -128.662832         4.520027  \n",
              "3          -143.127461       -137.294914         6.992085  \n",
              "5          -113.195125       -108.409451         4.995633  \n",
              "4          -116.336075       -110.358715         5.980495  \n",
              "2          -145.615195       -139.310472         7.759267  \n",
              "7          -284.651644       -275.851550        11.894838  \n",
              "6          -288.596603       -278.121709        12.631905  \n",
              "1          -293.241772       -285.528590        14.424931  \n",
              "0          -294.979984       -286.787030        14.653271  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVh5M3JbH75t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "45b721f3-dd8f-42ab-b7fa-80ad2d1abf0c"
      },
      "source": [
        "r_gridsearch.best_estimator_"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3paNPHSpIyeN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "ba368966-b966-45aa-bff6-bb066d9c2fbe"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>holiday</th>\n",
              "      <th>daylight_hrs</th>\n",
              "      <th>Temp (C)</th>\n",
              "      <th>dry day</th>\n",
              "      <th>annual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18.9</td>\n",
              "      <td>8.3</td>\n",
              "      <td>65</td>\n",
              "      <td>3521.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.219142</td>\n",
              "      <td>13.60</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.7</td>\n",
              "      <td>8.9</td>\n",
              "      <td>57</td>\n",
              "      <td>3475.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.161038</td>\n",
              "      <td>15.30</td>\n",
              "      <td>1</td>\n",
              "      <td>0.002740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>51</td>\n",
              "      <td>3148.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.103056</td>\n",
              "      <td>15.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0.005479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>13</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.045208</td>\n",
              "      <td>15.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0.008219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.1</td>\n",
              "      <td>7.8</td>\n",
              "      <td>19</td>\n",
              "      <td>2142.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.987503</td>\n",
              "      <td>14.45</td>\n",
              "      <td>1</td>\n",
              "      <td>0.010959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday  Mon  Tue  \\\n",
              "2012-10-04   0.0     0     0  18.9   8.3    65           3521.0  0.0  0.0   \n",
              "2012-10-05   0.0     0     0  21.7   8.9    57           3475.0  0.0  0.0   \n",
              "2012-10-06   0.0     0     0  23.9   7.8    51           3148.0  0.0  0.0   \n",
              "2012-10-07   0.0     0     0  23.9   7.8    13           2006.0  0.0  0.0   \n",
              "2012-10-08   0.0     0     0  21.1   7.8    19           2142.0  1.0  0.0   \n",
              "\n",
              "            Wed  Thu  Fri  Sat  Sun  holiday  daylight_hrs  Temp (C)  dry day  \\\n",
              "2012-10-04  0.0  1.0  0.0  0.0  0.0      0.0     11.219142     13.60        1   \n",
              "2012-10-05  0.0  0.0  1.0  0.0  0.0      0.0     11.161038     15.30        1   \n",
              "2012-10-06  0.0  0.0  0.0  1.0  0.0      0.0     11.103056     15.85        1   \n",
              "2012-10-07  0.0  0.0  0.0  0.0  1.0      0.0     11.045208     15.85        1   \n",
              "2012-10-08  0.0  0.0  0.0  0.0  0.0      1.0     10.987503     14.45        1   \n",
              "\n",
              "              annual  \n",
              "2012-10-04  0.000000  \n",
              "2012-10-05  0.002740  \n",
              "2012-10-06  0.005479  \n",
              "2012-10-07  0.008219  \n",
              "2012-10-08  0.010959  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pQF9l9-QiWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop function\n",
        "def drop(df, col):\n",
        "  return df.drop(columns=col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4Ck0IkGJNTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### FEATURE ENGINEERING #####\n",
        "\n",
        "# New feature - Room temperature. Tested and little affect on model\n",
        "X_train['Room Temp'] = ((X_train['Temp (C)'] >= 20) & (X_train['Temp (C)'] <= 22.22)).astype(int)\n",
        "\n",
        "# New feature - Cold\n",
        "X_train['Cold'] = (X_train['Temp (C)'] <= 0).astype(int)\n",
        "\n",
        "# New feature - Hot\n",
        "X_train['Hot'] = (X_train['Temp (C)'] >= 26.66).astype(int)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFvmHiecSr_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "a8e798d6-af14-44cc-f6d4-e8aaf72efc79"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>...</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>holiday</th>\n",
              "      <th>daylight_hrs</th>\n",
              "      <th>Temp (C)</th>\n",
              "      <th>dry day</th>\n",
              "      <th>annual</th>\n",
              "      <th>Cold</th>\n",
              "      <th>Hot</th>\n",
              "      <th>Room Temp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18.9</td>\n",
              "      <td>8.3</td>\n",
              "      <td>65</td>\n",
              "      <td>3521.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.219142</td>\n",
              "      <td>13.60</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.7</td>\n",
              "      <td>8.9</td>\n",
              "      <td>57</td>\n",
              "      <td>3475.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.161038</td>\n",
              "      <td>15.30</td>\n",
              "      <td>1</td>\n",
              "      <td>0.002740</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>51</td>\n",
              "      <td>3148.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.103056</td>\n",
              "      <td>15.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0.005479</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>13</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.045208</td>\n",
              "      <td>15.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0.008219</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.1</td>\n",
              "      <td>7.8</td>\n",
              "      <td>19</td>\n",
              "      <td>2142.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.987503</td>\n",
              "      <td>14.45</td>\n",
              "      <td>1</td>\n",
              "      <td>0.010959</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday  Mon  Tue  \\\n",
              "2012-10-04   0.0     0     0  18.9   8.3    65           3521.0  0.0  0.0   \n",
              "2012-10-05   0.0     0     0  21.7   8.9    57           3475.0  0.0  0.0   \n",
              "2012-10-06   0.0     0     0  23.9   7.8    51           3148.0  0.0  0.0   \n",
              "2012-10-07   0.0     0     0  23.9   7.8    13           2006.0  0.0  0.0   \n",
              "2012-10-08   0.0     0     0  21.1   7.8    19           2142.0  1.0  0.0   \n",
              "\n",
              "            Wed  ...  Sat  Sun  holiday  daylight_hrs  Temp (C)  dry day  \\\n",
              "2012-10-04  0.0  ...  0.0  0.0      0.0     11.219142     13.60        1   \n",
              "2012-10-05  0.0  ...  0.0  0.0      0.0     11.161038     15.30        1   \n",
              "2012-10-06  0.0  ...  1.0  0.0      0.0     11.103056     15.85        1   \n",
              "2012-10-07  0.0  ...  0.0  1.0      0.0     11.045208     15.85        1   \n",
              "2012-10-08  0.0  ...  0.0  0.0      1.0     10.987503     14.45        1   \n",
              "\n",
              "              annual  Cold  Hot  Room Temp  \n",
              "2012-10-04  0.000000     0    0          0  \n",
              "2012-10-05  0.002740     0    0          0  \n",
              "2012-10-06  0.005479     0    0          0  \n",
              "2012-10-07  0.008219     0    0          0  \n",
              "2012-10-08  0.010959     0    0          0  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV92KSunKCre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "6053a0c1-28e4-4c94-c574-ddf0bccc00bd"
      },
      "source": [
        "#Linear Regression\n",
        "\n",
        "#Score\n",
        "scores = cross_validate(LinearRegression(), X_train, y_train, scoring='neg_mean_absolute_error', \n",
        "                        cv=3, return_train_score=True, return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.015598</td>\n",
              "      <td>0.002011</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-306.071628</td>\n",
              "      <td>-289.496384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.004085</td>\n",
              "      <td>0.001551</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-297.880104</td>\n",
              "      <td>-282.935853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.007616</td>\n",
              "      <td>0.001634</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-322.712371</td>\n",
              "      <td>-281.999342</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.015598    0.002011  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "1  0.004085    0.001551  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "2  0.007616    0.001634  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -306.071628  -289.496384  \n",
              "1 -297.880104  -282.935853  \n",
              "2 -322.712371  -281.999342  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiWkDJTLLs56",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5fc43db3-732f-4cc7-d1b3-b22c6b5e3c4b"
      },
      "source": [
        "-scores['test_score'].mean()"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "308.88803419153413"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3scXatycLyHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "864fab62-4dc9-481a-d5f5-bb87cf0ac743"
      },
      "source": [
        "# Random Forest Randomized Search\n",
        "\n",
        "param_distributions = {\n",
        "    'n_estimators': [100],\n",
        "    'max_depth': [5,10,15],\n",
        "    'criterion': ['mae']\n",
        "}\n",
        "\n",
        "r_gridsearch = RandomizedSearchCV(\n",
        "    RandomForestRegressor(n_jobs=-1, random_state=42),\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=3,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    verbose=10,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "r_gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:   12.5s remaining:    3.6s\n",
            "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   14.8s finished\n",
            "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   14.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=3, n_jobs=-1,\n",
              "          param_distributions={'n_estimators': [100], 'max_depth': [5, 10, 15], 'criterion': ['mae']},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CskQbDGNPSq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "9e606a13-64ee-4942-fb8a-f643a3ef1deb"
      },
      "source": [
        "pd.DataFrame(r_gridsearch.cv_results_).sort_values(by='rank_test_score')"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.087710</td>\n",
              "      <td>0.645201</td>\n",
              "      <td>0.113317</td>\n",
              "      <td>0.007279</td>\n",
              "      <td>100</td>\n",
              "      <td>15</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 15, 'criter...</td>\n",
              "      <td>-346.689720</td>\n",
              "      <td>-322.019315</td>\n",
              "      <td>-303.620639</td>\n",
              "      <td>-324.109891</td>\n",
              "      <td>17.644911</td>\n",
              "      <td>1</td>\n",
              "      <td>-112.078910</td>\n",
              "      <td>-103.654852</td>\n",
              "      <td>-115.282383</td>\n",
              "      <td>-110.338715</td>\n",
              "      <td>4.903813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.249569</td>\n",
              "      <td>0.027128</td>\n",
              "      <td>0.113043</td>\n",
              "      <td>0.002706</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 10, 'criter...</td>\n",
              "      <td>-349.097477</td>\n",
              "      <td>-324.146402</td>\n",
              "      <td>-301.874003</td>\n",
              "      <td>-325.039294</td>\n",
              "      <td>19.289238</td>\n",
              "      <td>2</td>\n",
              "      <td>-142.402290</td>\n",
              "      <td>-128.134977</td>\n",
              "      <td>-144.891986</td>\n",
              "      <td>-138.476417</td>\n",
              "      <td>7.382804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.317899</td>\n",
              "      <td>0.108210</td>\n",
              "      <td>0.111145</td>\n",
              "      <td>0.008242</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-362.779081</td>\n",
              "      <td>-386.728178</td>\n",
              "      <td>-337.792056</td>\n",
              "      <td>-362.433105</td>\n",
              "      <td>19.979586</td>\n",
              "      <td>3</td>\n",
              "      <td>-298.992726</td>\n",
              "      <td>-265.850382</td>\n",
              "      <td>-295.139198</td>\n",
              "      <td>-286.660768</td>\n",
              "      <td>14.799022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "2       3.087710      0.645201         0.113317        0.007279   \n",
              "1       3.249569      0.027128         0.113043        0.002706   \n",
              "0       2.317899      0.108210         0.111145        0.008242   \n",
              "\n",
              "  param_n_estimators param_max_depth param_criterion  \\\n",
              "2                100              15             mae   \n",
              "1                100              10             mae   \n",
              "0                100               5             mae   \n",
              "\n",
              "                                              params  split0_test_score  \\\n",
              "2  {'n_estimators': 100, 'max_depth': 15, 'criter...        -346.689720   \n",
              "1  {'n_estimators': 100, 'max_depth': 10, 'criter...        -349.097477   \n",
              "0  {'n_estimators': 100, 'max_depth': 5, 'criteri...        -362.779081   \n",
              "\n",
              "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "2        -322.019315        -303.620639      -324.109891       17.644911   \n",
              "1        -324.146402        -301.874003      -325.039294       19.289238   \n",
              "0        -386.728178        -337.792056      -362.433105       19.979586   \n",
              "\n",
              "   rank_test_score  split0_train_score  split1_train_score  \\\n",
              "2                1         -112.078910         -103.654852   \n",
              "1                2         -142.402290         -128.134977   \n",
              "0                3         -298.992726         -265.850382   \n",
              "\n",
              "   split2_train_score  mean_train_score  std_train_score  \n",
              "2         -115.282383       -110.338715         4.903813  \n",
              "1         -144.891986       -138.476417         7.382804  \n",
              "0         -295.139198       -286.660768        14.799022  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ecbiO_vPme_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "d310304e-dd67-48fb-cf68-6f705e3830f1"
      },
      "source": [
        "r_gridsearch.best_estimator_"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=15,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egLW8jtyTpnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}