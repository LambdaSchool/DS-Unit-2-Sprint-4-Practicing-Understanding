{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>Total_yesterday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-04</th>\n",
       "      <td>3475.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>83</td>\n",
       "      <td>65</td>\n",
       "      <td>3521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-05</th>\n",
       "      <td>3148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>89</td>\n",
       "      <td>57</td>\n",
       "      <td>3475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-06</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>78</td>\n",
       "      <td>51</td>\n",
       "      <td>3148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-07</th>\n",
       "      <td>2142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>78</td>\n",
       "      <td>13</td>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-08</th>\n",
       "      <td>3537.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>2142.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
       "2012-10-04  3475.0     0     0     0   189    83    65           3521.0\n",
       "2012-10-05  3148.0     0     0     0   217    89    57           3475.0\n",
       "2012-10-06  2006.0     0     0     0   239    78    51           3148.0\n",
       "2012-10-07  2142.0     0     0     0   239    78    13           2006.0\n",
       "2012-10-08  3537.0     0     0     0   211    78    19           2142.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fremont_bridge = 'https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD'\n",
    "\n",
    "bicycle_weather = 'https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv'\n",
    "\n",
    "counts = pd.read_csv(fremont_bridge, index_col='Date', parse_dates=True, \n",
    "                     infer_datetime_format=True)\n",
    "\n",
    "weather = pd.read_csv(bicycle_weather, index_col='DATE', parse_dates=True, \n",
    "                      infer_datetime_format=True)\n",
    "\n",
    "daily = counts.resample('d').sum()\n",
    "daily['Total'] = daily.sum(axis=1)\n",
    "daily = daily[['Total']] # remove other columns\n",
    "\n",
    "weather_columns = ['PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND']\n",
    "daily = daily.join(weather[weather_columns], how='inner')\n",
    "\n",
    "# Make a feature for yesterday's total\n",
    "daily['Total_yesterday'] = daily.Total.shift(1)\n",
    "daily = daily.drop(index=daily.index[0])\n",
    "\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test/Train Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = daily.drop(columns='Total')[:-100]\n",
    "X_test = daily.drop(columns='Total')[-100:]\n",
    "\n",
    "y_train = daily['Total'][:-100]\n",
    "y_test = daily['Total'][-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((963, 7), (100, 7), (963,), (100,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect & Replace Incorrect  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>Total_yesterday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2632.449671</td>\n",
       "      <td>29.350894</td>\n",
       "      <td>-37.496707</td>\n",
       "      <td>0.098777</td>\n",
       "      <td>166.863594</td>\n",
       "      <td>84.472248</td>\n",
       "      <td>22.338664</td>\n",
       "      <td>2633.056444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1252.864020</td>\n",
       "      <td>65.813053</td>\n",
       "      <td>612.512583</td>\n",
       "      <td>2.570041</td>\n",
       "      <td>74.779734</td>\n",
       "      <td>50.916006</td>\n",
       "      <td>307.984292</td>\n",
       "      <td>1253.138245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-16.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1806.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1806.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2435.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2435.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3574.500000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3574.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6088.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>6088.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total         PRCP         SNOW         SNWD         TMAX  \\\n",
       "count  1063.000000  1063.000000  1063.000000  1063.000000  1063.000000   \n",
       "mean   2632.449671    29.350894   -37.496707     0.098777   166.863594   \n",
       "std    1252.864020    65.813053   612.512583     2.570041    74.779734   \n",
       "min      98.000000     0.000000 -9999.000000     0.000000   -16.000000   \n",
       "25%    1806.000000     0.000000     0.000000     0.000000   111.000000   \n",
       "50%    2435.000000     0.000000     0.000000     0.000000   150.000000   \n",
       "75%    3574.500000    26.500000     0.000000     0.000000   222.000000   \n",
       "max    6088.000000   559.000000    74.000000    80.000000   356.000000   \n",
       "\n",
       "              TMIN         AWND  Total_yesterday  \n",
       "count  1063.000000  1063.000000      1063.000000  \n",
       "mean     84.472248    22.338664      2633.056444  \n",
       "std      50.916006   307.984292      1253.138245  \n",
       "min     -71.000000 -9999.000000        98.000000  \n",
       "25%      44.000000    22.000000      1806.000000  \n",
       "50%      83.000000    29.000000      2435.000000  \n",
       "75%     128.000000    40.000000      3574.500000  \n",
       "max     183.000000    95.000000      6088.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(X):\n",
    "    AWND_mean = X_train['AWND'].mean()\n",
    "    SNOW_mean = X_train['SNOW'].mean()\n",
    "\n",
    "    X['AWND'] = X['AWND'].replace({-9999:AWND_mean})\n",
    "    X['SNOW'] = X['SNOW'].replace({-9999:SNOW_mean})\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clean(X_train)\n",
    "X_test = clean(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(X):\n",
    "    X = X.copy()\n",
    "\n",
    "    # patterns of use generally vary from day to day; \n",
    "    # let's add binary columns that indicate the day of the week:\n",
    "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    for i, day in enumerate(days):\n",
    "        X[day] = (X.index.dayofweek == i).astype(float)\n",
    "\n",
    "\n",
    "    # we might expect riders to behave differently on holidays; \n",
    "    # let's add an indicator of this as well:\n",
    "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "    cal = USFederalHolidayCalendar()\n",
    "    holidays = cal.holidays('2012', '2016')\n",
    "    X = X.join(pd.Series(1, index=holidays, name='holiday'))\n",
    "    X['holiday'].fillna(0, inplace=True)\n",
    "    \n",
    "    # We also might suspect that the hours of daylight would affect \n",
    "    # how many people ride; let's use the standard astronomical calculation \n",
    "    # to add this information:\n",
    "    def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
    "        \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
    "        days = (date - pd.datetime(2000, 12, 21)).days\n",
    "        m = (1. - np.tan(np.radians(latitude))\n",
    "             * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
    "        return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
    "\n",
    "    X['daylight_hrs'] = list(map(hours_of_daylight, X.index))\n",
    "    \n",
    "    # temperatures are in 1/10 deg C; convert to C\n",
    "    X['TMIN'] /= 10\n",
    "    X['TMAX'] /= 10\n",
    "    \n",
    "    # We can also calcuate the average temperature.\n",
    "    X['Temp (C)'] = 0.5 * (X['TMIN'] + X['TMAX'])\n",
    "    \n",
    "    # Convert Temperatures to Farenheit\n",
    "    X['TMIN'] = X['TMIN'] * 1.8 + 32\n",
    "    X['TMAX'] = X['TMAX'] * 1.8 + 32\n",
    "    X['Temp (C)'] = X['Temp (C)'] * 1.8 + 32\n",
    "    X = X.rename(columns={'Temp (C)':'Temp (F)'})\n",
    "    \n",
    "    # precip is in 1/10 mm; convert to inches\n",
    "    X['PRCP'] /= 254\n",
    "\n",
    "    # In addition to the inches of precipitation, let's add a flag that \n",
    "    # indicates whether a day is dry (has zero precipitation):\n",
    "    X['dry day'] = (X['PRCP'] == 0).astype(int)\n",
    "\n",
    "    # Let's add a counter that increases from day 1, and measures how many \n",
    "    # years have passed. This will let us measure any observed annual increase \n",
    "    # or decrease in daily crossings:\n",
    "    X['annual'] = (X.index - X.index[0]).days / 365.\n",
    "    \n",
    "    # Create feature to indicate how many standardeviations from the mean the data is \n",
    "    temp_mean = X['Temp (F)'].mean()\n",
    "    temp_std = X['Temp (F)'].std()\n",
    "    X['Temp_STD_from_mean'] = abs(X['Temp (F)'] - temp_mean) / temp_std\n",
    "    \n",
    "    # Create feature that record's the temperate from yesterday\n",
    "    X['Yesterdays Temp'] = X.tshift(periods=1)['Temp (F)'] \n",
    "    X['Yesterdays Temp'] = X['Yesterdays Temp'].fillna(method='bfill')\n",
    "    \n",
    "    # Create feature that records the total number of crossings from a week ago\n",
    "    X['Total_yesterday'] = X.shift(periods=7)['Total_yesterday']\n",
    "    X['Total_yesterday'] = X['Total_yesterday'].fillna(method='bfill')\n",
    "    \n",
    "    # DS1 DH\n",
    "    X['PRCP_yesterday'] = X.PRCP.shift(1).fillna(X.PRCP.mean())\n",
    "    X['Windchill'] = (((X['Temp (F)'] * (9/5) + 32) * .6215) + 34.74) - (35.75 * (X['AWND']** .16)) + (.4275 * (X['Temp (F)'])) * (X['AWND'] ** .16)\n",
    "    X['Rl_Cold'] = (((X['Temp (F)'] * (9/5) + 32) - X['Windchill']) -32) * (5/9)\n",
    "    X['TMIN_squared'] = X['TMIN'] **2\n",
    "    \n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    for i, month in enumerate(months):\n",
    "        X[month] = (X.index.month == i+1).astype(float)\n",
    "    \n",
    "    # DS3 JD\n",
    "    X['light_rain'] = (X['PRCP'] > 0) & (X['PRCP'] < 0.10)\n",
    "    X['moderate_rain'] = (X['PRCP'] >= 0.1) & (X['PRCP'] < 0.30)\n",
    "    X['heavy_rain'] = (X['PRCP'] >= 0.30)\n",
    "    X['weekend_day'] = (X['Sat'] == 1) | (X['Sun'] == 1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = make_features(X_train)\n",
    "X_test = make_features(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = ['PRCP', 'SNWD', 'TMAX', 'TMIN', 'AWND', 'Total_yesterday', 'daylight_hrs', 'Temp (F)', 'annual', 'Temp_STD_from_mean', 'Yesterdays Temp']\n",
    "preprocess = make_column_transformer(\n",
    "    (StandardScaler(), cont_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "build_boost = Pipeline(steps=[\n",
    "        ('model', XGBRegressor(n_jobs=-1))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators':[100, 125, 150, 250],\n",
    "    'model__learning_rate':[.04, .05, .06],\n",
    "    'model__max_depth':[5, 6, 7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('model', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'model__n_estimators': [100, 125, 150, 250], 'model__learning_rate': [0.04, 0.05, 0.06], 'model__max_depth': [5, 6, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search = GridSearchCV(build_boost, \n",
    "                      param_grid=param_grid, \n",
    "                      return_train_score=True, \n",
    "                      scoring='neg_mean_absolute_error', \n",
    "                      cv=3,\n",
    "                      n_jobs=-1)\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -291.28709974120585\n",
      "Best Params: {'model__learning_rate': 0.04, 'model__max_depth': 5, 'model__n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score:', search.best_score_)\n",
    "print('Best Params:', search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__learning_rate</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.196210</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'model__learning_rate': 0.04, 'model__max_dep...</td>\n",
       "      <td>-287.049677</td>\n",
       "      <td>-304.859678</td>\n",
       "      <td>-281.951944</td>\n",
       "      <td>-291.287100</td>\n",
       "      <td>9.820315</td>\n",
       "      <td>1</td>\n",
       "      <td>-70.680155</td>\n",
       "      <td>-70.904577</td>\n",
       "      <td>-71.617907</td>\n",
       "      <td>-71.067546</td>\n",
       "      <td>0.399803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.725579</td>\n",
       "      <td>0.012758</td>\n",
       "      <td>0.007034</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'model__learning_rate': 0.04, 'model__max_dep...</td>\n",
       "      <td>-282.926755</td>\n",
       "      <td>-307.632552</td>\n",
       "      <td>-286.209392</td>\n",
       "      <td>-292.256233</td>\n",
       "      <td>10.954978</td>\n",
       "      <td>2</td>\n",
       "      <td>-101.643501</td>\n",
       "      <td>-96.254972</td>\n",
       "      <td>-98.833348</td>\n",
       "      <td>-98.910607</td>\n",
       "      <td>2.200536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.609074</td>\n",
       "      <td>0.025311</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>{'model__learning_rate': 0.04, 'model__max_dep...</td>\n",
       "      <td>-276.345727</td>\n",
       "      <td>-315.098382</td>\n",
       "      <td>-286.310447</td>\n",
       "      <td>-292.584852</td>\n",
       "      <td>16.431031</td>\n",
       "      <td>3</td>\n",
       "      <td>-113.759979</td>\n",
       "      <td>-108.629875</td>\n",
       "      <td>-112.815375</td>\n",
       "      <td>-111.735077</td>\n",
       "      <td>2.229316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.624397</td>\n",
       "      <td>0.052786</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>-272.937854</td>\n",
       "      <td>-313.292727</td>\n",
       "      <td>-292.181383</td>\n",
       "      <td>-292.803988</td>\n",
       "      <td>16.480689</td>\n",
       "      <td>4</td>\n",
       "      <td>-82.396344</td>\n",
       "      <td>-77.062454</td>\n",
       "      <td>-78.991447</td>\n",
       "      <td>-79.483415</td>\n",
       "      <td>2.205164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.875598</td>\n",
       "      <td>0.034120</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>-282.428511</td>\n",
       "      <td>-306.077799</td>\n",
       "      <td>-292.214122</td>\n",
       "      <td>-293.573477</td>\n",
       "      <td>9.702512</td>\n",
       "      <td>5</td>\n",
       "      <td>-65.164959</td>\n",
       "      <td>-63.786570</td>\n",
       "      <td>-61.987985</td>\n",
       "      <td>-63.646505</td>\n",
       "      <td>1.300770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.490528</td>\n",
       "      <td>0.007414</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>-275.858107</td>\n",
       "      <td>-314.810933</td>\n",
       "      <td>-290.079069</td>\n",
       "      <td>-293.582703</td>\n",
       "      <td>16.094249</td>\n",
       "      <td>6</td>\n",
       "      <td>-113.830659</td>\n",
       "      <td>-108.315825</td>\n",
       "      <td>-114.410626</td>\n",
       "      <td>-112.185704</td>\n",
       "      <td>2.746641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.609491</td>\n",
       "      <td>0.011470</td>\n",
       "      <td>0.006885</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>-282.521621</td>\n",
       "      <td>-307.551070</td>\n",
       "      <td>-292.463451</td>\n",
       "      <td>-294.178714</td>\n",
       "      <td>10.289960</td>\n",
       "      <td>7</td>\n",
       "      <td>-98.939241</td>\n",
       "      <td>-93.283794</td>\n",
       "      <td>-98.709932</td>\n",
       "      <td>-96.977656</td>\n",
       "      <td>2.613632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.220476</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>-287.291263</td>\n",
       "      <td>-308.845733</td>\n",
       "      <td>-286.936088</td>\n",
       "      <td>-294.357695</td>\n",
       "      <td>10.245616</td>\n",
       "      <td>8</td>\n",
       "      <td>-57.114979</td>\n",
       "      <td>-61.566700</td>\n",
       "      <td>-62.394590</td>\n",
       "      <td>-60.358757</td>\n",
       "      <td>2.318465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.724368</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>-285.029646</td>\n",
       "      <td>-306.188680</td>\n",
       "      <td>-292.866001</td>\n",
       "      <td>-294.694776</td>\n",
       "      <td>8.734395</td>\n",
       "      <td>9</td>\n",
       "      <td>-88.729764</td>\n",
       "      <td>-84.572143</td>\n",
       "      <td>-89.119254</td>\n",
       "      <td>-87.473720</td>\n",
       "      <td>2.057878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.927429</td>\n",
       "      <td>0.048259</td>\n",
       "      <td>0.012950</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>-285.996297</td>\n",
       "      <td>-306.326635</td>\n",
       "      <td>-292.301772</td>\n",
       "      <td>-294.874901</td>\n",
       "      <td>8.496918</td>\n",
       "      <td>10</td>\n",
       "      <td>-54.811136</td>\n",
       "      <td>-54.841162</td>\n",
       "      <td>-53.833561</td>\n",
       "      <td>-54.495287</td>\n",
       "      <td>0.468071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.472834</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__learning_rate': 0.04, 'model__max_dep...</td>\n",
       "      <td>-264.532393</td>\n",
       "      <td>-332.632264</td>\n",
       "      <td>-287.996232</td>\n",
       "      <td>-295.053630</td>\n",
       "      <td>28.245982</td>\n",
       "      <td>11</td>\n",
       "      <td>-138.498035</td>\n",
       "      <td>-130.951017</td>\n",
       "      <td>-136.593107</td>\n",
       "      <td>-135.347386</td>\n",
       "      <td>3.204501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.444431</td>\n",
       "      <td>0.030441</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>-283.971854</td>\n",
       "      <td>-310.355237</td>\n",
       "      <td>-291.208055</td>\n",
       "      <td>-295.178382</td>\n",
       "      <td>11.130839</td>\n",
       "      <td>12</td>\n",
       "      <td>-29.705272</td>\n",
       "      <td>-35.252038</td>\n",
       "      <td>-31.984031</td>\n",
       "      <td>-32.313780</td>\n",
       "      <td>2.276431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.218886</td>\n",
       "      <td>0.013646</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>{'model__learning_rate': 0.06, 'model__max_dep...</td>\n",
       "      <td>-296.563841</td>\n",
       "      <td>-312.438115</td>\n",
       "      <td>-279.410272</td>\n",
       "      <td>-296.137409</td>\n",
       "      <td>13.486931</td>\n",
       "      <td>13</td>\n",
       "      <td>-47.184112</td>\n",
       "      <td>-50.901001</td>\n",
       "      <td>-50.501291</td>\n",
       "      <td>-49.528801</td>\n",
       "      <td>1.665957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.723058</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'model__learning_rate': 0.06, 'model__max_dep...</td>\n",
       "      <td>-297.607990</td>\n",
       "      <td>-309.518108</td>\n",
       "      <td>-283.944028</td>\n",
       "      <td>-297.023375</td>\n",
       "      <td>10.448755</td>\n",
       "      <td>14</td>\n",
       "      <td>-77.379594</td>\n",
       "      <td>-74.021296</td>\n",
       "      <td>-77.908193</td>\n",
       "      <td>-76.436361</td>\n",
       "      <td>1.721290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.497995</td>\n",
       "      <td>0.020639</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__learning_rate': 0.06, 'model__max_dep...</td>\n",
       "      <td>-293.236318</td>\n",
       "      <td>-310.059178</td>\n",
       "      <td>-288.309360</td>\n",
       "      <td>-297.201619</td>\n",
       "      <td>9.311511</td>\n",
       "      <td>15</td>\n",
       "      <td>-100.891208</td>\n",
       "      <td>-96.024043</td>\n",
       "      <td>-101.474023</td>\n",
       "      <td>-99.463092</td>\n",
       "      <td>2.443387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.631551</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>{'model__learning_rate': 0.06, 'model__max_dep...</td>\n",
       "      <td>-297.010415</td>\n",
       "      <td>-307.787440</td>\n",
       "      <td>-287.876151</td>\n",
       "      <td>-297.558002</td>\n",
       "      <td>8.137966</td>\n",
       "      <td>16</td>\n",
       "      <td>-87.822865</td>\n",
       "      <td>-83.336566</td>\n",
       "      <td>-88.051784</td>\n",
       "      <td>-86.403738</td>\n",
       "      <td>2.170831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.475472</td>\n",
       "      <td>0.025301</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>{'model__learning_rate': 0.06, 'model__max_dep...</td>\n",
       "      <td>-294.434505</td>\n",
       "      <td>-312.704045</td>\n",
       "      <td>-290.882323</td>\n",
       "      <td>-299.340291</td>\n",
       "      <td>9.560228</td>\n",
       "      <td>17</td>\n",
       "      <td>-20.913635</td>\n",
       "      <td>-27.383334</td>\n",
       "      <td>-24.172491</td>\n",
       "      <td>-24.156487</td>\n",
       "      <td>2.641268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.608941</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.04</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__learning_rate': 0.04, 'model__max_dep...</td>\n",
       "      <td>-280.714424</td>\n",
       "      <td>-324.556671</td>\n",
       "      <td>-293.553279</td>\n",
       "      <td>-299.608125</td>\n",
       "      <td>18.403469</td>\n",
       "      <td>18</td>\n",
       "      <td>-105.379518</td>\n",
       "      <td>-99.208724</td>\n",
       "      <td>-104.627266</td>\n",
       "      <td>-103.071836</td>\n",
       "      <td>2.748842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.863308</td>\n",
       "      <td>0.011645</td>\n",
       "      <td>0.008311</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>{'model__learning_rate': 0.06, 'model__max_dep...</td>\n",
       "      <td>-294.257375</td>\n",
       "      <td>-309.842911</td>\n",
       "      <td>-296.898701</td>\n",
       "      <td>-300.332996</td>\n",
       "      <td>6.810434</td>\n",
       "      <td>19</td>\n",
       "      <td>-43.732707</td>\n",
       "      <td>-46.995642</td>\n",
       "      <td>-43.360484</td>\n",
       "      <td>-44.696278</td>\n",
       "      <td>1.632982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.566021</td>\n",
       "      <td>0.021239</td>\n",
       "      <td>0.011880</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__learning_rate': 0.06, 'model__max_dep...</td>\n",
       "      <td>-295.912367</td>\n",
       "      <td>-308.939820</td>\n",
       "      <td>-297.743382</td>\n",
       "      <td>-300.865190</td>\n",
       "      <td>5.758350</td>\n",
       "      <td>20</td>\n",
       "      <td>-67.423226</td>\n",
       "      <td>-66.539156</td>\n",
       "      <td>-62.242800</td>\n",
       "      <td>-65.401727</td>\n",
       "      <td>2.262669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.654791</td>\n",
       "      <td>0.020988</td>\n",
       "      <td>0.007052</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>-297.852583</td>\n",
       "      <td>-311.491624</td>\n",
       "      <td>-293.875557</td>\n",
       "      <td>-301.073255</td>\n",
       "      <td>7.543695</td>\n",
       "      <td>21</td>\n",
       "      <td>-55.927539</td>\n",
       "      <td>-51.825030</td>\n",
       "      <td>-51.876762</td>\n",
       "      <td>-53.209777</td>\n",
       "      <td>1.921864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.721764</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>0.010569</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>{'model__learning_rate': 0.06, 'model__max_dep...</td>\n",
       "      <td>-297.724725</td>\n",
       "      <td>-307.732672</td>\n",
       "      <td>-297.782910</td>\n",
       "      <td>-301.080102</td>\n",
       "      <td>4.704137</td>\n",
       "      <td>22</td>\n",
       "      <td>-52.897372</td>\n",
       "      <td>-54.635942</td>\n",
       "      <td>-51.319328</td>\n",
       "      <td>-52.950881</td>\n",
       "      <td>1.354530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.823531</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.04</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>{'model__learning_rate': 0.04, 'model__max_dep...</td>\n",
       "      <td>-293.963489</td>\n",
       "      <td>-314.138610</td>\n",
       "      <td>-296.077181</td>\n",
       "      <td>-301.393093</td>\n",
       "      <td>9.053657</td>\n",
       "      <td>23</td>\n",
       "      <td>-80.866506</td>\n",
       "      <td>-76.424033</td>\n",
       "      <td>-79.187063</td>\n",
       "      <td>-78.825868</td>\n",
       "      <td>1.831527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.031352</td>\n",
       "      <td>0.007921</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__learning_rate': 0.04, 'model__max_dep...</td>\n",
       "      <td>-280.126562</td>\n",
       "      <td>-321.761573</td>\n",
       "      <td>-302.734257</td>\n",
       "      <td>-301.540797</td>\n",
       "      <td>17.018359</td>\n",
       "      <td>24</td>\n",
       "      <td>-85.445682</td>\n",
       "      <td>-80.329458</td>\n",
       "      <td>-78.689131</td>\n",
       "      <td>-81.488090</td>\n",
       "      <td>2.877449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.808114</td>\n",
       "      <td>0.017140</td>\n",
       "      <td>0.007391</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7</td>\n",
       "      <td>125</td>\n",
       "      <td>{'model__learning_rate': 0.04, 'model__max_dep...</td>\n",
       "      <td>-294.597083</td>\n",
       "      <td>-309.089459</td>\n",
       "      <td>-301.903914</td>\n",
       "      <td>-301.863485</td>\n",
       "      <td>5.916557</td>\n",
       "      <td>25</td>\n",
       "      <td>-58.247205</td>\n",
       "      <td>-52.788342</td>\n",
       "      <td>-53.871238</td>\n",
       "      <td>-54.968928</td>\n",
       "      <td>2.359871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.687772</td>\n",
       "      <td>0.094985</td>\n",
       "      <td>0.018488</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>0.04</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>{'model__learning_rate': 0.04, 'model__max_dep...</td>\n",
       "      <td>-302.448286</td>\n",
       "      <td>-308.590641</td>\n",
       "      <td>-298.578378</td>\n",
       "      <td>-303.205768</td>\n",
       "      <td>4.122434</td>\n",
       "      <td>26</td>\n",
       "      <td>-39.071327</td>\n",
       "      <td>-41.524715</td>\n",
       "      <td>-39.584095</td>\n",
       "      <td>-40.060046</td>\n",
       "      <td>1.056622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.933175</td>\n",
       "      <td>0.015128</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.04</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>{'model__learning_rate': 0.04, 'model__max_dep...</td>\n",
       "      <td>-303.423981</td>\n",
       "      <td>-309.998636</td>\n",
       "      <td>-299.498653</td>\n",
       "      <td>-304.307090</td>\n",
       "      <td>4.331845</td>\n",
       "      <td>27</td>\n",
       "      <td>-66.588368</td>\n",
       "      <td>-62.922064</td>\n",
       "      <td>-64.532325</td>\n",
       "      <td>-64.680919</td>\n",
       "      <td>1.500446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.705586</td>\n",
       "      <td>0.036075</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__learning_rate': 0.06, 'model__max_dep...</td>\n",
       "      <td>-305.249162</td>\n",
       "      <td>-309.230111</td>\n",
       "      <td>-298.977704</td>\n",
       "      <td>-304.485659</td>\n",
       "      <td>4.220203</td>\n",
       "      <td>28</td>\n",
       "      <td>-42.733068</td>\n",
       "      <td>-41.455464</td>\n",
       "      <td>-39.029723</td>\n",
       "      <td>-41.072752</td>\n",
       "      <td>1.535913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.797013</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>125</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>-309.062400</td>\n",
       "      <td>-308.069814</td>\n",
       "      <td>-297.069262</td>\n",
       "      <td>-304.733825</td>\n",
       "      <td>5.434792</td>\n",
       "      <td>29</td>\n",
       "      <td>-41.576985</td>\n",
       "      <td>-37.453748</td>\n",
       "      <td>-35.943076</td>\n",
       "      <td>-38.324603</td>\n",
       "      <td>2.381039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.852727</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7</td>\n",
       "      <td>125</td>\n",
       "      <td>{'model__learning_rate': 0.06, 'model__max_dep...</td>\n",
       "      <td>-310.212176</td>\n",
       "      <td>-307.877582</td>\n",
       "      <td>-298.584563</td>\n",
       "      <td>-305.558107</td>\n",
       "      <td>5.022305</td>\n",
       "      <td>30</td>\n",
       "      <td>-31.191000</td>\n",
       "      <td>-31.541957</td>\n",
       "      <td>-28.080447</td>\n",
       "      <td>-30.271135</td>\n",
       "      <td>1.555662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.381870</td>\n",
       "      <td>0.031046</td>\n",
       "      <td>0.010189</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>{'model__learning_rate': 0.06, 'model__max_dep...</td>\n",
       "      <td>-310.963212</td>\n",
       "      <td>-308.082765</td>\n",
       "      <td>-297.795379</td>\n",
       "      <td>-305.613785</td>\n",
       "      <td>5.652129</td>\n",
       "      <td>31</td>\n",
       "      <td>-10.347392</td>\n",
       "      <td>-11.453772</td>\n",
       "      <td>-10.695445</td>\n",
       "      <td>-10.832203</td>\n",
       "      <td>0.461913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.962483</td>\n",
       "      <td>0.030692</td>\n",
       "      <td>0.009883</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'model__learning_rate': 0.04, 'model__max_dep...</td>\n",
       "      <td>-308.062230</td>\n",
       "      <td>-305.692007</td>\n",
       "      <td>-303.241807</td>\n",
       "      <td>-305.665348</td>\n",
       "      <td>1.968020</td>\n",
       "      <td>32</td>\n",
       "      <td>-44.960723</td>\n",
       "      <td>-40.650301</td>\n",
       "      <td>-40.857984</td>\n",
       "      <td>-42.156336</td>\n",
       "      <td>1.984813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.985745</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'model__learning_rate': 0.06, 'model__max_dep...</td>\n",
       "      <td>-311.195130</td>\n",
       "      <td>-308.027986</td>\n",
       "      <td>-298.486542</td>\n",
       "      <td>-305.903220</td>\n",
       "      <td>5.401421</td>\n",
       "      <td>33</td>\n",
       "      <td>-24.341667</td>\n",
       "      <td>-25.343804</td>\n",
       "      <td>-22.033438</td>\n",
       "      <td>-23.906303</td>\n",
       "      <td>1.386070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.952117</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>-314.153933</td>\n",
       "      <td>-306.810230</td>\n",
       "      <td>-297.358617</td>\n",
       "      <td>-306.107593</td>\n",
       "      <td>6.874636</td>\n",
       "      <td>34</td>\n",
       "      <td>-31.661146</td>\n",
       "      <td>-29.984025</td>\n",
       "      <td>-28.564055</td>\n",
       "      <td>-30.069742</td>\n",
       "      <td>1.265834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.600406</td>\n",
       "      <td>0.031948</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>-316.248212</td>\n",
       "      <td>-307.093675</td>\n",
       "      <td>-295.522599</td>\n",
       "      <td>-306.288162</td>\n",
       "      <td>8.480346</td>\n",
       "      <td>35</td>\n",
       "      <td>-15.821322</td>\n",
       "      <td>-15.957919</td>\n",
       "      <td>-11.859692</td>\n",
       "      <td>-14.546311</td>\n",
       "      <td>1.900544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.631352</td>\n",
       "      <td>0.035854</td>\n",
       "      <td>0.016410</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>{'model__learning_rate': 0.04, 'model__max_dep...</td>\n",
       "      <td>-313.941381</td>\n",
       "      <td>-303.764192</td>\n",
       "      <td>-301.897934</td>\n",
       "      <td>-306.534502</td>\n",
       "      <td>5.292581</td>\n",
       "      <td>36</td>\n",
       "      <td>-21.328616</td>\n",
       "      <td>-24.237766</td>\n",
       "      <td>-21.665805</td>\n",
       "      <td>-22.410729</td>\n",
       "      <td>1.299223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3        1.196210      0.010767         0.009908        0.000448   \n",
       "2        0.725579      0.012758         0.007034        0.000302   \n",
       "1        0.609074      0.025311         0.006511        0.000198   \n",
       "16       0.624397      0.052786         0.010526        0.004732   \n",
       "17       0.875598      0.034120         0.020348        0.014442   \n",
       "12       0.490528      0.007414         0.008120        0.002829   \n",
       "13       0.609491      0.011470         0.006885        0.000248   \n",
       "15       1.220476      0.033993         0.013934        0.002417   \n",
       "14       0.724368      0.003926         0.007731        0.000602   \n",
       "18       0.927429      0.048259         0.012950        0.003795   \n",
       "0        0.472834      0.001975         0.009331        0.001925   \n",
       "19       1.444431      0.030441         0.011418        0.000531   \n",
       "27       1.218886      0.013646         0.010304        0.000749   \n",
       "26       0.723058      0.005368         0.007630        0.000703   \n",
       "24       0.497995      0.020639         0.006418        0.000111   \n",
       "25       0.631551      0.001969         0.006800        0.000528   \n",
       "31       1.475472      0.025301         0.015501        0.002945   \n",
       "4        0.608941      0.070211         0.007995        0.001664   \n",
       "30       0.863308      0.011645         0.008311        0.000176   \n",
       "28       0.566021      0.021239         0.011880        0.007121   \n",
       "20       0.654791      0.020988         0.007052        0.000117   \n",
       "29       0.721764      0.013029         0.010569        0.003744   \n",
       "5        0.823531      0.012241         0.010875        0.004087   \n",
       "8        0.811869      0.031352         0.007921        0.001083   \n",
       "9        0.808114      0.017140         0.007391        0.000132   \n",
       "7        1.687772      0.094985         0.018488        0.006079   \n",
       "6        0.933175      0.015128         0.008181        0.000766   \n",
       "32       0.705586      0.036075         0.007980        0.000897   \n",
       "21       0.797013      0.013731         0.007528        0.000203   \n",
       "33       0.852727      0.002735         0.008221        0.000459   \n",
       "35       1.381870      0.031046         0.010189        0.000896   \n",
       "10       0.962483      0.030692         0.009883        0.000721   \n",
       "34       0.985745      0.018801         0.009009        0.000086   \n",
       "22       0.952117      0.005871         0.008979        0.000637   \n",
       "23       1.600406      0.031948         0.013594        0.001197   \n",
       "11       1.631352      0.035854         0.016410        0.003918   \n",
       "\n",
       "   param_model__learning_rate param_model__max_depth  \\\n",
       "3                        0.04                      5   \n",
       "2                        0.04                      5   \n",
       "1                        0.04                      5   \n",
       "16                       0.05                      6   \n",
       "17                       0.05                      6   \n",
       "12                       0.05                      5   \n",
       "13                       0.05                      5   \n",
       "15                       0.05                      5   \n",
       "14                       0.05                      5   \n",
       "18                       0.05                      6   \n",
       "0                        0.04                      5   \n",
       "19                       0.05                      6   \n",
       "27                       0.06                      5   \n",
       "26                       0.06                      5   \n",
       "24                       0.06                      5   \n",
       "25                       0.06                      5   \n",
       "31                       0.06                      6   \n",
       "4                        0.04                      6   \n",
       "30                       0.06                      6   \n",
       "28                       0.06                      6   \n",
       "20                       0.05                      7   \n",
       "29                       0.06                      6   \n",
       "5                        0.04                      6   \n",
       "8                        0.04                      7   \n",
       "9                        0.04                      7   \n",
       "7                        0.04                      6   \n",
       "6                        0.04                      6   \n",
       "32                       0.06                      7   \n",
       "21                       0.05                      7   \n",
       "33                       0.06                      7   \n",
       "35                       0.06                      7   \n",
       "10                       0.04                      7   \n",
       "34                       0.06                      7   \n",
       "22                       0.05                      7   \n",
       "23                       0.05                      7   \n",
       "11                       0.04                      7   \n",
       "\n",
       "   param_model__n_estimators  \\\n",
       "3                        250   \n",
       "2                        150   \n",
       "1                        125   \n",
       "16                       100   \n",
       "17                       125   \n",
       "12                       100   \n",
       "13                       125   \n",
       "15                       250   \n",
       "14                       150   \n",
       "18                       150   \n",
       "0                        100   \n",
       "19                       250   \n",
       "27                       250   \n",
       "26                       150   \n",
       "24                       100   \n",
       "25                       125   \n",
       "31                       250   \n",
       "4                        100   \n",
       "30                       150   \n",
       "28                       100   \n",
       "20                       100   \n",
       "29                       125   \n",
       "5                        125   \n",
       "8                        100   \n",
       "9                        125   \n",
       "7                        250   \n",
       "6                        150   \n",
       "32                       100   \n",
       "21                       125   \n",
       "33                       125   \n",
       "35                       250   \n",
       "10                       150   \n",
       "34                       150   \n",
       "22                       150   \n",
       "23                       250   \n",
       "11                       250   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "3   {'model__learning_rate': 0.04, 'model__max_dep...        -287.049677   \n",
       "2   {'model__learning_rate': 0.04, 'model__max_dep...        -282.926755   \n",
       "1   {'model__learning_rate': 0.04, 'model__max_dep...        -276.345727   \n",
       "16  {'model__learning_rate': 0.05, 'model__max_dep...        -272.937854   \n",
       "17  {'model__learning_rate': 0.05, 'model__max_dep...        -282.428511   \n",
       "12  {'model__learning_rate': 0.05, 'model__max_dep...        -275.858107   \n",
       "13  {'model__learning_rate': 0.05, 'model__max_dep...        -282.521621   \n",
       "15  {'model__learning_rate': 0.05, 'model__max_dep...        -287.291263   \n",
       "14  {'model__learning_rate': 0.05, 'model__max_dep...        -285.029646   \n",
       "18  {'model__learning_rate': 0.05, 'model__max_dep...        -285.996297   \n",
       "0   {'model__learning_rate': 0.04, 'model__max_dep...        -264.532393   \n",
       "19  {'model__learning_rate': 0.05, 'model__max_dep...        -283.971854   \n",
       "27  {'model__learning_rate': 0.06, 'model__max_dep...        -296.563841   \n",
       "26  {'model__learning_rate': 0.06, 'model__max_dep...        -297.607990   \n",
       "24  {'model__learning_rate': 0.06, 'model__max_dep...        -293.236318   \n",
       "25  {'model__learning_rate': 0.06, 'model__max_dep...        -297.010415   \n",
       "31  {'model__learning_rate': 0.06, 'model__max_dep...        -294.434505   \n",
       "4   {'model__learning_rate': 0.04, 'model__max_dep...        -280.714424   \n",
       "30  {'model__learning_rate': 0.06, 'model__max_dep...        -294.257375   \n",
       "28  {'model__learning_rate': 0.06, 'model__max_dep...        -295.912367   \n",
       "20  {'model__learning_rate': 0.05, 'model__max_dep...        -297.852583   \n",
       "29  {'model__learning_rate': 0.06, 'model__max_dep...        -297.724725   \n",
       "5   {'model__learning_rate': 0.04, 'model__max_dep...        -293.963489   \n",
       "8   {'model__learning_rate': 0.04, 'model__max_dep...        -280.126562   \n",
       "9   {'model__learning_rate': 0.04, 'model__max_dep...        -294.597083   \n",
       "7   {'model__learning_rate': 0.04, 'model__max_dep...        -302.448286   \n",
       "6   {'model__learning_rate': 0.04, 'model__max_dep...        -303.423981   \n",
       "32  {'model__learning_rate': 0.06, 'model__max_dep...        -305.249162   \n",
       "21  {'model__learning_rate': 0.05, 'model__max_dep...        -309.062400   \n",
       "33  {'model__learning_rate': 0.06, 'model__max_dep...        -310.212176   \n",
       "35  {'model__learning_rate': 0.06, 'model__max_dep...        -310.963212   \n",
       "10  {'model__learning_rate': 0.04, 'model__max_dep...        -308.062230   \n",
       "34  {'model__learning_rate': 0.06, 'model__max_dep...        -311.195130   \n",
       "22  {'model__learning_rate': 0.05, 'model__max_dep...        -314.153933   \n",
       "23  {'model__learning_rate': 0.05, 'model__max_dep...        -316.248212   \n",
       "11  {'model__learning_rate': 0.04, 'model__max_dep...        -313.941381   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "3         -304.859678        -281.951944      -291.287100        9.820315   \n",
       "2         -307.632552        -286.209392      -292.256233       10.954978   \n",
       "1         -315.098382        -286.310447      -292.584852       16.431031   \n",
       "16        -313.292727        -292.181383      -292.803988       16.480689   \n",
       "17        -306.077799        -292.214122      -293.573477        9.702512   \n",
       "12        -314.810933        -290.079069      -293.582703       16.094249   \n",
       "13        -307.551070        -292.463451      -294.178714       10.289960   \n",
       "15        -308.845733        -286.936088      -294.357695       10.245616   \n",
       "14        -306.188680        -292.866001      -294.694776        8.734395   \n",
       "18        -306.326635        -292.301772      -294.874901        8.496918   \n",
       "0         -332.632264        -287.996232      -295.053630       28.245982   \n",
       "19        -310.355237        -291.208055      -295.178382       11.130839   \n",
       "27        -312.438115        -279.410272      -296.137409       13.486931   \n",
       "26        -309.518108        -283.944028      -297.023375       10.448755   \n",
       "24        -310.059178        -288.309360      -297.201619        9.311511   \n",
       "25        -307.787440        -287.876151      -297.558002        8.137966   \n",
       "31        -312.704045        -290.882323      -299.340291        9.560228   \n",
       "4         -324.556671        -293.553279      -299.608125       18.403469   \n",
       "30        -309.842911        -296.898701      -300.332996        6.810434   \n",
       "28        -308.939820        -297.743382      -300.865190        5.758350   \n",
       "20        -311.491624        -293.875557      -301.073255        7.543695   \n",
       "29        -307.732672        -297.782910      -301.080102        4.704137   \n",
       "5         -314.138610        -296.077181      -301.393093        9.053657   \n",
       "8         -321.761573        -302.734257      -301.540797       17.018359   \n",
       "9         -309.089459        -301.903914      -301.863485        5.916557   \n",
       "7         -308.590641        -298.578378      -303.205768        4.122434   \n",
       "6         -309.998636        -299.498653      -304.307090        4.331845   \n",
       "32        -309.230111        -298.977704      -304.485659        4.220203   \n",
       "21        -308.069814        -297.069262      -304.733825        5.434792   \n",
       "33        -307.877582        -298.584563      -305.558107        5.022305   \n",
       "35        -308.082765        -297.795379      -305.613785        5.652129   \n",
       "10        -305.692007        -303.241807      -305.665348        1.968020   \n",
       "34        -308.027986        -298.486542      -305.903220        5.401421   \n",
       "22        -306.810230        -297.358617      -306.107593        6.874636   \n",
       "23        -307.093675        -295.522599      -306.288162        8.480346   \n",
       "11        -303.764192        -301.897934      -306.534502        5.292581   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "3                 1          -70.680155          -70.904577   \n",
       "2                 2         -101.643501          -96.254972   \n",
       "1                 3         -113.759979         -108.629875   \n",
       "16                4          -82.396344          -77.062454   \n",
       "17                5          -65.164959          -63.786570   \n",
       "12                6         -113.830659         -108.315825   \n",
       "13                7          -98.939241          -93.283794   \n",
       "15                8          -57.114979          -61.566700   \n",
       "14                9          -88.729764          -84.572143   \n",
       "18               10          -54.811136          -54.841162   \n",
       "0                11         -138.498035         -130.951017   \n",
       "19               12          -29.705272          -35.252038   \n",
       "27               13          -47.184112          -50.901001   \n",
       "26               14          -77.379594          -74.021296   \n",
       "24               15         -100.891208          -96.024043   \n",
       "25               16          -87.822865          -83.336566   \n",
       "31               17          -20.913635          -27.383334   \n",
       "4                18         -105.379518          -99.208724   \n",
       "30               19          -43.732707          -46.995642   \n",
       "28               20          -67.423226          -66.539156   \n",
       "20               21          -55.927539          -51.825030   \n",
       "29               22          -52.897372          -54.635942   \n",
       "5                23          -80.866506          -76.424033   \n",
       "8                24          -85.445682          -80.329458   \n",
       "9                25          -58.247205          -52.788342   \n",
       "7                26          -39.071327          -41.524715   \n",
       "6                27          -66.588368          -62.922064   \n",
       "32               28          -42.733068          -41.455464   \n",
       "21               29          -41.576985          -37.453748   \n",
       "33               30          -31.191000          -31.541957   \n",
       "35               31          -10.347392          -11.453772   \n",
       "10               32          -44.960723          -40.650301   \n",
       "34               33          -24.341667          -25.343804   \n",
       "22               34          -31.661146          -29.984025   \n",
       "23               35          -15.821322          -15.957919   \n",
       "11               36          -21.328616          -24.237766   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "3           -71.617907        -71.067546         0.399803  \n",
       "2           -98.833348        -98.910607         2.200536  \n",
       "1          -112.815375       -111.735077         2.229316  \n",
       "16          -78.991447        -79.483415         2.205164  \n",
       "17          -61.987985        -63.646505         1.300770  \n",
       "12         -114.410626       -112.185704         2.746641  \n",
       "13          -98.709932        -96.977656         2.613632  \n",
       "15          -62.394590        -60.358757         2.318465  \n",
       "14          -89.119254        -87.473720         2.057878  \n",
       "18          -53.833561        -54.495287         0.468071  \n",
       "0          -136.593107       -135.347386         3.204501  \n",
       "19          -31.984031        -32.313780         2.276431  \n",
       "27          -50.501291        -49.528801         1.665957  \n",
       "26          -77.908193        -76.436361         1.721290  \n",
       "24         -101.474023        -99.463092         2.443387  \n",
       "25          -88.051784        -86.403738         2.170831  \n",
       "31          -24.172491        -24.156487         2.641268  \n",
       "4          -104.627266       -103.071836         2.748842  \n",
       "30          -43.360484        -44.696278         1.632982  \n",
       "28          -62.242800        -65.401727         2.262669  \n",
       "20          -51.876762        -53.209777         1.921864  \n",
       "29          -51.319328        -52.950881         1.354530  \n",
       "5           -79.187063        -78.825868         1.831527  \n",
       "8           -78.689131        -81.488090         2.877449  \n",
       "9           -53.871238        -54.968928         2.359871  \n",
       "7           -39.584095        -40.060046         1.056622  \n",
       "6           -64.532325        -64.680919         1.500446  \n",
       "32          -39.029723        -41.072752         1.535913  \n",
       "21          -35.943076        -38.324603         2.381039  \n",
       "33          -28.080447        -30.271135         1.555662  \n",
       "35          -10.695445        -10.832203         0.461913  \n",
       "10          -40.857984        -42.156336         1.984813  \n",
       "34          -22.033438        -23.906303         1.386070  \n",
       "22          -28.564055        -30.069742         1.265834  \n",
       "23          -11.859692        -14.546311         1.900544  \n",
       "11          -21.665805        -22.410729         1.299223  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error, with final model, on the hold-out test set  243.40218139648437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "final = search.best_estimator_\n",
    "y_pred = final.predict(X_test)\n",
    "\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "print('Mean Absolute Error, with final model, on the hold-out test set ', test_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
