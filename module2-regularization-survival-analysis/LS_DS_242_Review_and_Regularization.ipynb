{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_242_Review_and_Regularization.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5zk1n36HAJs",
        "colab_type": "text"
      },
      "source": [
        "_Lambda School Data Science — Practicing & Understanding Predictive Modeling_\n",
        "\n",
        "# Review & Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1wd1wTCHAJ1",
        "colab_type": "text"
      },
      "source": [
        "## Start with example solution for yesterday's assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL_wjNEGHAJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8GPyrF_HAKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll modify a project from Python Data Science Handbook by Jake VanderPlas\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "    \n",
        "# Predicting Bicycle Traffic\n",
        "\n",
        "# As an example, let's take a look at whether we can predict the number of \n",
        "# bicycle trips across Seattle's Fremont Bridge based on weather, season, \n",
        "# and other factors.\n",
        "\n",
        "# We will join the bike data with another dataset, and try to determine the \n",
        "# extent to which weather and seasonal factors—temperature, precipitation, \n",
        "# and daylight hours—affect the volume of bicycle traffic through this corridor. \n",
        "# Fortunately, the NOAA makes available their daily weather station data \n",
        "# (I used station ID USW00024233) and we can easily use Pandas to join \n",
        "# the two data sources.\n",
        "\n",
        "def load(): \n",
        "    fremont_bridge = 'https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD'\n",
        "    \n",
        "    bicycle_weather = 'https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv'\n",
        "\n",
        "    counts = pd.read_csv(fremont_bridge, index_col='Date', parse_dates=True, \n",
        "                         infer_datetime_format=True)\n",
        "\n",
        "    weather = pd.read_csv(bicycle_weather, index_col='DATE', parse_dates=True, \n",
        "                          infer_datetime_format=True)\n",
        "\n",
        "    daily = counts.resample('d').sum()\n",
        "    daily['Total'] = daily.sum(axis=1)\n",
        "    daily = daily[['Total']] # remove other columns\n",
        "\n",
        "    weather_columns = ['PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND']\n",
        "    daily = daily.join(weather[weather_columns], how='inner')\n",
        "    \n",
        "    # Make a feature for yesterday's total\n",
        "    daily['Total_yesterday'] = daily.Total.shift(1)\n",
        "    daily = daily.drop(index=daily.index[0])\n",
        "    \n",
        "    return daily"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-L_zApoHAKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split(daily):\n",
        "    # Hold out an \"out-of-time\" test set, from the last 100 days of data\n",
        "    \n",
        "    train = daily[:-100]\n",
        "    test = daily[-100:]\n",
        "    \n",
        "    X_train = train.drop(columns='Total')\n",
        "    y_train = train.Total\n",
        "\n",
        "    X_test  = test.drop(columns='Total')\n",
        "    y_test  = test.Total\n",
        "    \"\"\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1yTEg3IHAKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def jake_wrangle(X):  \n",
        "    X = X.copy()\n",
        "\n",
        "    # patterns of use generally vary from day to day; \n",
        "    # let's add binary columns that indicate the day of the week:\n",
        "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "    for i, day in enumerate(days):\n",
        "        X[day] = (X.index.dayofweek == i).astype(float)\n",
        "\n",
        "\n",
        "    # we might expect riders to behave differently on holidays; \n",
        "    # let's add an indicator of this as well:\n",
        "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "    cal = USFederalHolidayCalendar()\n",
        "    holidays = cal.holidays('2012', '2016')\n",
        "    X = X.join(pd.Series(1, index=holidays, name='holiday'))\n",
        "    X['holiday'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "    # We also might suspect that the hours of daylight would affect \n",
        "    # how many people ride; let's use the standard astronomical calculation \n",
        "    # to add this information:\n",
        "    def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
        "        \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
        "        days = (date - pd.datetime(2000, 12, 21)).days\n",
        "        m = (1. - np.tan(np.radians(latitude))\n",
        "             * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
        "        return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
        "\n",
        "    X['daylight_hrs'] = list(map(hours_of_daylight, X.index))\n",
        "\n",
        "\n",
        "    # temperatures are in 1/10 deg C; convert to C\n",
        "    X['TMIN'] /= 10\n",
        "    X['TMAX'] /= 10\n",
        "\n",
        "    # We can also calcuate the average temperature.\n",
        "    X['Temp (C)'] = 0.5 * (X['TMIN'] + X['TMAX'])\n",
        "\n",
        "\n",
        "    # precip is in 1/10 mm; convert to inches\n",
        "    X['PRCP'] /= 254\n",
        "\n",
        "    # In addition to the inches of precipitation, let's add a flag that \n",
        "    # indicates whether a day is dry (has zero precipitation):\n",
        "    X['dry day'] = (X['PRCP'] == 0).astype(int)\n",
        "\n",
        "\n",
        "    # Let's add a counter that increases from day 1, and measures how many \n",
        "    # years have passed. This will let us measure any observed annual increase \n",
        "    # or decrease in daily crossings:\n",
        "    X['annual'] = (X.index - X.index[0]).days / 365.\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZwSrc1gHAK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and join data into a dataframe\n",
        "data = load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV66y9xoHAK6",
        "colab_type": "text"
      },
      "source": [
        "#### `SNOW` and `AWND` have minimums of `-9999` ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osOoLPVgHAK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "5b637b1a-150c-4c7f-dde1-536429f84759"
      },
      "source": [
        "data.describe(include='number')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1063.000000</td>\n",
              "      <td>1063.000000</td>\n",
              "      <td>1063.000000</td>\n",
              "      <td>1063.000000</td>\n",
              "      <td>1063.000000</td>\n",
              "      <td>1063.000000</td>\n",
              "      <td>1063.000000</td>\n",
              "      <td>1063.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2632.449671</td>\n",
              "      <td>29.350894</td>\n",
              "      <td>-37.496707</td>\n",
              "      <td>0.098777</td>\n",
              "      <td>166.863594</td>\n",
              "      <td>84.472248</td>\n",
              "      <td>22.338664</td>\n",
              "      <td>2633.056444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1252.864020</td>\n",
              "      <td>65.813053</td>\n",
              "      <td>612.512583</td>\n",
              "      <td>2.570041</td>\n",
              "      <td>74.779734</td>\n",
              "      <td>50.916006</td>\n",
              "      <td>307.984292</td>\n",
              "      <td>1253.138245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-9999.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-16.000000</td>\n",
              "      <td>-71.000000</td>\n",
              "      <td>-9999.000000</td>\n",
              "      <td>98.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1806.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1806.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2435.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2435.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3574.500000</td>\n",
              "      <td>26.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>222.000000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>3574.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6088.000000</td>\n",
              "      <td>559.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>356.000000</td>\n",
              "      <td>183.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>6088.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total         PRCP         SNOW         SNWD         TMAX  \\\n",
              "count  1063.000000  1063.000000  1063.000000  1063.000000  1063.000000   \n",
              "mean   2632.449671    29.350894   -37.496707     0.098777   166.863594   \n",
              "std    1252.864020    65.813053   612.512583     2.570041    74.779734   \n",
              "min      98.000000     0.000000 -9999.000000     0.000000   -16.000000   \n",
              "25%    1806.000000     0.000000     0.000000     0.000000   111.000000   \n",
              "50%    2435.000000     0.000000     0.000000     0.000000   150.000000   \n",
              "75%    3574.500000    26.500000     0.000000     0.000000   222.000000   \n",
              "max    6088.000000   559.000000    74.000000    80.000000   356.000000   \n",
              "\n",
              "              TMIN         AWND  Total_yesterday  \n",
              "count  1063.000000  1063.000000      1063.000000  \n",
              "mean     84.472248    22.338664      2633.056444  \n",
              "std      50.916006   307.984292      1253.138245  \n",
              "min     -71.000000 -9999.000000        98.000000  \n",
              "25%      44.000000    22.000000      1806.000000  \n",
              "50%      83.000000    29.000000      2435.000000  \n",
              "75%     128.000000    40.000000      3574.500000  \n",
              "max     183.000000    95.000000      6088.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT4JD3-JHALA",
        "colab_type": "text"
      },
      "source": [
        "### Clean data and engineer features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e6MYWTBHALC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrangle(X):\n",
        "    X = X.copy()\n",
        "    X = X.replace(-9999, 0)\n",
        "    X = jake_wrangle(X)\n",
        "    \n",
        "    # DS1 DH\n",
        "    X['PRCP_yesterday'] = X.PRCP.shift(1).fillna(X.PRCP.mean())\n",
        "    X['Windchill'] = (((X['Temp (C)'] * (9/5) + 32) * .6215) + 34.74) - (35.75 * (X['AWND']** .16)) + (.4275 * (X['Temp (C)'])) * (X['AWND'] ** .16)\n",
        "    X['Rl_Cold'] = (((X['Temp (C)'] * (9/5) + 32) - X['Windchill']) -32) * (5/9)\n",
        "    X['TMIN_squared'] = X['TMIN'] **2\n",
        "    \n",
        "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "    for i, month in enumerate(months):\n",
        "        X[month] = (X.index.month == i+1).astype(float)\n",
        "    \n",
        "    # DS3 JD\n",
        "    X['light_rain'] = (X['PRCP'] > 0) & (X['PRCP'] < 0.10)\n",
        "    X['moderate_rain'] = (X['PRCP'] >= 0.1) & (X['PRCP'] < 0.30)\n",
        "    X['heavy_rain'] = (X['PRCP'] >= 0.30)\n",
        "    X['weekend_day'] = (X['Sat'] == 1) | (X['Sun'] == 1)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjQUyCcCHALJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data into train and test\n",
        "X_train, X_test, y_train, y_test = split(data)\n",
        "\n",
        "# Do the same wrangling to X_train and X_test\n",
        "X_train = wrangle(X_train)\n",
        "X_test  = wrangle(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyCwmFjhHALN",
        "colab_type": "text"
      },
      "source": [
        "### RandomizedSearchCV review / SPRINT CHALLENGE PRACTICE\n",
        "- https://twitter.com/jakevdp/status/648593367786323968\n",
        "- https://www.google.com/search?q=site%3Ascikit-learn.org+RandomizedSearchCV\n",
        "  - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
        "  - https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html\n",
        "- https://www.google.com/search?q=XGBRegressor\n",
        "  - https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor\n",
        "- https://www.google.com/search?q=xgboost+parameter+tuning\n",
        "  - https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html\n",
        "- https://nbviewer.jupyter.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/svm_iris_pipeline_and_gridsearch.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYfv2l2RHALO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "b686df28-7058-4cbd-c2bc-6ca0a717fb2d"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_distributions = {\n",
        "    'n_estimators': randint(50, 500),\n",
        "    'max_depth' : randint(1,5),\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=XGBRegressor(n_jobs=-1, random_state=42),\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=50,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    n_jobs=-1,\n",
        "    cv=3,\n",
        "    verbose=10,\n",
        "    return_train_score=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "search.fit(X_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.9s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   12.7s\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   15.4s\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:   18.5s\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   22.5s\n",
            "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:   24.6s\n",
            "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:   27.8s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:   31.2s\n",
            "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:   35.6s\n",
            "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   37.9s finished\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  data.base is not None and isinstance(data, np.ndarray) \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
              "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
              "       nthread=None, objective='reg:linear', random_state=42, reg_alpha=0,\n",
              "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
              "       subsample=1),\n",
              "          fit_params=None, iid='warn', n_iter=50, n_jobs=-1,\n",
              "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f94e8203908>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f94e594e6d8>},\n",
              "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOD_rzuJMMpa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec4a91f5-4048-40b6-e6c9-ddde458404ba"
      },
      "source": [
        "print('Mean Absolute Error with cross-validation: ',-search.best_score_)\n",
        "print(f'Predictions off by {int(-search.best_score_)} biciclysts per day, on average')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error with cross-validation:  265.83134640290604\n",
            "Predictions off by 265 biciclysts per day, on average\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9zkDQAXN0GS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4169
        },
        "outputId": "e6d06ab8-0b0f-4b0a-a181-77ce1342f45d"
      },
      "source": [
        "pd.DataFrame(search.cv_results_).sort_values(by='rank_test_score')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.226267</td>\n",
              "      <td>0.009088</td>\n",
              "      <td>0.008890</td>\n",
              "      <td>0.002680</td>\n",
              "      <td>4</td>\n",
              "      <td>99</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 99}</td>\n",
              "      <td>-239.140201</td>\n",
              "      <td>-299.719542</td>\n",
              "      <td>-258.634296</td>\n",
              "      <td>-265.831346</td>\n",
              "      <td>25.249584</td>\n",
              "      <td>1</td>\n",
              "      <td>-118.287817</td>\n",
              "      <td>-111.714466</td>\n",
              "      <td>-115.705761</td>\n",
              "      <td>-115.236015</td>\n",
              "      <td>2.704038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.250023</td>\n",
              "      <td>0.003333</td>\n",
              "      <td>0.006264</td>\n",
              "      <td>0.000319</td>\n",
              "      <td>3</td>\n",
              "      <td>137</td>\n",
              "      <td>{'max_depth': 3, 'n_estimators': 137}</td>\n",
              "      <td>-244.438229</td>\n",
              "      <td>-304.533409</td>\n",
              "      <td>-251.465551</td>\n",
              "      <td>-266.812396</td>\n",
              "      <td>26.826627</td>\n",
              "      <td>2</td>\n",
              "      <td>-147.865735</td>\n",
              "      <td>-142.781576</td>\n",
              "      <td>-148.144886</td>\n",
              "      <td>-146.264066</td>\n",
              "      <td>2.465127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.213073</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.005468</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>3</td>\n",
              "      <td>121</td>\n",
              "      <td>{'max_depth': 3, 'n_estimators': 121}</td>\n",
              "      <td>-243.344933</td>\n",
              "      <td>-304.401840</td>\n",
              "      <td>-254.079236</td>\n",
              "      <td>-267.275336</td>\n",
              "      <td>26.615651</td>\n",
              "      <td>3</td>\n",
              "      <td>-155.450152</td>\n",
              "      <td>-149.231834</td>\n",
              "      <td>-154.527866</td>\n",
              "      <td>-153.069951</td>\n",
              "      <td>2.739952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.332540</td>\n",
              "      <td>0.008256</td>\n",
              "      <td>0.006929</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>2</td>\n",
              "      <td>267</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 267}</td>\n",
              "      <td>-240.444091</td>\n",
              "      <td>-302.803964</td>\n",
              "      <td>-259.613981</td>\n",
              "      <td>-267.620679</td>\n",
              "      <td>26.080246</td>\n",
              "      <td>4</td>\n",
              "      <td>-169.646317</td>\n",
              "      <td>-160.380511</td>\n",
              "      <td>-166.519723</td>\n",
              "      <td>-165.515517</td>\n",
              "      <td>3.848819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.354847</td>\n",
              "      <td>0.004640</td>\n",
              "      <td>0.006881</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>2</td>\n",
              "      <td>291</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 291}</td>\n",
              "      <td>-241.840456</td>\n",
              "      <td>-303.311846</td>\n",
              "      <td>-259.036209</td>\n",
              "      <td>-268.062837</td>\n",
              "      <td>25.894567</td>\n",
              "      <td>5</td>\n",
              "      <td>-165.989825</td>\n",
              "      <td>-155.599304</td>\n",
              "      <td>-161.756025</td>\n",
              "      <td>-161.115051</td>\n",
              "      <td>4.266057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.388570</td>\n",
              "      <td>0.009093</td>\n",
              "      <td>0.006885</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>4</td>\n",
              "      <td>180</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 180}</td>\n",
              "      <td>-251.023010</td>\n",
              "      <td>-301.820389</td>\n",
              "      <td>-251.491774</td>\n",
              "      <td>-268.111724</td>\n",
              "      <td>23.836393</td>\n",
              "      <td>6</td>\n",
              "      <td>-78.801195</td>\n",
              "      <td>-78.138161</td>\n",
              "      <td>-80.406992</td>\n",
              "      <td>-79.115449</td>\n",
              "      <td>0.952528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.378072</td>\n",
              "      <td>0.015528</td>\n",
              "      <td>0.007085</td>\n",
              "      <td>0.000543</td>\n",
              "      <td>2</td>\n",
              "      <td>302</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 302}</td>\n",
              "      <td>-241.948864</td>\n",
              "      <td>-305.349984</td>\n",
              "      <td>-258.406315</td>\n",
              "      <td>-268.568388</td>\n",
              "      <td>26.862319</td>\n",
              "      <td>7</td>\n",
              "      <td>-164.606615</td>\n",
              "      <td>-153.527684</td>\n",
              "      <td>-159.558914</td>\n",
              "      <td>-159.231071</td>\n",
              "      <td>4.528892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.531969</td>\n",
              "      <td>0.014347</td>\n",
              "      <td>0.008498</td>\n",
              "      <td>0.000840</td>\n",
              "      <td>2</td>\n",
              "      <td>437</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 437}</td>\n",
              "      <td>-238.999624</td>\n",
              "      <td>-306.706189</td>\n",
              "      <td>-261.231241</td>\n",
              "      <td>-268.979018</td>\n",
              "      <td>28.178784</td>\n",
              "      <td>8</td>\n",
              "      <td>-145.489765</td>\n",
              "      <td>-131.843921</td>\n",
              "      <td>-138.524280</td>\n",
              "      <td>-138.619322</td>\n",
              "      <td>5.571298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.541610</td>\n",
              "      <td>0.007272</td>\n",
              "      <td>0.008477</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>2</td>\n",
              "      <td>435</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 435}</td>\n",
              "      <td>-239.046106</td>\n",
              "      <td>-306.846962</td>\n",
              "      <td>-261.190062</td>\n",
              "      <td>-269.027710</td>\n",
              "      <td>28.228951</td>\n",
              "      <td>9</td>\n",
              "      <td>-145.685230</td>\n",
              "      <td>-132.158503</td>\n",
              "      <td>-138.631844</td>\n",
              "      <td>-138.825192</td>\n",
              "      <td>5.523955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.325554</td>\n",
              "      <td>0.024534</td>\n",
              "      <td>0.006541</td>\n",
              "      <td>0.000340</td>\n",
              "      <td>3</td>\n",
              "      <td>171</td>\n",
              "      <td>{'max_depth': 3, 'n_estimators': 171}</td>\n",
              "      <td>-245.110404</td>\n",
              "      <td>-307.535504</td>\n",
              "      <td>-254.496243</td>\n",
              "      <td>-269.047384</td>\n",
              "      <td>27.483632</td>\n",
              "      <td>10</td>\n",
              "      <td>-132.673931</td>\n",
              "      <td>-130.636762</td>\n",
              "      <td>-134.051616</td>\n",
              "      <td>-132.454103</td>\n",
              "      <td>1.402747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.465744</td>\n",
              "      <td>0.007431</td>\n",
              "      <td>0.007553</td>\n",
              "      <td>0.000226</td>\n",
              "      <td>2</td>\n",
              "      <td>389</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 389}</td>\n",
              "      <td>-242.164459</td>\n",
              "      <td>-305.779086</td>\n",
              "      <td>-259.707190</td>\n",
              "      <td>-269.216912</td>\n",
              "      <td>26.826993</td>\n",
              "      <td>11</td>\n",
              "      <td>-152.029338</td>\n",
              "      <td>-138.251466</td>\n",
              "      <td>-144.693506</td>\n",
              "      <td>-144.991437</td>\n",
              "      <td>5.628736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.530451</td>\n",
              "      <td>0.014487</td>\n",
              "      <td>0.008445</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>2</td>\n",
              "      <td>439</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 439}</td>\n",
              "      <td>-239.061357</td>\n",
              "      <td>-306.591580</td>\n",
              "      <td>-262.900956</td>\n",
              "      <td>-269.517964</td>\n",
              "      <td>27.963325</td>\n",
              "      <td>12</td>\n",
              "      <td>-145.076551</td>\n",
              "      <td>-131.568911</td>\n",
              "      <td>-138.274815</td>\n",
              "      <td>-138.306759</td>\n",
              "      <td>5.514517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.394981</td>\n",
              "      <td>0.015075</td>\n",
              "      <td>0.007139</td>\n",
              "      <td>0.000474</td>\n",
              "      <td>2</td>\n",
              "      <td>314</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 314}</td>\n",
              "      <td>-241.969526</td>\n",
              "      <td>-304.692513</td>\n",
              "      <td>-262.057680</td>\n",
              "      <td>-269.573239</td>\n",
              "      <td>26.152196</td>\n",
              "      <td>13</td>\n",
              "      <td>-162.752955</td>\n",
              "      <td>-151.087178</td>\n",
              "      <td>-156.990622</td>\n",
              "      <td>-156.943585</td>\n",
              "      <td>4.762650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.447183</td>\n",
              "      <td>0.009820</td>\n",
              "      <td>0.007534</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>4</td>\n",
              "      <td>201</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 201}</td>\n",
              "      <td>-256.125398</td>\n",
              "      <td>-301.948695</td>\n",
              "      <td>-251.769023</td>\n",
              "      <td>-269.947706</td>\n",
              "      <td>22.697900</td>\n",
              "      <td>14</td>\n",
              "      <td>-71.468125</td>\n",
              "      <td>-71.544820</td>\n",
              "      <td>-74.977502</td>\n",
              "      <td>-72.663482</td>\n",
              "      <td>1.636558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.454541</td>\n",
              "      <td>0.013711</td>\n",
              "      <td>0.007673</td>\n",
              "      <td>0.000211</td>\n",
              "      <td>4</td>\n",
              "      <td>211</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 211}</td>\n",
              "      <td>-258.026175</td>\n",
              "      <td>-301.897845</td>\n",
              "      <td>-252.481026</td>\n",
              "      <td>-270.801682</td>\n",
              "      <td>22.104535</td>\n",
              "      <td>15</td>\n",
              "      <td>-68.028119</td>\n",
              "      <td>-68.300412</td>\n",
              "      <td>-72.253605</td>\n",
              "      <td>-69.527378</td>\n",
              "      <td>1.930936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.544323</td>\n",
              "      <td>0.066345</td>\n",
              "      <td>0.007920</td>\n",
              "      <td>0.000804</td>\n",
              "      <td>2</td>\n",
              "      <td>495</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 495}</td>\n",
              "      <td>-238.785233</td>\n",
              "      <td>-308.326131</td>\n",
              "      <td>-266.339100</td>\n",
              "      <td>-271.150155</td>\n",
              "      <td>28.593050</td>\n",
              "      <td>16</td>\n",
              "      <td>-136.949726</td>\n",
              "      <td>-124.490166</td>\n",
              "      <td>-130.758340</td>\n",
              "      <td>-130.732744</td>\n",
              "      <td>5.086626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.594561</td>\n",
              "      <td>0.006769</td>\n",
              "      <td>0.008618</td>\n",
              "      <td>0.000232</td>\n",
              "      <td>2</td>\n",
              "      <td>495</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 495}</td>\n",
              "      <td>-238.785233</td>\n",
              "      <td>-308.326131</td>\n",
              "      <td>-266.339100</td>\n",
              "      <td>-271.150155</td>\n",
              "      <td>28.593050</td>\n",
              "      <td>16</td>\n",
              "      <td>-136.949726</td>\n",
              "      <td>-124.490166</td>\n",
              "      <td>-130.758340</td>\n",
              "      <td>-130.732744</td>\n",
              "      <td>5.086626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.006095</td>\n",
              "      <td>0.009274</td>\n",
              "      <td>0.012644</td>\n",
              "      <td>0.000821</td>\n",
              "      <td>4</td>\n",
              "      <td>463</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 463}</td>\n",
              "      <td>-264.083292</td>\n",
              "      <td>-298.266089</td>\n",
              "      <td>-252.673771</td>\n",
              "      <td>-271.674384</td>\n",
              "      <td>19.371515</td>\n",
              "      <td>18</td>\n",
              "      <td>-25.082481</td>\n",
              "      <td>-23.281627</td>\n",
              "      <td>-26.815669</td>\n",
              "      <td>-25.059925</td>\n",
              "      <td>1.442855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.922960</td>\n",
              "      <td>0.005390</td>\n",
              "      <td>0.011644</td>\n",
              "      <td>0.000714</td>\n",
              "      <td>4</td>\n",
              "      <td>437</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 437}</td>\n",
              "      <td>-264.086397</td>\n",
              "      <td>-298.606780</td>\n",
              "      <td>-253.128459</td>\n",
              "      <td>-271.940546</td>\n",
              "      <td>19.379287</td>\n",
              "      <td>19</td>\n",
              "      <td>-27.123176</td>\n",
              "      <td>-26.078462</td>\n",
              "      <td>-29.001141</td>\n",
              "      <td>-27.400926</td>\n",
              "      <td>1.209234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.340573</td>\n",
              "      <td>0.000867</td>\n",
              "      <td>0.006582</td>\n",
              "      <td>0.000201</td>\n",
              "      <td>3</td>\n",
              "      <td>199</td>\n",
              "      <td>{'max_depth': 3, 'n_estimators': 199}</td>\n",
              "      <td>-247.334461</td>\n",
              "      <td>-308.127996</td>\n",
              "      <td>-260.933199</td>\n",
              "      <td>-272.131886</td>\n",
              "      <td>26.051505</td>\n",
              "      <td>20</td>\n",
              "      <td>-122.077881</td>\n",
              "      <td>-122.158787</td>\n",
              "      <td>-123.796066</td>\n",
              "      <td>-122.677578</td>\n",
              "      <td>0.791580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1.022487</td>\n",
              "      <td>0.010047</td>\n",
              "      <td>0.012447</td>\n",
              "      <td>0.000651</td>\n",
              "      <td>4</td>\n",
              "      <td>477</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 477}</td>\n",
              "      <td>-265.596068</td>\n",
              "      <td>-298.392426</td>\n",
              "      <td>-252.846965</td>\n",
              "      <td>-272.278486</td>\n",
              "      <td>19.184860</td>\n",
              "      <td>21</td>\n",
              "      <td>-24.277007</td>\n",
              "      <td>-22.002629</td>\n",
              "      <td>-25.608257</td>\n",
              "      <td>-23.962631</td>\n",
              "      <td>1.488682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.913996</td>\n",
              "      <td>0.021477</td>\n",
              "      <td>0.011666</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>4</td>\n",
              "      <td>416</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 416}</td>\n",
              "      <td>-264.997488</td>\n",
              "      <td>-298.646608</td>\n",
              "      <td>-253.220600</td>\n",
              "      <td>-272.288232</td>\n",
              "      <td>19.248320</td>\n",
              "      <td>22</td>\n",
              "      <td>-29.675427</td>\n",
              "      <td>-28.599269</td>\n",
              "      <td>-31.184823</td>\n",
              "      <td>-29.819840</td>\n",
              "      <td>1.060476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.770710</td>\n",
              "      <td>0.019622</td>\n",
              "      <td>0.010166</td>\n",
              "      <td>0.000371</td>\n",
              "      <td>4</td>\n",
              "      <td>359</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 359}</td>\n",
              "      <td>-264.636681</td>\n",
              "      <td>-299.172041</td>\n",
              "      <td>-253.512777</td>\n",
              "      <td>-272.440499</td>\n",
              "      <td>19.439938</td>\n",
              "      <td>23</td>\n",
              "      <td>-36.763864</td>\n",
              "      <td>-36.641410</td>\n",
              "      <td>-38.569223</td>\n",
              "      <td>-37.324832</td>\n",
              "      <td>0.881336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.511904</td>\n",
              "      <td>0.012985</td>\n",
              "      <td>0.008200</td>\n",
              "      <td>0.000413</td>\n",
              "      <td>4</td>\n",
              "      <td>237</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 237}</td>\n",
              "      <td>-262.158470</td>\n",
              "      <td>-301.813298</td>\n",
              "      <td>-253.594659</td>\n",
              "      <td>-272.522142</td>\n",
              "      <td>21.004977</td>\n",
              "      <td>24</td>\n",
              "      <td>-59.937224</td>\n",
              "      <td>-60.968301</td>\n",
              "      <td>-64.587592</td>\n",
              "      <td>-61.831039</td>\n",
              "      <td>1.994111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.056752</td>\n",
              "      <td>0.006448</td>\n",
              "      <td>0.012604</td>\n",
              "      <td>0.000316</td>\n",
              "      <td>4</td>\n",
              "      <td>493</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 493}</td>\n",
              "      <td>-266.598200</td>\n",
              "      <td>-298.249717</td>\n",
              "      <td>-252.742118</td>\n",
              "      <td>-272.530012</td>\n",
              "      <td>19.046000</td>\n",
              "      <td>25</td>\n",
              "      <td>-22.994918</td>\n",
              "      <td>-20.913465</td>\n",
              "      <td>-24.079672</td>\n",
              "      <td>-22.662685</td>\n",
              "      <td>1.313773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.851621</td>\n",
              "      <td>0.013388</td>\n",
              "      <td>0.010959</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>4</td>\n",
              "      <td>394</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 394}</td>\n",
              "      <td>-266.377387</td>\n",
              "      <td>-298.724254</td>\n",
              "      <td>-253.645220</td>\n",
              "      <td>-272.915620</td>\n",
              "      <td>18.975268</td>\n",
              "      <td>26</td>\n",
              "      <td>-31.973895</td>\n",
              "      <td>-31.272266</td>\n",
              "      <td>-34.033673</td>\n",
              "      <td>-32.426611</td>\n",
              "      <td>1.171909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.770056</td>\n",
              "      <td>0.013096</td>\n",
              "      <td>0.013886</td>\n",
              "      <td>0.004086</td>\n",
              "      <td>4</td>\n",
              "      <td>363</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 363}</td>\n",
              "      <td>-266.038459</td>\n",
              "      <td>-299.156047</td>\n",
              "      <td>-253.573957</td>\n",
              "      <td>-272.922821</td>\n",
              "      <td>19.234995</td>\n",
              "      <td>27</td>\n",
              "      <td>-36.072727</td>\n",
              "      <td>-35.970523</td>\n",
              "      <td>-38.155618</td>\n",
              "      <td>-36.732956</td>\n",
              "      <td>1.006839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.685228</td>\n",
              "      <td>0.009594</td>\n",
              "      <td>0.009408</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>4</td>\n",
              "      <td>320</td>\n",
              "      <td>{'max_depth': 4, 'n_estimators': 320}</td>\n",
              "      <td>-266.134098</td>\n",
              "      <td>-299.086622</td>\n",
              "      <td>-253.658849</td>\n",
              "      <td>-272.959856</td>\n",
              "      <td>19.163574</td>\n",
              "      <td>28</td>\n",
              "      <td>-43.934972</td>\n",
              "      <td>-43.313801</td>\n",
              "      <td>-45.671065</td>\n",
              "      <td>-44.306613</td>\n",
              "      <td>0.997584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.380342</td>\n",
              "      <td>0.005497</td>\n",
              "      <td>0.006673</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>3</td>\n",
              "      <td>219</td>\n",
              "      <td>{'max_depth': 3, 'n_estimators': 219}</td>\n",
              "      <td>-247.862685</td>\n",
              "      <td>-310.550499</td>\n",
              "      <td>-263.300370</td>\n",
              "      <td>-273.904518</td>\n",
              "      <td>26.668039</td>\n",
              "      <td>29</td>\n",
              "      <td>-115.672294</td>\n",
              "      <td>-115.942186</td>\n",
              "      <td>-116.619518</td>\n",
              "      <td>-116.077999</td>\n",
              "      <td>0.398449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.196078</td>\n",
              "      <td>0.004872</td>\n",
              "      <td>0.005241</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>2</td>\n",
              "      <td>155</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 155}</td>\n",
              "      <td>-238.252844</td>\n",
              "      <td>-311.108326</td>\n",
              "      <td>-273.019792</td>\n",
              "      <td>-274.126987</td>\n",
              "      <td>29.753428</td>\n",
              "      <td>30</td>\n",
              "      <td>-194.669503</td>\n",
              "      <td>-188.679666</td>\n",
              "      <td>-192.159128</td>\n",
              "      <td>-191.836099</td>\n",
              "      <td>2.455986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.457591</td>\n",
              "      <td>0.010399</td>\n",
              "      <td>0.008049</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>3</td>\n",
              "      <td>264</td>\n",
              "      <td>{'max_depth': 3, 'n_estimators': 264}</td>\n",
              "      <td>-249.421200</td>\n",
              "      <td>-312.822772</td>\n",
              "      <td>-266.479466</td>\n",
              "      <td>-276.241146</td>\n",
              "      <td>26.788152</td>\n",
              "      <td>31</td>\n",
              "      <td>-103.228856</td>\n",
              "      <td>-103.592948</td>\n",
              "      <td>-103.877132</td>\n",
              "      <td>-103.566312</td>\n",
              "      <td>0.265327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.170084</td>\n",
              "      <td>0.004881</td>\n",
              "      <td>0.005042</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 130}</td>\n",
              "      <td>-236.372528</td>\n",
              "      <td>-313.331043</td>\n",
              "      <td>-280.319201</td>\n",
              "      <td>-276.674257</td>\n",
              "      <td>31.523721</td>\n",
              "      <td>32</td>\n",
              "      <td>-202.931792</td>\n",
              "      <td>-197.253261</td>\n",
              "      <td>-199.610645</td>\n",
              "      <td>-199.931899</td>\n",
              "      <td>2.329353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.487405</td>\n",
              "      <td>0.003926</td>\n",
              "      <td>0.007965</td>\n",
              "      <td>0.000667</td>\n",
              "      <td>3</td>\n",
              "      <td>293</td>\n",
              "      <td>{'max_depth': 3, 'n_estimators': 293}</td>\n",
              "      <td>-250.997272</td>\n",
              "      <td>-314.770765</td>\n",
              "      <td>-266.634172</td>\n",
              "      <td>-277.467403</td>\n",
              "      <td>27.138948</td>\n",
              "      <td>33</td>\n",
              "      <td>-95.530594</td>\n",
              "      <td>-96.287317</td>\n",
              "      <td>-96.706497</td>\n",
              "      <td>-96.174803</td>\n",
              "      <td>0.486609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.672554</td>\n",
              "      <td>0.004546</td>\n",
              "      <td>0.009329</td>\n",
              "      <td>0.000298</td>\n",
              "      <td>3</td>\n",
              "      <td>413</td>\n",
              "      <td>{'max_depth': 3, 'n_estimators': 413}</td>\n",
              "      <td>-251.588342</td>\n",
              "      <td>-316.670789</td>\n",
              "      <td>-272.852182</td>\n",
              "      <td>-280.370438</td>\n",
              "      <td>27.096424</td>\n",
              "      <td>34</td>\n",
              "      <td>-70.739271</td>\n",
              "      <td>-72.653390</td>\n",
              "      <td>-74.261201</td>\n",
              "      <td>-72.551287</td>\n",
              "      <td>1.439633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.152673</td>\n",
              "      <td>0.005537</td>\n",
              "      <td>0.005195</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>3</td>\n",
              "      <td>84</td>\n",
              "      <td>{'max_depth': 3, 'n_estimators': 84}</td>\n",
              "      <td>-246.760039</td>\n",
              "      <td>-307.640594</td>\n",
              "      <td>-293.612071</td>\n",
              "      <td>-282.670901</td>\n",
              "      <td>26.030654</td>\n",
              "      <td>35</td>\n",
              "      <td>-175.151825</td>\n",
              "      <td>-166.785080</td>\n",
              "      <td>-173.989616</td>\n",
              "      <td>-171.975507</td>\n",
              "      <td>3.700728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.801045</td>\n",
              "      <td>0.037310</td>\n",
              "      <td>0.011322</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>3</td>\n",
              "      <td>485</td>\n",
              "      <td>{'max_depth': 3, 'n_estimators': 485}</td>\n",
              "      <td>-253.761815</td>\n",
              "      <td>-317.554585</td>\n",
              "      <td>-278.972618</td>\n",
              "      <td>-283.429672</td>\n",
              "      <td>26.233292</td>\n",
              "      <td>36</td>\n",
              "      <td>-59.667545</td>\n",
              "      <td>-63.338495</td>\n",
              "      <td>-64.197799</td>\n",
              "      <td>-62.401280</td>\n",
              "      <td>1.964617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.808028</td>\n",
              "      <td>0.010017</td>\n",
              "      <td>0.010468</td>\n",
              "      <td>0.000426</td>\n",
              "      <td>3</td>\n",
              "      <td>495</td>\n",
              "      <td>{'max_depth': 3, 'n_estimators': 495}</td>\n",
              "      <td>-253.965659</td>\n",
              "      <td>-317.523775</td>\n",
              "      <td>-278.875016</td>\n",
              "      <td>-283.454817</td>\n",
              "      <td>26.148798</td>\n",
              "      <td>37</td>\n",
              "      <td>-58.393495</td>\n",
              "      <td>-61.964452</td>\n",
              "      <td>-62.691977</td>\n",
              "      <td>-61.016641</td>\n",
              "      <td>1.878474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.136235</td>\n",
              "      <td>0.007332</td>\n",
              "      <td>0.004808</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>2</td>\n",
              "      <td>102</td>\n",
              "      <td>{'max_depth': 2, 'n_estimators': 102}</td>\n",
              "      <td>-238.914425</td>\n",
              "      <td>-320.973910</td>\n",
              "      <td>-296.666394</td>\n",
              "      <td>-285.518243</td>\n",
              "      <td>34.415604</td>\n",
              "      <td>38</td>\n",
              "      <td>-215.317748</td>\n",
              "      <td>-208.369549</td>\n",
              "      <td>-212.227408</td>\n",
              "      <td>-211.971568</td>\n",
              "      <td>2.842353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.130152</td>\n",
              "      <td>0.002926</td>\n",
              "      <td>0.005076</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>3</td>\n",
              "      <td>70</td>\n",
              "      <td>{'max_depth': 3, 'n_estimators': 70}</td>\n",
              "      <td>-252.954741</td>\n",
              "      <td>-312.739327</td>\n",
              "      <td>-298.280324</td>\n",
              "      <td>-287.991464</td>\n",
              "      <td>25.468211</td>\n",
              "      <td>39</td>\n",
              "      <td>-186.545948</td>\n",
              "      <td>-176.636303</td>\n",
              "      <td>-185.214760</td>\n",
              "      <td>-182.799004</td>\n",
              "      <td>4.391444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.321240</td>\n",
              "      <td>0.025497</td>\n",
              "      <td>0.005837</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>1</td>\n",
              "      <td>356</td>\n",
              "      <td>{'max_depth': 1, 'n_estimators': 356}</td>\n",
              "      <td>-287.459832</td>\n",
              "      <td>-319.523384</td>\n",
              "      <td>-321.723172</td>\n",
              "      <td>-309.568796</td>\n",
              "      <td>15.659172</td>\n",
              "      <td>40</td>\n",
              "      <td>-251.700772</td>\n",
              "      <td>-250.290728</td>\n",
              "      <td>-243.066185</td>\n",
              "      <td>-248.352562</td>\n",
              "      <td>3.782097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.315708</td>\n",
              "      <td>0.013897</td>\n",
              "      <td>0.006251</td>\n",
              "      <td>0.000556</td>\n",
              "      <td>1</td>\n",
              "      <td>365</td>\n",
              "      <td>{'max_depth': 1, 'n_estimators': 365}</td>\n",
              "      <td>-288.015937</td>\n",
              "      <td>-319.459340</td>\n",
              "      <td>-321.466481</td>\n",
              "      <td>-309.647253</td>\n",
              "      <td>15.317583</td>\n",
              "      <td>41</td>\n",
              "      <td>-250.980921</td>\n",
              "      <td>-249.610734</td>\n",
              "      <td>-242.167375</td>\n",
              "      <td>-247.586343</td>\n",
              "      <td>3.872404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.272837</td>\n",
              "      <td>0.011488</td>\n",
              "      <td>0.005896</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>1</td>\n",
              "      <td>320</td>\n",
              "      <td>{'max_depth': 1, 'n_estimators': 320}</td>\n",
              "      <td>-287.299512</td>\n",
              "      <td>-321.488980</td>\n",
              "      <td>-320.849911</td>\n",
              "      <td>-309.879468</td>\n",
              "      <td>15.968571</td>\n",
              "      <td>42</td>\n",
              "      <td>-254.680389</td>\n",
              "      <td>-252.901311</td>\n",
              "      <td>-247.046127</td>\n",
              "      <td>-251.542609</td>\n",
              "      <td>3.261395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.258826</td>\n",
              "      <td>0.001853</td>\n",
              "      <td>0.005754</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>1</td>\n",
              "      <td>307</td>\n",
              "      <td>{'max_depth': 1, 'n_estimators': 307}</td>\n",
              "      <td>-287.940249</td>\n",
              "      <td>-322.025901</td>\n",
              "      <td>-320.597952</td>\n",
              "      <td>-310.188034</td>\n",
              "      <td>15.742357</td>\n",
              "      <td>43</td>\n",
              "      <td>-255.767753</td>\n",
              "      <td>-253.859720</td>\n",
              "      <td>-248.445201</td>\n",
              "      <td>-252.690891</td>\n",
              "      <td>3.101566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.255513</td>\n",
              "      <td>0.004868</td>\n",
              "      <td>0.005780</td>\n",
              "      <td>0.000255</td>\n",
              "      <td>1</td>\n",
              "      <td>313</td>\n",
              "      <td>{'max_depth': 1, 'n_estimators': 313}</td>\n",
              "      <td>-287.601148</td>\n",
              "      <td>-321.607294</td>\n",
              "      <td>-321.600117</td>\n",
              "      <td>-310.269520</td>\n",
              "      <td>16.028960</td>\n",
              "      <td>44</td>\n",
              "      <td>-255.215113</td>\n",
              "      <td>-253.413261</td>\n",
              "      <td>-247.883637</td>\n",
              "      <td>-252.170671</td>\n",
              "      <td>3.119365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.197061</td>\n",
              "      <td>0.004939</td>\n",
              "      <td>0.005812</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>1</td>\n",
              "      <td>240</td>\n",
              "      <td>{'max_depth': 1, 'n_estimators': 240}</td>\n",
              "      <td>-289.702290</td>\n",
              "      <td>-326.210076</td>\n",
              "      <td>-322.018680</td>\n",
              "      <td>-312.643682</td>\n",
              "      <td>16.312011</td>\n",
              "      <td>45</td>\n",
              "      <td>-263.556526</td>\n",
              "      <td>-260.421062</td>\n",
              "      <td>-257.718926</td>\n",
              "      <td>-260.565504</td>\n",
              "      <td>2.385378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.191390</td>\n",
              "      <td>0.003972</td>\n",
              "      <td>0.006259</td>\n",
              "      <td>0.001440</td>\n",
              "      <td>1</td>\n",
              "      <td>216</td>\n",
              "      <td>{'max_depth': 1, 'n_estimators': 216}</td>\n",
              "      <td>-289.782356</td>\n",
              "      <td>-328.937102</td>\n",
              "      <td>-323.153247</td>\n",
              "      <td>-313.957568</td>\n",
              "      <td>17.256765</td>\n",
              "      <td>46</td>\n",
              "      <td>-267.154350</td>\n",
              "      <td>-263.490960</td>\n",
              "      <td>-262.507895</td>\n",
              "      <td>-264.384402</td>\n",
              "      <td>1.999344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.177341</td>\n",
              "      <td>0.002567</td>\n",
              "      <td>0.005188</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>1</td>\n",
              "      <td>210</td>\n",
              "      <td>{'max_depth': 1, 'n_estimators': 210}</td>\n",
              "      <td>-289.803013</td>\n",
              "      <td>-330.444365</td>\n",
              "      <td>-323.009156</td>\n",
              "      <td>-314.418845</td>\n",
              "      <td>17.668710</td>\n",
              "      <td>47</td>\n",
              "      <td>-268.307510</td>\n",
              "      <td>-264.348917</td>\n",
              "      <td>-263.597397</td>\n",
              "      <td>-265.417941</td>\n",
              "      <td>2.066140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.135335</td>\n",
              "      <td>0.003580</td>\n",
              "      <td>0.004944</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>1</td>\n",
              "      <td>149</td>\n",
              "      <td>{'max_depth': 1, 'n_estimators': 149}</td>\n",
              "      <td>-293.405354</td>\n",
              "      <td>-342.035906</td>\n",
              "      <td>-328.566641</td>\n",
              "      <td>-321.335967</td>\n",
              "      <td>20.501132</td>\n",
              "      <td>48</td>\n",
              "      <td>-283.697866</td>\n",
              "      <td>-276.645941</td>\n",
              "      <td>-281.306564</td>\n",
              "      <td>-280.550123</td>\n",
              "      <td>2.928203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.096330</td>\n",
              "      <td>0.001988</td>\n",
              "      <td>0.005658</td>\n",
              "      <td>0.001556</td>\n",
              "      <td>1</td>\n",
              "      <td>108</td>\n",
              "      <td>{'max_depth': 1, 'n_estimators': 108}</td>\n",
              "      <td>-320.589672</td>\n",
              "      <td>-360.931201</td>\n",
              "      <td>-340.759934</td>\n",
              "      <td>-340.760269</td>\n",
              "      <td>16.469360</td>\n",
              "      <td>49</td>\n",
              "      <td>-303.647344</td>\n",
              "      <td>-292.263201</td>\n",
              "      <td>-300.832288</td>\n",
              "      <td>-298.914278</td>\n",
              "      <td>4.841401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.071102</td>\n",
              "      <td>0.004115</td>\n",
              "      <td>0.004422</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "      <td>{'max_depth': 1, 'n_estimators': 70}</td>\n",
              "      <td>-346.360580</td>\n",
              "      <td>-397.258697</td>\n",
              "      <td>-363.825120</td>\n",
              "      <td>-369.148132</td>\n",
              "      <td>21.117219</td>\n",
              "      <td>50</td>\n",
              "      <td>-345.075502</td>\n",
              "      <td>-324.808175</td>\n",
              "      <td>-338.039347</td>\n",
              "      <td>-335.974341</td>\n",
              "      <td>8.401957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "41       0.226267      0.009088         0.008890        0.002680   \n",
              "6        0.250023      0.003333         0.006264        0.000319   \n",
              "2        0.213073      0.000664         0.005468        0.000116   \n",
              "47       0.332540      0.008256         0.006929        0.000427   \n",
              "32       0.354847      0.004640         0.006881        0.000141   \n",
              "26       0.388570      0.009093         0.006885        0.000111   \n",
              "16       0.378072      0.015528         0.007085        0.000543   \n",
              "30       0.531969      0.014347         0.008498        0.000840   \n",
              "12       0.541610      0.007272         0.008477        0.000068   \n",
              "4        0.325554      0.024534         0.006541        0.000340   \n",
              "35       0.465744      0.007431         0.007553        0.000226   \n",
              "43       0.530451      0.014487         0.008445        0.000305   \n",
              "33       0.394981      0.015075         0.007139        0.000474   \n",
              "8        0.447183      0.009820         0.007534        0.000164   \n",
              "48       0.454541      0.013711         0.007673        0.000211   \n",
              "49       0.544323      0.066345         0.007920        0.000804   \n",
              "22       0.594561      0.006769         0.008618        0.000232   \n",
              "11       1.006095      0.009274         0.012644        0.000821   \n",
              "42       0.922960      0.005390         0.011644        0.000714   \n",
              "9        0.340573      0.000867         0.006582        0.000201   \n",
              "37       1.022487      0.010047         0.012447        0.000651   \n",
              "36       0.913996      0.021477         0.011666        0.000383   \n",
              "45       0.770710      0.019622         0.010166        0.000371   \n",
              "20       0.511904      0.012985         0.008200        0.000413   \n",
              "13       1.056752      0.006448         0.012604        0.000316   \n",
              "17       0.851621      0.013388         0.010959        0.000390   \n",
              "15       0.770056      0.013096         0.013886        0.004086   \n",
              "21       0.685228      0.009594         0.009408        0.000280   \n",
              "19       0.380342      0.005497         0.006673        0.000171   \n",
              "44       0.196078      0.004872         0.005241        0.000010   \n",
              "5        0.457591      0.010399         0.008049        0.000506   \n",
              "40       0.170084      0.004881         0.005042        0.000055   \n",
              "25       0.487405      0.003926         0.007965        0.000667   \n",
              "24       0.672554      0.004546         0.009329        0.000298   \n",
              "39       0.152673      0.005537         0.005195        0.000456   \n",
              "0        0.801045      0.037310         0.011322        0.000310   \n",
              "23       0.808028      0.010017         0.010468        0.000426   \n",
              "34       0.136235      0.007332         0.004808        0.000069   \n",
              "28       0.130152      0.002926         0.005076        0.000119   \n",
              "27       0.321240      0.025497         0.005837        0.000083   \n",
              "31       0.315708      0.013897         0.006251        0.000556   \n",
              "1        0.272837      0.011488         0.005896        0.000140   \n",
              "10       0.258826      0.001853         0.005754        0.000037   \n",
              "38       0.255513      0.004868         0.005780        0.000255   \n",
              "46       0.197061      0.004939         0.005812        0.000303   \n",
              "29       0.191390      0.003972         0.006259        0.001440   \n",
              "14       0.177341      0.002567         0.005188        0.000438   \n",
              "7        0.135335      0.003580         0.004944        0.000129   \n",
              "18       0.096330      0.001988         0.005658        0.001556   \n",
              "3        0.071102      0.004115         0.004422        0.000023   \n",
              "\n",
              "   param_max_depth param_n_estimators                                 params  \\\n",
              "41               4                 99   {'max_depth': 4, 'n_estimators': 99}   \n",
              "6                3                137  {'max_depth': 3, 'n_estimators': 137}   \n",
              "2                3                121  {'max_depth': 3, 'n_estimators': 121}   \n",
              "47               2                267  {'max_depth': 2, 'n_estimators': 267}   \n",
              "32               2                291  {'max_depth': 2, 'n_estimators': 291}   \n",
              "26               4                180  {'max_depth': 4, 'n_estimators': 180}   \n",
              "16               2                302  {'max_depth': 2, 'n_estimators': 302}   \n",
              "30               2                437  {'max_depth': 2, 'n_estimators': 437}   \n",
              "12               2                435  {'max_depth': 2, 'n_estimators': 435}   \n",
              "4                3                171  {'max_depth': 3, 'n_estimators': 171}   \n",
              "35               2                389  {'max_depth': 2, 'n_estimators': 389}   \n",
              "43               2                439  {'max_depth': 2, 'n_estimators': 439}   \n",
              "33               2                314  {'max_depth': 2, 'n_estimators': 314}   \n",
              "8                4                201  {'max_depth': 4, 'n_estimators': 201}   \n",
              "48               4                211  {'max_depth': 4, 'n_estimators': 211}   \n",
              "49               2                495  {'max_depth': 2, 'n_estimators': 495}   \n",
              "22               2                495  {'max_depth': 2, 'n_estimators': 495}   \n",
              "11               4                463  {'max_depth': 4, 'n_estimators': 463}   \n",
              "42               4                437  {'max_depth': 4, 'n_estimators': 437}   \n",
              "9                3                199  {'max_depth': 3, 'n_estimators': 199}   \n",
              "37               4                477  {'max_depth': 4, 'n_estimators': 477}   \n",
              "36               4                416  {'max_depth': 4, 'n_estimators': 416}   \n",
              "45               4                359  {'max_depth': 4, 'n_estimators': 359}   \n",
              "20               4                237  {'max_depth': 4, 'n_estimators': 237}   \n",
              "13               4                493  {'max_depth': 4, 'n_estimators': 493}   \n",
              "17               4                394  {'max_depth': 4, 'n_estimators': 394}   \n",
              "15               4                363  {'max_depth': 4, 'n_estimators': 363}   \n",
              "21               4                320  {'max_depth': 4, 'n_estimators': 320}   \n",
              "19               3                219  {'max_depth': 3, 'n_estimators': 219}   \n",
              "44               2                155  {'max_depth': 2, 'n_estimators': 155}   \n",
              "5                3                264  {'max_depth': 3, 'n_estimators': 264}   \n",
              "40               2                130  {'max_depth': 2, 'n_estimators': 130}   \n",
              "25               3                293  {'max_depth': 3, 'n_estimators': 293}   \n",
              "24               3                413  {'max_depth': 3, 'n_estimators': 413}   \n",
              "39               3                 84   {'max_depth': 3, 'n_estimators': 84}   \n",
              "0                3                485  {'max_depth': 3, 'n_estimators': 485}   \n",
              "23               3                495  {'max_depth': 3, 'n_estimators': 495}   \n",
              "34               2                102  {'max_depth': 2, 'n_estimators': 102}   \n",
              "28               3                 70   {'max_depth': 3, 'n_estimators': 70}   \n",
              "27               1                356  {'max_depth': 1, 'n_estimators': 356}   \n",
              "31               1                365  {'max_depth': 1, 'n_estimators': 365}   \n",
              "1                1                320  {'max_depth': 1, 'n_estimators': 320}   \n",
              "10               1                307  {'max_depth': 1, 'n_estimators': 307}   \n",
              "38               1                313  {'max_depth': 1, 'n_estimators': 313}   \n",
              "46               1                240  {'max_depth': 1, 'n_estimators': 240}   \n",
              "29               1                216  {'max_depth': 1, 'n_estimators': 216}   \n",
              "14               1                210  {'max_depth': 1, 'n_estimators': 210}   \n",
              "7                1                149  {'max_depth': 1, 'n_estimators': 149}   \n",
              "18               1                108  {'max_depth': 1, 'n_estimators': 108}   \n",
              "3                1                 70   {'max_depth': 1, 'n_estimators': 70}   \n",
              "\n",
              "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
              "41        -239.140201        -299.719542        -258.634296      -265.831346   \n",
              "6         -244.438229        -304.533409        -251.465551      -266.812396   \n",
              "2         -243.344933        -304.401840        -254.079236      -267.275336   \n",
              "47        -240.444091        -302.803964        -259.613981      -267.620679   \n",
              "32        -241.840456        -303.311846        -259.036209      -268.062837   \n",
              "26        -251.023010        -301.820389        -251.491774      -268.111724   \n",
              "16        -241.948864        -305.349984        -258.406315      -268.568388   \n",
              "30        -238.999624        -306.706189        -261.231241      -268.979018   \n",
              "12        -239.046106        -306.846962        -261.190062      -269.027710   \n",
              "4         -245.110404        -307.535504        -254.496243      -269.047384   \n",
              "35        -242.164459        -305.779086        -259.707190      -269.216912   \n",
              "43        -239.061357        -306.591580        -262.900956      -269.517964   \n",
              "33        -241.969526        -304.692513        -262.057680      -269.573239   \n",
              "8         -256.125398        -301.948695        -251.769023      -269.947706   \n",
              "48        -258.026175        -301.897845        -252.481026      -270.801682   \n",
              "49        -238.785233        -308.326131        -266.339100      -271.150155   \n",
              "22        -238.785233        -308.326131        -266.339100      -271.150155   \n",
              "11        -264.083292        -298.266089        -252.673771      -271.674384   \n",
              "42        -264.086397        -298.606780        -253.128459      -271.940546   \n",
              "9         -247.334461        -308.127996        -260.933199      -272.131886   \n",
              "37        -265.596068        -298.392426        -252.846965      -272.278486   \n",
              "36        -264.997488        -298.646608        -253.220600      -272.288232   \n",
              "45        -264.636681        -299.172041        -253.512777      -272.440499   \n",
              "20        -262.158470        -301.813298        -253.594659      -272.522142   \n",
              "13        -266.598200        -298.249717        -252.742118      -272.530012   \n",
              "17        -266.377387        -298.724254        -253.645220      -272.915620   \n",
              "15        -266.038459        -299.156047        -253.573957      -272.922821   \n",
              "21        -266.134098        -299.086622        -253.658849      -272.959856   \n",
              "19        -247.862685        -310.550499        -263.300370      -273.904518   \n",
              "44        -238.252844        -311.108326        -273.019792      -274.126987   \n",
              "5         -249.421200        -312.822772        -266.479466      -276.241146   \n",
              "40        -236.372528        -313.331043        -280.319201      -276.674257   \n",
              "25        -250.997272        -314.770765        -266.634172      -277.467403   \n",
              "24        -251.588342        -316.670789        -272.852182      -280.370438   \n",
              "39        -246.760039        -307.640594        -293.612071      -282.670901   \n",
              "0         -253.761815        -317.554585        -278.972618      -283.429672   \n",
              "23        -253.965659        -317.523775        -278.875016      -283.454817   \n",
              "34        -238.914425        -320.973910        -296.666394      -285.518243   \n",
              "28        -252.954741        -312.739327        -298.280324      -287.991464   \n",
              "27        -287.459832        -319.523384        -321.723172      -309.568796   \n",
              "31        -288.015937        -319.459340        -321.466481      -309.647253   \n",
              "1         -287.299512        -321.488980        -320.849911      -309.879468   \n",
              "10        -287.940249        -322.025901        -320.597952      -310.188034   \n",
              "38        -287.601148        -321.607294        -321.600117      -310.269520   \n",
              "46        -289.702290        -326.210076        -322.018680      -312.643682   \n",
              "29        -289.782356        -328.937102        -323.153247      -313.957568   \n",
              "14        -289.803013        -330.444365        -323.009156      -314.418845   \n",
              "7         -293.405354        -342.035906        -328.566641      -321.335967   \n",
              "18        -320.589672        -360.931201        -340.759934      -340.760269   \n",
              "3         -346.360580        -397.258697        -363.825120      -369.148132   \n",
              "\n",
              "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
              "41       25.249584                1         -118.287817         -111.714466   \n",
              "6        26.826627                2         -147.865735         -142.781576   \n",
              "2        26.615651                3         -155.450152         -149.231834   \n",
              "47       26.080246                4         -169.646317         -160.380511   \n",
              "32       25.894567                5         -165.989825         -155.599304   \n",
              "26       23.836393                6          -78.801195          -78.138161   \n",
              "16       26.862319                7         -164.606615         -153.527684   \n",
              "30       28.178784                8         -145.489765         -131.843921   \n",
              "12       28.228951                9         -145.685230         -132.158503   \n",
              "4        27.483632               10         -132.673931         -130.636762   \n",
              "35       26.826993               11         -152.029338         -138.251466   \n",
              "43       27.963325               12         -145.076551         -131.568911   \n",
              "33       26.152196               13         -162.752955         -151.087178   \n",
              "8        22.697900               14          -71.468125          -71.544820   \n",
              "48       22.104535               15          -68.028119          -68.300412   \n",
              "49       28.593050               16         -136.949726         -124.490166   \n",
              "22       28.593050               16         -136.949726         -124.490166   \n",
              "11       19.371515               18          -25.082481          -23.281627   \n",
              "42       19.379287               19          -27.123176          -26.078462   \n",
              "9        26.051505               20         -122.077881         -122.158787   \n",
              "37       19.184860               21          -24.277007          -22.002629   \n",
              "36       19.248320               22          -29.675427          -28.599269   \n",
              "45       19.439938               23          -36.763864          -36.641410   \n",
              "20       21.004977               24          -59.937224          -60.968301   \n",
              "13       19.046000               25          -22.994918          -20.913465   \n",
              "17       18.975268               26          -31.973895          -31.272266   \n",
              "15       19.234995               27          -36.072727          -35.970523   \n",
              "21       19.163574               28          -43.934972          -43.313801   \n",
              "19       26.668039               29         -115.672294         -115.942186   \n",
              "44       29.753428               30         -194.669503         -188.679666   \n",
              "5        26.788152               31         -103.228856         -103.592948   \n",
              "40       31.523721               32         -202.931792         -197.253261   \n",
              "25       27.138948               33          -95.530594          -96.287317   \n",
              "24       27.096424               34          -70.739271          -72.653390   \n",
              "39       26.030654               35         -175.151825         -166.785080   \n",
              "0        26.233292               36          -59.667545          -63.338495   \n",
              "23       26.148798               37          -58.393495          -61.964452   \n",
              "34       34.415604               38         -215.317748         -208.369549   \n",
              "28       25.468211               39         -186.545948         -176.636303   \n",
              "27       15.659172               40         -251.700772         -250.290728   \n",
              "31       15.317583               41         -250.980921         -249.610734   \n",
              "1        15.968571               42         -254.680389         -252.901311   \n",
              "10       15.742357               43         -255.767753         -253.859720   \n",
              "38       16.028960               44         -255.215113         -253.413261   \n",
              "46       16.312011               45         -263.556526         -260.421062   \n",
              "29       17.256765               46         -267.154350         -263.490960   \n",
              "14       17.668710               47         -268.307510         -264.348917   \n",
              "7        20.501132               48         -283.697866         -276.645941   \n",
              "18       16.469360               49         -303.647344         -292.263201   \n",
              "3        21.117219               50         -345.075502         -324.808175   \n",
              "\n",
              "    split2_train_score  mean_train_score  std_train_score  \n",
              "41         -115.705761       -115.236015         2.704038  \n",
              "6          -148.144886       -146.264066         2.465127  \n",
              "2          -154.527866       -153.069951         2.739952  \n",
              "47         -166.519723       -165.515517         3.848819  \n",
              "32         -161.756025       -161.115051         4.266057  \n",
              "26          -80.406992        -79.115449         0.952528  \n",
              "16         -159.558914       -159.231071         4.528892  \n",
              "30         -138.524280       -138.619322         5.571298  \n",
              "12         -138.631844       -138.825192         5.523955  \n",
              "4          -134.051616       -132.454103         1.402747  \n",
              "35         -144.693506       -144.991437         5.628736  \n",
              "43         -138.274815       -138.306759         5.514517  \n",
              "33         -156.990622       -156.943585         4.762650  \n",
              "8           -74.977502        -72.663482         1.636558  \n",
              "48          -72.253605        -69.527378         1.930936  \n",
              "49         -130.758340       -130.732744         5.086626  \n",
              "22         -130.758340       -130.732744         5.086626  \n",
              "11          -26.815669        -25.059925         1.442855  \n",
              "42          -29.001141        -27.400926         1.209234  \n",
              "9          -123.796066       -122.677578         0.791580  \n",
              "37          -25.608257        -23.962631         1.488682  \n",
              "36          -31.184823        -29.819840         1.060476  \n",
              "45          -38.569223        -37.324832         0.881336  \n",
              "20          -64.587592        -61.831039         1.994111  \n",
              "13          -24.079672        -22.662685         1.313773  \n",
              "17          -34.033673        -32.426611         1.171909  \n",
              "15          -38.155618        -36.732956         1.006839  \n",
              "21          -45.671065        -44.306613         0.997584  \n",
              "19         -116.619518       -116.077999         0.398449  \n",
              "44         -192.159128       -191.836099         2.455986  \n",
              "5          -103.877132       -103.566312         0.265327  \n",
              "40         -199.610645       -199.931899         2.329353  \n",
              "25          -96.706497        -96.174803         0.486609  \n",
              "24          -74.261201        -72.551287         1.439633  \n",
              "39         -173.989616       -171.975507         3.700728  \n",
              "0           -64.197799        -62.401280         1.964617  \n",
              "23          -62.691977        -61.016641         1.878474  \n",
              "34         -212.227408       -211.971568         2.842353  \n",
              "28         -185.214760       -182.799004         4.391444  \n",
              "27         -243.066185       -248.352562         3.782097  \n",
              "31         -242.167375       -247.586343         3.872404  \n",
              "1          -247.046127       -251.542609         3.261395  \n",
              "10         -248.445201       -252.690891         3.101566  \n",
              "38         -247.883637       -252.170671         3.119365  \n",
              "46         -257.718926       -260.565504         2.385378  \n",
              "29         -262.507895       -264.384402         1.999344  \n",
              "14         -263.597397       -265.417941         2.066140  \n",
              "7          -281.306564       -280.550123         2.928203  \n",
              "18         -300.832288       -298.914278         4.841401  \n",
              "3          -338.039347       -335.974341         8.401957  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpanBfX0P1b3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f9e43528-36ed-40a2-f325-4aa97f171c38"
      },
      "source": [
        "search.best_estimator_"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
              "       learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
              "       min_child_weight=1, missing=None, n_estimators=99, n_jobs=-1,\n",
              "       nthread=None, objective='reg:linear', random_state=42, reg_alpha=0,\n",
              "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
              "       subsample=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-zEQPvCP96x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "8704082d-f275-4173-de8c-e9bcb758d242"
      },
      "source": [
        "## plotting importance of features\n",
        "plt.figure(figsize=(5,10)) ## to make it easier to see labels\n",
        "\n",
        "importances = pd.Series(search.best_estimator_.feature_importances_, X_train.columns)\n",
        "importances.sort_values().plot.barh(color='gray')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f94fbe6c208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAJCCAYAAADJDxCdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOQGYmVWUE4CZWUU5AZiZVdT/Awmn5HujSi1XAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEvkRCQvHALT",
        "colab_type": "text"
      },
      "source": [
        "### Take the last step\n",
        "\n",
        "Yesterday's assingment said,\n",
        "\n",
        "At the end of the day, take the last step in the \"universal workflow of machine learning\" — \"You can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\"\n",
        "\n",
        "See the [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) documentation for the `refit` parameter, `best_estimator_` attribute, and `predict` method:\n",
        "\n",
        "> **refit : boolean, or string, default=True**\n",
        "\n",
        "> Refit an estimator using the best found parameters on the whole dataset.\n",
        "\n",
        "> The refitted estimator is made available at the `best_estimator_` attribute and permits using `predict` directly on this `GridSearchCV` instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9zgaiEUHALV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a58c8205-4628-4914-ddc5-41a9133b89e2"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "final = search.best_estimator_\n",
        "\n",
        "y_pred = final.predict(X_test) # we already wrangled X_test in the same way as X_train\n",
        "\n",
        "test_mae = mean_absolute_error(y_test, y_pred)\n",
        "print('Mean absolute error, with final model, on hold-out-test set:', test_mae)\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean absolute error, with final model, on hold-out-test set: 252.56884338378907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2UhCHZ9HALZ",
        "colab_type": "text"
      },
      "source": [
        "## A few new things!\n",
        "- Pipeline + RandomizedSearchCV\n",
        "- SelectKBest for feature selection, in a pipeline\n",
        "- Ridge Regression, a linear model with regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q4RzL_1HALb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h3E6mdcHALi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shows which features were selected\n",
        "selector = search.best_estimator_.named_steps['selectkbest']\n",
        "all_names = X_train.columns\n",
        "selected_mask = selector.get_support()\n",
        "selected_names = all_names[selected_mask]\n",
        "unselected_names = all_names[~selected_mask]\n",
        "\n",
        "print('Features selected:')\n",
        "for name in selected_names:\n",
        "    print(name)\n",
        "\n",
        "print('\\n', 'Features not selected:')\n",
        "for name in unselected_names:\n",
        "    print(name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMacQxC4HALl",
        "colab_type": "text"
      },
      "source": [
        "## Regularization with Linear Models\n",
        "\n",
        "- https://www.google.com/search?q=site%3Ascikit-learn.org+regularization+%22linear+models%22\n",
        "  - https://scikit-learn.org/stable/modules/linear_model.html\n",
        "  - https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression\n",
        "  - https://scikit-learn.org/stable/modules/linear_model.html#lasso\n",
        "  - https://scikit-learn.org/stable/modules/linear_model.html#setting-regularization-parameter\n",
        "  - https://scikit-learn.org/stable/modules/linear_model.html#using-cross-validation\n",
        "    \n",
        "> The [`Lasso`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso) is a linear model that estimates sparse coefficients. It is useful in some contexts due to its tendency to prefer solutions with fewer non-zero coefficients, effectively reducing the number of features upon which the given solution is dependent. \n",
        "  \n",
        "> The `alpha` parameter controls the degree of sparsity of the estimated coefficients.\n",
        "  \n",
        "> scikit-learn exposes objects that set the Lasso `alpha` parameter by cross-validation: [`LassoCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV) ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPNGTkVjHALm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ipywidgets import interact\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
        "\n",
        "def plot_lasso_coefs(power=-2):\n",
        "    # Make pipeline with StandardScaler and Lasso Linear Model\n",
        "    alpha = 10**power\n",
        "    print(f'Lasso Alpha: {alpha}')\n",
        "    pipe = make_pipeline(StandardScaler(), Lasso(alpha=alpha, max_iter=100000))\n",
        "    \n",
        "    # Get cross-validation scores\n",
        "    maes = -cross_val_score(pipe, X_train, y_train, scoring='neg_mean_absolute_error', cv=3)\n",
        "    print('Cross-Validated Mean Absolute Error:', maes.mean())\n",
        "    \n",
        "    # Get coefficients\n",
        "    pipe.fit(X_train, y_train)\n",
        "    coefficients = pd.Series(pipe.named_steps['lasso'].coef_, X_train.columns)\n",
        "    \n",
        "    # Plot coefficients\n",
        "    plt.figure(figsize=(16,8))\n",
        "    coefficients.sort_values().plot.barh(color='grey')\n",
        "    plt.xlim(-550,550)\n",
        "\n",
        "interact(plot_lasso_coefs, power=(-2,2,1));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVLZANkPHALp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "pipe = make_pipeline(StandardScaler(), LassoCV(cv=3))\n",
        "pipe.fit(X_train, y_train)\n",
        "lasso = pipe.named_steps['lassocv']\n",
        "print('Lasso Linear Model, alpha value optimized with cross validation:', lasso.alpha_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl8Itv3zHALs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphas = lasso.alphas_\n",
        "mses = lasso.mse_path_.mean(axis=1)\n",
        "rmses = np.sqrt(mses)\n",
        "plt.plot(alphas, rmses)\n",
        "plt.title('Lasso Linear Model')\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('RMSE')\n",
        "plt.xscale('log');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf-wBcgWHALw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(alphas, rmses)\n",
        "plt.title('Lasso Linear Model')\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('RMSE')\n",
        "plt.xlim(1,10)\n",
        "plt.ylim(380,400);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM4BlvzCHAL1",
        "colab_type": "text"
      },
      "source": [
        "## Want to learn more about regularized linear models?\n",
        "- Aaron Gallant, [Ridge Regression](https://www.youtube.com/watch?v=XK5jkedy17w) (9 minute video)\n",
        "- Selecting good features, [Part 2](https://blog.datadive.net/selecting-good-features-part-ii-linear-models-and-regularization/) and [Part 4](https://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/)\n",
        "- [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/), Chapters 3 & 6"
      ]
    }
  ]
}