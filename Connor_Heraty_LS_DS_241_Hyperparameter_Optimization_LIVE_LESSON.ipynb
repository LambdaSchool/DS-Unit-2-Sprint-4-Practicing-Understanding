{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Connor Heraty - LS_DS_241_Hyperparameter_Optimization_LIVE_LESSON.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/connorpheraty/DS-Unit-2-Sprint-4-Practicing-Understanding/blob/master/Connor_Heraty_LS_DS_241_Hyperparameter_Optimization_LIVE_LESSON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O67uhlT4MExK"
      },
      "source": [
        "_Lambda School Data Science — Practicing & Understanding Predictive Modeling_\n",
        "\n",
        "# Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VE4rfZd4NUGA"
      },
      "source": [
        "Today we'll use this process:\n",
        "\n",
        "## \"A universal workflow of machine learning\"\n",
        "\n",
        "_Excerpt from Francois Chollet, [Deep Learning with Python](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/README.md), Chapter 4: Fundamentals of machine learning_\n",
        " \n",
        "**1. Define the problem at hand and the data on which you’ll train.** Collect this data, or annotate it with labels if need be.\n",
        "\n",
        "**2. Choose how you’ll measure success on your problem.** Which metrics will you monitor on your validation data?\n",
        "\n",
        "**3. Determine your evaluation protocol:** hold-out validation? K-fold validation? Which portion of the data should you use for validation?\n",
        "\n",
        "**4. Develop a first model that does better than a basic baseline:** a model with statistical power.\n",
        "\n",
        "**5. Develop a model that overfits.** The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
        "\n",
        "**6. Regularize your model and tune its hyperparameters, based on performance on the validation data.** Repeatedly modify your model, train it, evaluate on your validation data (not the test data, at this point), modify it again, and repeat, until the model is as good as it can get. \n",
        "\n",
        "**Iterate on feature engineering: add new features, or remove features that don’t seem to be informative.** \n",
        "\n",
        "Once you’ve developed a satisfactory model configuration, you can **train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3kt6bzEcOIaa"
      },
      "source": [
        "## 1. Define the problem at hand and the data on which you'll train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "di16k7vpRg67"
      },
      "source": [
        "We'll apply the workflow to a [project from _Python Data Science Handbook_](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic) by Jake VanderPlas:\n",
        "\n",
        "> **Predicting Bicycle Traffic**\n",
        "\n",
        "> As an example, let's take a look at whether we can predict the number of bicycle trips across Seattle's Fremont Bridge based on weather, season, and other factors.\n",
        "\n",
        "> We will join the bike data with another dataset, and try to determine the extent to which weather and seasonal factors—temperature, precipitation, and daylight hours—affect the volume of bicycle traffic through this corridor. Fortunately, the NOAA makes available their daily [weather station data](http://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND) (I used station ID USW00024233) and we can easily use Pandas to join the two data sources.\n",
        "\n",
        "> Let's start by loading the two datasets, indexing by date:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "19dpb_d0R1A6"
      },
      "source": [
        "So this is a regression problem, not a classification problem. We'll define the target, choose an evaluation metric, and choose models that are appropriate for regression problems.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "os1zruXQ30KM"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5XVu-HSeMDtV",
        "outputId": "2498c2f1-afaa-495e-a025-ffd8087fc636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1616k    0 1616k    0     0   977k      0 --:--:--  0:00:01 --:--:--  977k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sih_7mTzMdfr",
        "outputId": "3b0d5e96-644d-44f5-adbf-9879f49de4e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-13 21:23:08--  https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 234945 (229K) [text/plain]\n",
            "Saving to: ‘BicycleWeather.csv.1’\n",
            "\n",
            "\rBicycleWeather.csv.   0%[                    ]       0  --.-KB/s               \rBicycleWeather.csv. 100%[===================>] 229.44K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-05-13 21:23:08 (7.89 MB/s) - ‘BicycleWeather.csv.1’ saved [234945/234945]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9GYm74kD34OQ"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BfQ7gE28MNdF",
        "colab": {}
      },
      "source": [
        "# Modified from cells 15, 16, and 20, at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Download and join data into a dataframe\n",
        "def load(): \n",
        "    fremont_bridge = 'https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD'\n",
        "    \n",
        "    bicycle_weather = 'https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv'\n",
        "\n",
        "    counts = pd.read_csv(fremont_bridge, index_col='Date', parse_dates=True, \n",
        "                         infer_datetime_format=True)\n",
        "\n",
        "    weather = pd.read_csv(bicycle_weather, index_col='DATE', parse_dates=True, \n",
        "                          infer_datetime_format=True)\n",
        "\n",
        "    daily = counts.resample('d').sum()\n",
        "    daily['Total'] = daily.sum(axis=1)\n",
        "    daily = daily[['Total']] # remove other columns\n",
        "\n",
        "    weather_columns = ['PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND']\n",
        "    daily = daily.join(weather[weather_columns], how='inner')\n",
        "    \n",
        "    # Make a feature for yesterday's total\n",
        "    daily['Total_yesterday'] = daily.Total.shift(1)\n",
        "    daily = daily.drop(index=daily.index[0])\n",
        "    \n",
        "    return daily\n",
        "\n",
        "daily = load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VVB3g4704An5"
      },
      "source": [
        "### First fast look at the data\n",
        "- What's the shape?\n",
        "- What's the date range?\n",
        "- What's the target and the features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t50E2fTUWBBU",
        "outputId": "7c816278-41a0-4a58-9f96-59b5117b1717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "daily.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1063, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66PGW0TW9mjo",
        "colab_type": "code",
        "outputId": "5fad8bf2-5132-413c-c277-810c728118d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "daily.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>3475.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>83</td>\n",
              "      <td>65</td>\n",
              "      <td>3521.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>3148.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>217</td>\n",
              "      <td>89</td>\n",
              "      <td>57</td>\n",
              "      <td>3475.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>2006.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>51</td>\n",
              "      <td>3148.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>2142.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>13</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>3537.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211</td>\n",
              "      <td>78</td>\n",
              "      <td>19</td>\n",
              "      <td>2142.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2012-10-04  3475.0     0     0     0   189    83    65           3521.0\n",
              "2012-10-05  3148.0     0     0     0   217    89    57           3475.0\n",
              "2012-10-06  2006.0     0     0     0   239    78    51           3148.0\n",
              "2012-10-07  2142.0     0     0     0   239    78    13           2006.0\n",
              "2012-10-08  3537.0     0     0     0   211    78    19           2142.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCY7-ElJ9pS4",
        "colab_type": "code",
        "outputId": "3cd2fe92-64a9-427e-c982-fe4930c01e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "daily.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-08-28</th>\n",
              "      <td>2653.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>233</td>\n",
              "      <td>156</td>\n",
              "      <td>26</td>\n",
              "      <td>4336.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-29</th>\n",
              "      <td>699.0</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>222</td>\n",
              "      <td>133</td>\n",
              "      <td>58</td>\n",
              "      <td>2653.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-30</th>\n",
              "      <td>1213.0</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>128</td>\n",
              "      <td>47</td>\n",
              "      <td>699.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-31</th>\n",
              "      <td>2823.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>161</td>\n",
              "      <td>58</td>\n",
              "      <td>1213.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-01</th>\n",
              "      <td>2876.0</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>194</td>\n",
              "      <td>139</td>\n",
              "      <td>-9999</td>\n",
              "      <td>2823.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2015-08-28  2653.0     5     0     0   233   156    26           4336.0\n",
              "2015-08-29   699.0   325     0     0   222   133    58           2653.0\n",
              "2015-08-30  1213.0   102     0     0   200   128    47            699.0\n",
              "2015-08-31  2823.0     0     0     0   189   161    58           1213.0\n",
              "2015-09-01  2876.0    58     0     0   194   139 -9999           2823.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlaGsqtv96rZ",
        "colab_type": "code",
        "outputId": "920d037f-6260-4f4e-c545-6dbbed6f9962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "daily.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1063 entries, 2012-10-04 to 2015-09-01\n",
            "Data columns (total 8 columns):\n",
            "Total              1063 non-null float64\n",
            "PRCP               1063 non-null int64\n",
            "SNOW               1063 non-null int64\n",
            "SNWD               1063 non-null int64\n",
            "TMAX               1063 non-null int64\n",
            "TMIN               1063 non-null int64\n",
            "AWND               1063 non-null int64\n",
            "Total_yesterday    1063 non-null float64\n",
            "dtypes: float64(2), int64(6)\n",
            "memory usage: 74.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XgMvCsaWJR7Q"
      },
      "source": [
        "Target\n",
        "- Total : Daily total number of bicycle trips across Seattle's Fremont Bridge\n",
        "\n",
        "Features\n",
        "- Date (index) : from 2012-10-04 to 2015-09-01\n",
        "- Total_yesterday : Total trips yesterday\n",
        "- PRCP : Precipitation (1/10 mm)\n",
        "- SNOW : Snowfall (1/10 mm)\n",
        "- SNWD : Snow depth (1/10 mm)\n",
        "- TMAX : Maximum temperature (1/10 Celsius)\n",
        "- TMIN : Minimum temperature (1/10 Celsius)\n",
        "- AWND : Average daily wind speed (1/10 meters per second)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lenL-przSYCo"
      },
      "source": [
        "## 2. Choose how you’ll measure success on your problem.\n",
        "\n",
        "Which metrics will you monitor on your validation data?\n",
        "\n",
        "This is a regression problem, so we need to choose a regression [metric](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
        "\n",
        "\n",
        "\n",
        "I'll choose mean absolute error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1TqbomapSyRP",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IRHrB3rsS5hF"
      },
      "source": [
        "## 3. Determine your evaluation protocol \n",
        "\n",
        "We're doing model selection, hyperparameter optimization, and performance estimation. So generally we have two ideal [options](https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg) to choose from:\n",
        "\n",
        "- 3-way holdout method (train/validation/test split)\n",
        "- Cross-validation with independent test set\n",
        "\n",
        "I'll choose cross-validation with independent test set. Scikit-learn makes cross-validation convenient for us!\n",
        "\n",
        "Specifically, I will use random shuffled cross validation to train and validate, but I will hold out an \"out-of-time\" test set, from the last 100 days of data:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A3xo6HgbPMFm",
        "outputId": "c0a96ae3-b732-49e4-8db8-72069ffa7395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train = daily[:-100] # everything but the last 100 days\n",
        "test  = daily[-100:] # last 100 days\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((963, 8), (100, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpySz4fF_53D",
        "colab_type": "code",
        "outputId": "2ff53e47-aa97-4fff-937e-5734ede21b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = train.drop(columns='Total')\n",
        "y_train = train['Total']\n",
        "\n",
        "X_test  = test.drop(columns='Total')\n",
        "y_test  = test['Total']\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((963, 7), (963,), (100, 7), (100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vH6IsORQTvTU"
      },
      "source": [
        "## 4. Develop a first model that does better than a basic baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DJBs2nQkj7oB"
      },
      "source": [
        "### Look at the target's distribution and descriptive stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P5peakv9Zs71",
        "outputId": "eb1cec93-19e3-4627-f04a-fa7d20a941e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.distplot(y_train);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUCoUIiIS1P8Hd41s336jLrkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc3c9cq_Avfj",
        "colab_type": "code",
        "outputId": "7e859ac2-3715-44ac-e4f5-21ea1251b9ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "y_train.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     963.000000\n",
              "mean     2534.329180\n",
              "std      1224.065027\n",
              "min        98.000000\n",
              "25%      1755.000000\n",
              "50%      2381.000000\n",
              "75%      3317.500000\n",
              "max      6088.000000\n",
              "Name: Total, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fEjxxgV9kExY"
      },
      "source": [
        "### Basic baseline 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6GepKdQjYcEP",
        "outputId": "cff662e0-bad4-40aa-b052-fb1f00be94ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = [y_train.median()] * len(y_train)\n",
        "mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "971.9376947040498"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tN2I_F3FkIHb"
      },
      "source": [
        "### Basic baseline 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZW8bhZFtTunV",
        "outputId": "07d4de2f-f1ca-470d-b13a-2cad77a0f69e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = X_train['Total_yesterday']\n",
        "mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "708.061266874351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ggf3VpxwkJ0T"
      },
      "source": [
        "### First model that does better than a basic baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KfaqL1Ezer2-"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OeBtU68skfW-",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "scores = cross_validate(LinearRegression(), X_train, y_train, \n",
        "                        scoring='neg_mean_absolute_error', cv=3, \n",
        "                        return_train_score=True, return_estimator=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipenee_7EJ2u",
        "colab_type": "code",
        "outputId": "09e00e9c-9ad5-4e26-97c7-940fec825433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.007126</td>\n",
              "      <td>0.002564</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-555.186275</td>\n",
              "      <td>-619.509206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.005220</td>\n",
              "      <td>0.002625</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-651.126513</td>\n",
              "      <td>-583.427702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.005666</td>\n",
              "      <td>0.002256</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-615.965800</td>\n",
              "      <td>-589.341301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.007126    0.002564  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "1  0.005220    0.002625  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "2  0.005666    0.002256  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -555.186275  -619.509206  \n",
              "1 -651.126513  -583.427702  \n",
              "2 -615.965800  -589.341301  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEhrY7YmE8e4",
        "colab_type": "code",
        "outputId": "10b1a886-752e-4406-cfd0-4025001e5a8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "-scores['test_score'].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "607.4261958631806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndz5IXGRFRMB",
        "colab_type": "code",
        "outputId": "7255df57-4ec0-4563-f4b3-16bb168625f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "for i, model in enumerate(scores['estimator']):\n",
        "    coefficients = model.coef_\n",
        "    intercept = model.intercept_\n",
        "    feature_names = X_train.columns\n",
        "    \n",
        "    print(f'Model from cross-validation fold #{i}')\n",
        "    print('Intercept', intercept)\n",
        "    print(pd.Series(coefficients, feature_names).to_string())\n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model from cross-validation fold #0\n",
            "Intercept 566.7766337283679\n",
            "PRCP               -3.525103\n",
            "SNOW               -0.082029\n",
            "SNWD              -12.045027\n",
            "TMAX                9.475238\n",
            "TMIN               -4.607775\n",
            "AWND               -2.745191\n",
            "Total_yesterday     0.417360\n",
            "\n",
            "\n",
            "Model from cross-validation fold #1\n",
            "Intercept 671.9064515706045\n",
            "PRCP               -2.772253\n",
            "SNOW               -0.000995\n",
            "SNWD               20.800688\n",
            "TMAX                8.804948\n",
            "TMIN               -3.741386\n",
            "AWND               -6.108300\n",
            "Total_yesterday     0.405074\n",
            "\n",
            "\n",
            "Model from cross-validation fold #2\n",
            "Intercept 465.84525362296563\n",
            "PRCP               -2.876196\n",
            "SNOW               -0.016432\n",
            "SNWD               -8.809696\n",
            "TMAX               10.419441\n",
            "TMIN               -5.862868\n",
            "AWND               -2.398991\n",
            "Total_yesterday     0.423493\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fg1YI4X8n9nI"
      },
      "source": [
        "## 5. Develop a model that overfits. \n",
        "\n",
        "\"The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\" —Chollet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lodd6UPOoy89"
      },
      "source": [
        "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.03-validation-curve.png\">\n",
        "\n",
        "Diagram Source: https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xj82P0VdwYlh"
      },
      "source": [
        "### Random Forest?\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_yYXpk99C4cM",
        "outputId": "9e300aa6-fe82-457d-b7c4-c3e15d27c751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, max_depth=None, n_jobs=-1)\n",
        "\n",
        "scores = cross_validate(model, X_train, y_train, \n",
        "                        scoring='neg_mean_absolute_error', \n",
        "                        cv=3, return_train_score=True, \n",
        "                        return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.731998</td>\n",
              "      <td>0.104760</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-558.469034</td>\n",
              "      <td>-242.984953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.251459</td>\n",
              "      <td>0.103897</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-635.797850</td>\n",
              "      <td>-224.710452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.235977</td>\n",
              "      <td>0.103634</td>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>-639.092461</td>\n",
              "      <td>-224.836106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  1.731998    0.104760  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "1  0.251459    0.103897  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "2  0.235977    0.103634  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -558.469034  -242.984953  \n",
              "1 -635.797850  -224.710452  \n",
              "2 -639.092461  -224.836106  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqDXxpM6KMSQ",
        "colab_type": "code",
        "outputId": "834f680f-9f5f-49f5-e7c9-2b1a0b4f451b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "-scores['train_score'].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "230.84383696780893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ryO1hVKr-6f"
      },
      "source": [
        "### Validation Curve\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html\n",
        "\n",
        "> Validation curve. Determine training and test scores for varying parameter values. This is similar to grid search with one parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjLSeMJhM91_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apKk4vKiwgtM",
        "outputId": "5a3a8015-09ea-4bd9-dd1b-3b56ec987edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Modified from cell 13 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100)\n",
        "\n",
        "depth = [2, 3, 4, 5, 6]\n",
        "train_score, val_score = validation_curve(\n",
        "    model, X_train, y_train,\n",
        "    param_name='max_depth', param_range=depth, \n",
        "    scoring='neg_mean_absolute_error', cv=3)\n",
        "\n",
        "plt.plot(depth, np.median(train_score, 1), color='blue', label='training score')\n",
        "plt.plot(depth, np.median(val_score, 1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('depth');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DQoMvZ7-yCAQ"
      },
      "source": [
        "### `RandomizedSearchCV`\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/grid_search.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bk_dX_mByKm7",
        "outputId": "21a5b078-b170-42b0-e173-c66966981bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 200], \n",
        "    'max_depth': [4, 5], \n",
        "    'criterion': ['mse', 'mae']\n",
        "}\n",
        "\n",
        "gridsearch = RandomizedSearchCV(\n",
        "    RandomForestRegressor(n_jobs=-1, random_state=42), \n",
        "    param_distributions=param_distributions, \n",
        "    n_iter=8, \n",
        "    cv=3, \n",
        "    scoring='neg_mean_absolute_error', \n",
        "    verbose=10, \n",
        "    return_train_score=True, \n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    4.9s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   10.6s\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   14.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   14.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=8, n_jobs=-1,\n",
              "          param_distributions={'n_estimators': [100, 200], 'max_depth': [4, 5], 'criterion': ['mse', 'mae']},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW9Ihz6bQ5HD",
        "colab_type": "code",
        "outputId": "98e89544-d716-4af6-e5a1-c2715865174f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "results = pd.DataFrame(gridsearch.cv_results_)\n",
        "print(f'Best result from search of {len(results)} parameter combinations')\n",
        "results.sort_values(by='rank_test_score').head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best result from search of 8 parameter combinations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.924548</td>\n",
              "      <td>0.449705</td>\n",
              "      <td>0.104129</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-537.343224</td>\n",
              "      <td>-633.188069</td>\n",
              "      <td>-611.812399</td>\n",
              "      <td>-594.114564</td>\n",
              "      <td>41.080965</td>\n",
              "      <td>1</td>\n",
              "      <td>-514.399139</td>\n",
              "      <td>-476.132208</td>\n",
              "      <td>-486.784755</td>\n",
              "      <td>-492.438701</td>\n",
              "      <td>16.125856</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "7       1.924548      0.449705         0.104129        0.000223   \n",
              "\n",
              "  param_n_estimators param_max_depth param_criterion  \\\n",
              "7                200               5             mae   \n",
              "\n",
              "                                              params  split0_test_score  \\\n",
              "7  {'n_estimators': 200, 'max_depth': 5, 'criteri...        -537.343224   \n",
              "\n",
              "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "7        -633.188069        -611.812399      -594.114564       41.080965   \n",
              "\n",
              "   rank_test_score  split0_train_score  split1_train_score  \\\n",
              "7                1         -514.399139         -476.132208   \n",
              "\n",
              "   split2_train_score  mean_train_score  std_train_score  \n",
              "7         -486.784755       -492.438701        16.125856  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZPleKB6RnmC",
        "colab_type": "code",
        "outputId": "29c1347c-ee05-4214-c2bc-089803fac2ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "gridsearch.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=5,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZW5HfYtU0GW2"
      },
      "source": [
        "## FEATURE ENGINEERING!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ms-eoOHFvPG"
      },
      "source": [
        "Jake VanderPlas demonstrates this feature engineering: \n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sEwME8wR3A5g",
        "colab": {}
      },
      "source": [
        "# Modified from code cells 17-21 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "def jake_wrangle(X):  \n",
        "    X = X.copy()\n",
        "\n",
        "    # patterns of use generally vary from day to day; \n",
        "    # let's add binary columns that indicate the day of the week:\n",
        "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "    for i, day in enumerate(days):\n",
        "        X[day] = (X.index.dayofweek == i).astype(float)\n",
        "\n",
        "\n",
        "    # we might expect riders to behave differently on holidays; \n",
        "    # let's add an indicator of this as well:\n",
        "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "    cal = USFederalHolidayCalendar()\n",
        "    holidays = cal.holidays('2012', '2016')\n",
        "    X = X.join(pd.Series(1, index=holidays, name='holiday'))\n",
        "    X['holiday'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "    # We also might suspect that the hours of daylight would affect \n",
        "    # how many people ride; let's use the standard astronomical calculation \n",
        "    # to add this information:\n",
        "    def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
        "        \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
        "        days = (date - pd.datetime(2000, 12, 21)).days\n",
        "        m = (1. - np.tan(np.radians(latitude))\n",
        "             * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
        "        return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
        "\n",
        "    X['daylight_hrs'] = list(map(hours_of_daylight, X.index))\n",
        "\n",
        "    \n",
        "    # temperatures are in 1/10 deg C; convert to C\n",
        "    X['TMIN'] /= 10\n",
        "    X['TMAX'] /= 10\n",
        "    \n",
        "    # We can also calcuate the average temperature.\n",
        "    X['Temp (C)'] = 0.5 * (X['TMIN'] + X['TMAX'])\n",
        "\n",
        "    # precip is in 1/10 mm; convert to inches\n",
        "    X['PRCP'] /= 254\n",
        "\n",
        "    # In addition to the inches of precipitation, let's add a flag that \n",
        "    # indicates whether a day is dry (has zero precipitation):\n",
        "    X['dry day'] = (X['PRCP'] == 0).astype(int)\n",
        "\n",
        "\n",
        "    # Let's add a counter that increases from day 1, and measures how many \n",
        "    # years have passed. This will let us measure any observed annual increase \n",
        "    # or decrease in daily crossings:\n",
        "    X['annual'] = (X.index - X.index[0]).days / 365.\n",
        "\n",
        "    return X\n",
        "\n",
        "X_train = jake_wrangle(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeDRXrgGN6SB",
        "colab_type": "code",
        "outputId": "11817053-90f1-4815-bda5-d8ea8e982968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "for i, day in enumerate(days):\n",
        "  print(i, day)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Mon\n",
            "1 Tue\n",
            "2 Wed\n",
            "3 Thu\n",
            "4 Fri\n",
            "5 Sat\n",
            "6 Sun\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dDGkAv813Wtj"
      },
      "source": [
        "### Linear Regression (with new features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cj3HTM6p5F1A",
        "outputId": "d2c906d3-44e5-4b0a-d478-1e9f8d25c8ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "scores = cross_validate(LinearRegression(), X_train, y_train, \n",
        "                        scoring='neg_mean_absolute_error', cv=3, \n",
        "                        return_train_score=True, return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.015851</td>\n",
              "      <td>0.006409</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-297.692524</td>\n",
              "      <td>-294.532315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.005448</td>\n",
              "      <td>0.001445</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-300.419037</td>\n",
              "      <td>-283.779461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.003571</td>\n",
              "      <td>0.001270</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-322.640378</td>\n",
              "      <td>-283.509114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.015851    0.006409  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "1  0.005448    0.001445  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "2  0.003571    0.001270  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -297.692524  -294.532315  \n",
              "1 -300.419037  -283.779461  \n",
              "2 -322.640378  -283.509114  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XABdbNKVUlqF",
        "colab_type": "code",
        "outputId": "43d12f0a-6954-4e81-ef2b-972e611a1a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "-scores['test_score'].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "306.9173130794428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b6zxN2xB3bX_"
      },
      "source": [
        "### Random Forest (with new features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3sWUDZIz1-kk",
        "outputId": "acbd7527-ebfd-4ff7-af3d-904c6eaa8365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "param_distributions = {\n",
        "    'n_estimators': [100], \n",
        "    'max_depth': [5, 10, 15], \n",
        "    'criterion': ['mae']\n",
        "}\n",
        "\n",
        "gridsearch = RandomizedSearchCV(\n",
        "    RandomForestRegressor(n_jobs=-1, random_state=42), \n",
        "    param_distributions=param_distributions, \n",
        "    n_iter=2, \n",
        "    cv=3, \n",
        "    scoring='neg_mean_absolute_error', \n",
        "    verbose=10, \n",
        "    return_train_score=True, \n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    9.3s remaining:    4.7s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   12.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   12.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=2, n_jobs=-1,\n",
              "          param_distributions={'n_estimators': [100], 'max_depth': [5, 10, 15], 'criterion': ['mae']},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPPNLt3vU_Oy",
        "colab_type": "code",
        "outputId": "b685299f-8253-405f-d388-dc12120f34e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "pd.DataFrame(gridsearch.cv_results_).sort_values(by='rank_test_score')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.616482</td>\n",
              "      <td>0.047678</td>\n",
              "      <td>0.110722</td>\n",
              "      <td>0.005819</td>\n",
              "      <td>100</td>\n",
              "      <td>15</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 15, 'criter...</td>\n",
              "      <td>-347.235405</td>\n",
              "      <td>-319.651340</td>\n",
              "      <td>-304.428754</td>\n",
              "      <td>-323.771833</td>\n",
              "      <td>17.716963</td>\n",
              "      <td>1</td>\n",
              "      <td>-112.552009</td>\n",
              "      <td>-102.188061</td>\n",
              "      <td>-116.336075</td>\n",
              "      <td>-110.358715</td>\n",
              "      <td>5.980495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.214792</td>\n",
              "      <td>0.073107</td>\n",
              "      <td>0.110686</td>\n",
              "      <td>0.007984</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 10, 'criter...</td>\n",
              "      <td>-349.442196</td>\n",
              "      <td>-324.468287</td>\n",
              "      <td>-297.640561</td>\n",
              "      <td>-323.850348</td>\n",
              "      <td>21.152443</td>\n",
              "      <td>2</td>\n",
              "      <td>-143.936106</td>\n",
              "      <td>-128.380117</td>\n",
              "      <td>-145.615195</td>\n",
              "      <td>-139.310472</td>\n",
              "      <td>7.759267</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0       3.616482      0.047678         0.110722        0.005819   \n",
              "1       3.214792      0.073107         0.110686        0.007984   \n",
              "\n",
              "  param_n_estimators param_max_depth param_criterion  \\\n",
              "0                100              15             mae   \n",
              "1                100              10             mae   \n",
              "\n",
              "                                              params  split0_test_score  \\\n",
              "0  {'n_estimators': 100, 'max_depth': 15, 'criter...        -347.235405   \n",
              "1  {'n_estimators': 100, 'max_depth': 10, 'criter...        -349.442196   \n",
              "\n",
              "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "0        -319.651340        -304.428754      -323.771833       17.716963   \n",
              "1        -324.468287        -297.640561      -323.850348       21.152443   \n",
              "\n",
              "   rank_test_score  split0_train_score  split1_train_score  \\\n",
              "0                1         -112.552009         -102.188061   \n",
              "1                2         -143.936106         -128.380117   \n",
              "\n",
              "   split2_train_score  mean_train_score  std_train_score  \n",
              "0         -116.336075       -110.358715         5.980495  \n",
              "1         -145.615195       -139.310472         7.759267  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "edpJ87A8A8sd"
      },
      "source": [
        "\n",
        "### Feature engineering, explained by Francois Chollet\n",
        "\n",
        "> _Feature engineering_ is the process of using your own knowledge about the data and about the machine learning algorithm at hand to make the algorithm work better by applying hardcoded (nonlearned) transformations to the data before it goes into the model. In many cases, it isn’t reasonable to expect a machine-learning model to be able to learn from completely arbitrary data. The data needs to be presented to the model in a way that will make the model’s job easier.\n",
        "\n",
        "> Let’s look at an intuitive example. Suppose you’re trying to develop a model that can take as input an image of a clock and can output the time of day.\n",
        "\n",
        "> If you choose to use the raw pixels of the image as input data, then you have a difficult machine-learning problem on your hands. You’ll need a convolutional neural network to solve it, and you’ll have to expend quite a bit of computational resources to train the network.\n",
        "\n",
        "> But if you already understand the problem at a high level (you understand how humans read time on a clock face), then you can come up with much better input features for a machine-learning algorithm: for instance, write a Python script to follow the black pixels of the clock hands and output the (x, y) coordinates of the tip of each hand. Then a simple machine-learning algorithm can learn to associate these coordinates with the appropriate time of day.\n",
        "\n",
        "> You can go even further: do a coordinate change, and express the (x, y) coordinates as polar coordinates with regard to the center of the image. Your input will become the angle theta of each clock hand. At this point, your features are making the problem so easy that no machine learning is required; a simple rounding operation and dictionary lookup are enough to recover the approximate time of day.\n",
        "\n",
        "> That’s the essence of feature engineering: making a problem easier by expressing it in a simpler way. It usually requires understanding the problem in depth.\n",
        "\n",
        "> Before convolutional neural networks became successful on the MNIST digit-classification problem, solutions were typically based on hardcoded features such as the number of loops in a digit image, the height of each digit in an image, a histogram of pixel values, and so on.\n",
        "\n",
        "> Neural networks are capable of automatically extracting useful features from raw data. Does this mean you don’t have to worry about feature engineering as long as you’re using deep neural networks? No, for two reasons:\n",
        "\n",
        "> - Good features still allow you to solve problems more elegantly while using fewer resources. For instance, it would be ridiculous to solve the problem of reading a clock face using a convolutional neural network.\n",
        "> - Good features let you solve a problem with far less data. The ability of deep-learning models to learn features on their own relies on having lots of training data available; if you have only a few samples, then the information value in their features becomes critical.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oux-dd-5FD6p"
      },
      "source": [
        "# ASSIGNMENT\n",
        "\n",
        "**1.** Complete the notebook cells that were originally commented **`TODO`**. \n",
        "\n",
        "**2.** Then, focus on feature engineering to improve your cross validation scores. Collaborate with your cohort on Slack. You could start with the ideas [Jake VanderPlas suggests:](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic)\n",
        "\n",
        "> Our model is almost certainly missing some relevant information. For example, nonlinear effects (such as effects of precipitation and cold temperature) and nonlinear trends within each variable (such as disinclination to ride at very cold and very hot temperatures) cannot be accounted for in this model. Additionally, we have thrown away some of the finer-grained information (such as the difference between a rainy morning and a rainy afternoon), and we have ignored correlations between days (such as the possible effect of a rainy Tuesday on Wednesday's numbers, or the effect of an unexpected sunny day after a streak of rainy days). These are all potentially interesting effects, and you now have the tools to begin exploring them if you wish!\n",
        "\n",
        "**3.** Experiment with the Categorical Encoding notebook.\n",
        "\n",
        "**4.** At the end of the day, take the last step in the \"universal workflow of machine learning\" — \"You can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\"\n",
        "\n",
        "See the [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) documentation for the `refit` parameter, `best_estimator_` attribute, and `predict` method:\n",
        "\n",
        "> **refit : boolean, or string, default=True**\n",
        "\n",
        "> Refit an estimator using the best found parameters on the whole dataset.\n",
        "\n",
        "> The refitted estimator is made available at the `best_estimator_` attribute and permits using `predict` directly on this `GridSearchCV` instance.\n",
        "\n",
        "### STRETCH\n",
        "\n",
        "**A.** Apply this lesson other datasets you've worked with, like Ames Housing, Bank Marketing, or others.\n",
        "\n",
        "**B.** In additon to `RandomizedSearchCV`, scikit-learn has [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Another library called scikit-optimize has [`BayesSearchCV`](https://scikit-optimize.github.io/notebooks/sklearn-gridsearchcv-replacement.html). Experiment with these alternatives.\n",
        "\n",
        "**C.** _[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)_ discusses options for \"Grid-Searching Which Model To Use\" in Chapter 6:\n",
        "\n",
        "> You can even go further in combining GridSearchCV and Pipeline: it is also possible to search over the actual steps being performed in the pipeline (say whether to use StandardScaler or MinMaxScaler). This leads to an even bigger search space and should be considered carefully. Trying all possible solutions is usually not a viable machine learning strategy. However, here is an example comparing a RandomForestClassifier and an SVC ...\n",
        "\n",
        "The example is shown in [the accompanying notebook](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb), code cells 35-37. Could you apply this concept to your own pipelines?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMbTssn2MTJ1",
        "colab_type": "code",
        "outputId": "572d6f69-843e-45e1-d7cb-6ccbe8fe6fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>83</td>\n",
              "      <td>65</td>\n",
              "      <td>3521.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>217</td>\n",
              "      <td>89</td>\n",
              "      <td>57</td>\n",
              "      <td>3475.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>51</td>\n",
              "      <td>3148.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239</td>\n",
              "      <td>78</td>\n",
              "      <td>13</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211</td>\n",
              "      <td>78</td>\n",
              "      <td>19</td>\n",
              "      <td>2142.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2012-10-04     0     0     0   189    83    65           3521.0\n",
              "2012-10-05     0     0     0   217    89    57           3475.0\n",
              "2012-10-06     0     0     0   239    78    51           3148.0\n",
              "2012-10-07     0     0     0   239    78    13           2006.0\n",
              "2012-10-08     0     0     0   211    78    19           2142.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yij935D4MTMC",
        "colab_type": "code",
        "outputId": "6c20668a-37c1-4a30-e1e8-afaeac705230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "      <th>Mon</th>\n",
              "      <th>Tue</th>\n",
              "      <th>Wed</th>\n",
              "      <th>Thu</th>\n",
              "      <th>Fri</th>\n",
              "      <th>Sat</th>\n",
              "      <th>Sun</th>\n",
              "      <th>holiday</th>\n",
              "      <th>daylight_hrs</th>\n",
              "      <th>Temp (C)</th>\n",
              "      <th>dry day</th>\n",
              "      <th>annual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-10-04</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18.9</td>\n",
              "      <td>8.3</td>\n",
              "      <td>65</td>\n",
              "      <td>3521.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.219142</td>\n",
              "      <td>13.60</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-05</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.7</td>\n",
              "      <td>8.9</td>\n",
              "      <td>57</td>\n",
              "      <td>3475.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.161038</td>\n",
              "      <td>15.30</td>\n",
              "      <td>1</td>\n",
              "      <td>0.002740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-06</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>51</td>\n",
              "      <td>3148.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.103056</td>\n",
              "      <td>15.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0.005479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-07</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>7.8</td>\n",
              "      <td>13</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.045208</td>\n",
              "      <td>15.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0.008219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.1</td>\n",
              "      <td>7.8</td>\n",
              "      <td>19</td>\n",
              "      <td>2142.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.987503</td>\n",
              "      <td>14.45</td>\n",
              "      <td>1</td>\n",
              "      <td>0.010959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday  Mon  Tue  \\\n",
              "2012-10-04   0.0     0     0  18.9   8.3    65           3521.0  0.0  0.0   \n",
              "2012-10-05   0.0     0     0  21.7   8.9    57           3475.0  0.0  0.0   \n",
              "2012-10-06   0.0     0     0  23.9   7.8    51           3148.0  0.0  0.0   \n",
              "2012-10-07   0.0     0     0  23.9   7.8    13           2006.0  0.0  0.0   \n",
              "2012-10-08   0.0     0     0  21.1   7.8    19           2142.0  1.0  0.0   \n",
              "\n",
              "            Wed  Thu  Fri  Sat  Sun  holiday  daylight_hrs  Temp (C)  dry day  \\\n",
              "2012-10-04  0.0  1.0  0.0  0.0  0.0      0.0     11.219142     13.60        1   \n",
              "2012-10-05  0.0  0.0  1.0  0.0  0.0      0.0     11.161038     15.30        1   \n",
              "2012-10-06  0.0  0.0  0.0  1.0  0.0      0.0     11.103056     15.85        1   \n",
              "2012-10-07  0.0  0.0  0.0  0.0  1.0      0.0     11.045208     15.85        1   \n",
              "2012-10-08  0.0  0.0  0.0  0.0  0.0      1.0     10.987503     14.45        1   \n",
              "\n",
              "              annual  \n",
              "2012-10-04  0.000000  \n",
              "2012-10-05  0.002740  \n",
              "2012-10-06  0.005479  \n",
              "2012-10-07  0.008219  \n",
              "2012-10-08  0.010959  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vXaNi39MTOa",
        "colab_type": "code",
        "outputId": "4a88d121-f13a-491f-8016-17f3c6531670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatetimeIndex(['2012-10-04', '2012-10-05', '2012-10-06', '2012-10-07',\n",
              "               '2012-10-08', '2012-10-09', '2012-10-10', '2012-10-11',\n",
              "               '2012-10-12', '2012-10-13',\n",
              "               ...\n",
              "               '2015-05-15', '2015-05-16', '2015-05-17', '2015-05-18',\n",
              "               '2015-05-19', '2015-05-20', '2015-05-21', '2015-05-22',\n",
              "               '2015-05-23', '2015-05-24'],\n",
              "              dtype='datetime64[ns]', length=963, freq=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5rwNPd1MTQf",
        "colab_type": "code",
        "outputId": "b4ef7c36-0068-4c57-ba09-02d34b7c1189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "params= {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'max_depth': [3, 4, 5, 6, None],\n",
        "    'criterion' : ['mae'],\n",
        "     \n",
        "}\n",
        "\n",
        "gridsearch = RandomizedSearchCV(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    param_distributions = params,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    n_iter = 20,\n",
        "    cv=3,\n",
        "    n_jobs = -1,\n",
        "    verbose=True,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
              "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=20, n_jobs=-1,\n",
              "          param_distributions={'n_estimators': [50, 100, 150, 200], 'max_depth': [3, 4, 5, 6, None], 'criterion': ['mae']},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
              "          verbose=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6gvXROkSgJE",
        "colab_type": "code",
        "outputId": "30f1cc4b-ac28-4c68-e02f-17b2263d3913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1709
        }
      },
      "source": [
        "pd.DataFrame(gridsearch.cv_results_).sort_values(by='rank_test_score')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6.719057</td>\n",
              "      <td>0.737968</td>\n",
              "      <td>0.023620</td>\n",
              "      <td>0.003075</td>\n",
              "      <td>200</td>\n",
              "      <td>None</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': None, 'crit...</td>\n",
              "      <td>-346.190062</td>\n",
              "      <td>-318.915483</td>\n",
              "      <td>-302.466970</td>\n",
              "      <td>-322.524172</td>\n",
              "      <td>18.031346</td>\n",
              "      <td>1</td>\n",
              "      <td>-106.517150</td>\n",
              "      <td>-99.609498</td>\n",
              "      <td>-111.020724</td>\n",
              "      <td>-105.715790</td>\n",
              "      <td>4.692949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5.437287</td>\n",
              "      <td>0.064146</td>\n",
              "      <td>0.020219</td>\n",
              "      <td>0.001108</td>\n",
              "      <td>150</td>\n",
              "      <td>None</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 150, 'max_depth': None, 'crit...</td>\n",
              "      <td>-349.911236</td>\n",
              "      <td>-319.031734</td>\n",
              "      <td>-300.739595</td>\n",
              "      <td>-323.227522</td>\n",
              "      <td>20.292298</td>\n",
              "      <td>2</td>\n",
              "      <td>-107.762653</td>\n",
              "      <td>-100.485644</td>\n",
              "      <td>-112.196288</td>\n",
              "      <td>-106.814862</td>\n",
              "      <td>4.827596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3.630309</td>\n",
              "      <td>0.099024</td>\n",
              "      <td>0.014127</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>100</td>\n",
              "      <td>None</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': None, 'crit...</td>\n",
              "      <td>-358.797290</td>\n",
              "      <td>-320.268505</td>\n",
              "      <td>-301.250794</td>\n",
              "      <td>-326.772196</td>\n",
              "      <td>23.939135</td>\n",
              "      <td>3</td>\n",
              "      <td>-108.845631</td>\n",
              "      <td>-99.839463</td>\n",
              "      <td>-113.803692</td>\n",
              "      <td>-107.496262</td>\n",
              "      <td>5.780168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.792706</td>\n",
              "      <td>0.025737</td>\n",
              "      <td>0.008530</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>50</td>\n",
              "      <td>None</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 50, 'max_depth': None, 'crite...</td>\n",
              "      <td>-364.483053</td>\n",
              "      <td>-320.885888</td>\n",
              "      <td>-309.882399</td>\n",
              "      <td>-331.750447</td>\n",
              "      <td>23.577346</td>\n",
              "      <td>4</td>\n",
              "      <td>-111.540125</td>\n",
              "      <td>-101.554470</td>\n",
              "      <td>-116.004953</td>\n",
              "      <td>-109.699849</td>\n",
              "      <td>6.041196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5.193666</td>\n",
              "      <td>0.077654</td>\n",
              "      <td>0.018679</td>\n",
              "      <td>0.000568</td>\n",
              "      <td>200</td>\n",
              "      <td>6</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 6, 'criteri...</td>\n",
              "      <td>-338.569868</td>\n",
              "      <td>-354.521698</td>\n",
              "      <td>-311.595148</td>\n",
              "      <td>-334.895571</td>\n",
              "      <td>17.716236</td>\n",
              "      <td>5</td>\n",
              "      <td>-246.257967</td>\n",
              "      <td>-221.985066</td>\n",
              "      <td>-247.074945</td>\n",
              "      <td>-238.439326</td>\n",
              "      <td>11.639698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.903132</td>\n",
              "      <td>0.084699</td>\n",
              "      <td>0.014712</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>150</td>\n",
              "      <td>6</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 150, 'max_depth': 6, 'criteri...</td>\n",
              "      <td>-338.377144</td>\n",
              "      <td>-354.626947</td>\n",
              "      <td>-312.454528</td>\n",
              "      <td>-335.152873</td>\n",
              "      <td>17.367118</td>\n",
              "      <td>6</td>\n",
              "      <td>-246.174886</td>\n",
              "      <td>-221.749720</td>\n",
              "      <td>-247.711983</td>\n",
              "      <td>-238.545530</td>\n",
              "      <td>11.892998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2.581205</td>\n",
              "      <td>0.038792</td>\n",
              "      <td>0.010737</td>\n",
              "      <td>0.000476</td>\n",
              "      <td>100</td>\n",
              "      <td>6</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 6, 'criteri...</td>\n",
              "      <td>-340.982617</td>\n",
              "      <td>-357.709143</td>\n",
              "      <td>-315.642445</td>\n",
              "      <td>-338.111402</td>\n",
              "      <td>17.293249</td>\n",
              "      <td>7</td>\n",
              "      <td>-246.309688</td>\n",
              "      <td>-222.370779</td>\n",
              "      <td>-249.967640</td>\n",
              "      <td>-239.549369</td>\n",
              "      <td>12.238549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.286609</td>\n",
              "      <td>0.030930</td>\n",
              "      <td>0.006743</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>50</td>\n",
              "      <td>6</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 50, 'max_depth': 6, 'criterio...</td>\n",
              "      <td>-351.246199</td>\n",
              "      <td>-357.480187</td>\n",
              "      <td>-316.174766</td>\n",
              "      <td>-341.633718</td>\n",
              "      <td>18.181205</td>\n",
              "      <td>8</td>\n",
              "      <td>-248.789798</td>\n",
              "      <td>-223.687555</td>\n",
              "      <td>-251.758738</td>\n",
              "      <td>-241.412030</td>\n",
              "      <td>12.591569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.765290</td>\n",
              "      <td>0.111254</td>\n",
              "      <td>0.017815</td>\n",
              "      <td>0.000230</td>\n",
              "      <td>200</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-356.324579</td>\n",
              "      <td>-383.678715</td>\n",
              "      <td>-333.667445</td>\n",
              "      <td>-357.890247</td>\n",
              "      <td>20.447009</td>\n",
              "      <td>9</td>\n",
              "      <td>-298.027368</td>\n",
              "      <td>-265.316632</td>\n",
              "      <td>-293.241772</td>\n",
              "      <td>-285.528590</td>\n",
              "      <td>14.424931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.558917</td>\n",
              "      <td>0.037653</td>\n",
              "      <td>0.014072</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>150</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 150, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-358.256376</td>\n",
              "      <td>-383.658868</td>\n",
              "      <td>-333.006521</td>\n",
              "      <td>-358.307255</td>\n",
              "      <td>20.678765</td>\n",
              "      <td>10</td>\n",
              "      <td>-298.832762</td>\n",
              "      <td>-264.696511</td>\n",
              "      <td>-293.238640</td>\n",
              "      <td>-285.589304</td>\n",
              "      <td>14.948917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.366993</td>\n",
              "      <td>0.078378</td>\n",
              "      <td>0.010215</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
              "      <td>-360.615374</td>\n",
              "      <td>-387.242134</td>\n",
              "      <td>-335.736137</td>\n",
              "      <td>-361.197882</td>\n",
              "      <td>21.031269</td>\n",
              "      <td>11</td>\n",
              "      <td>-299.174914</td>\n",
              "      <td>-266.206192</td>\n",
              "      <td>-294.979984</td>\n",
              "      <td>-286.787030</td>\n",
              "      <td>14.653271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.184834</td>\n",
              "      <td>0.041688</td>\n",
              "      <td>0.006514</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>50</td>\n",
              "      <td>5</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 50, 'max_depth': 5, 'criterio...</td>\n",
              "      <td>-369.602181</td>\n",
              "      <td>-387.080312</td>\n",
              "      <td>-338.029221</td>\n",
              "      <td>-364.903904</td>\n",
              "      <td>20.298731</td>\n",
              "      <td>12</td>\n",
              "      <td>-302.977492</td>\n",
              "      <td>-265.555234</td>\n",
              "      <td>-294.478816</td>\n",
              "      <td>-287.670514</td>\n",
              "      <td>16.018137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.179698</td>\n",
              "      <td>0.086867</td>\n",
              "      <td>0.016904</td>\n",
              "      <td>0.000363</td>\n",
              "      <td>200</td>\n",
              "      <td>4</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-404.055187</td>\n",
              "      <td>-431.759984</td>\n",
              "      <td>-379.833333</td>\n",
              "      <td>-405.216168</td>\n",
              "      <td>21.214856</td>\n",
              "      <td>13</td>\n",
              "      <td>-368.264938</td>\n",
              "      <td>-323.936024</td>\n",
              "      <td>-357.404825</td>\n",
              "      <td>-349.868596</td>\n",
              "      <td>18.865475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.110274</td>\n",
              "      <td>0.048170</td>\n",
              "      <td>0.013763</td>\n",
              "      <td>0.000543</td>\n",
              "      <td>150</td>\n",
              "      <td>4</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 150, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-406.150997</td>\n",
              "      <td>-432.763406</td>\n",
              "      <td>-379.827539</td>\n",
              "      <td>-406.247314</td>\n",
              "      <td>21.611085</td>\n",
              "      <td>14</td>\n",
              "      <td>-368.584808</td>\n",
              "      <td>-322.486532</td>\n",
              "      <td>-357.876501</td>\n",
              "      <td>-349.649280</td>\n",
              "      <td>19.698192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.114697</td>\n",
              "      <td>0.032054</td>\n",
              "      <td>0.009739</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 4, 'criteri...</td>\n",
              "      <td>-406.597025</td>\n",
              "      <td>-436.049143</td>\n",
              "      <td>-383.623676</td>\n",
              "      <td>-408.756615</td>\n",
              "      <td>21.457016</td>\n",
              "      <td>15</td>\n",
              "      <td>-369.265179</td>\n",
              "      <td>-325.042087</td>\n",
              "      <td>-360.111363</td>\n",
              "      <td>-351.472876</td>\n",
              "      <td>19.059347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.058816</td>\n",
              "      <td>0.017870</td>\n",
              "      <td>0.006473</td>\n",
              "      <td>0.000114</td>\n",
              "      <td>50</td>\n",
              "      <td>4</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 50, 'max_depth': 4, 'criterio...</td>\n",
              "      <td>-408.758910</td>\n",
              "      <td>-433.390467</td>\n",
              "      <td>-387.022181</td>\n",
              "      <td>-409.723853</td>\n",
              "      <td>18.942067</td>\n",
              "      <td>16</td>\n",
              "      <td>-377.306449</td>\n",
              "      <td>-325.655140</td>\n",
              "      <td>-358.800561</td>\n",
              "      <td>-353.920717</td>\n",
              "      <td>21.367016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.541156</td>\n",
              "      <td>0.060838</td>\n",
              "      <td>0.016716</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>200</td>\n",
              "      <td>3</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 200, 'max_depth': 3, 'criteri...</td>\n",
              "      <td>-483.699548</td>\n",
              "      <td>-505.600724</td>\n",
              "      <td>-457.607796</td>\n",
              "      <td>-482.302690</td>\n",
              "      <td>19.617912</td>\n",
              "      <td>17</td>\n",
              "      <td>-466.486546</td>\n",
              "      <td>-402.630779</td>\n",
              "      <td>-442.234720</td>\n",
              "      <td>-437.117348</td>\n",
              "      <td>26.318946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.629522</td>\n",
              "      <td>0.041774</td>\n",
              "      <td>0.012623</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>150</td>\n",
              "      <td>3</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 150, 'max_depth': 3, 'criteri...</td>\n",
              "      <td>-483.716656</td>\n",
              "      <td>-505.904403</td>\n",
              "      <td>-458.223946</td>\n",
              "      <td>-482.615002</td>\n",
              "      <td>19.481046</td>\n",
              "      <td>18</td>\n",
              "      <td>-465.008146</td>\n",
              "      <td>-401.678790</td>\n",
              "      <td>-443.469128</td>\n",
              "      <td>-436.718688</td>\n",
              "      <td>26.291040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.865766</td>\n",
              "      <td>0.015469</td>\n",
              "      <td>0.006065</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 50, 'max_depth': 3, 'criterio...</td>\n",
              "      <td>-489.121495</td>\n",
              "      <td>-505.301495</td>\n",
              "      <td>-455.585670</td>\n",
              "      <td>-483.336220</td>\n",
              "      <td>20.704555</td>\n",
              "      <td>19</td>\n",
              "      <td>-476.458053</td>\n",
              "      <td>-401.817897</td>\n",
              "      <td>-444.233318</td>\n",
              "      <td>-440.836423</td>\n",
              "      <td>30.566238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.742363</td>\n",
              "      <td>0.038025</td>\n",
              "      <td>0.009380</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>mae</td>\n",
              "      <td>{'n_estimators': 100, 'max_depth': 3, 'criteri...</td>\n",
              "      <td>-488.196713</td>\n",
              "      <td>-509.457243</td>\n",
              "      <td>-463.737773</td>\n",
              "      <td>-487.130576</td>\n",
              "      <td>18.680114</td>\n",
              "      <td>20</td>\n",
              "      <td>-468.625397</td>\n",
              "      <td>-403.691752</td>\n",
              "      <td>-446.643006</td>\n",
              "      <td>-439.653385</td>\n",
              "      <td>26.965851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "19       6.719057      0.737968         0.023620        0.003075   \n",
              "18       5.437287      0.064146         0.020219        0.001108   \n",
              "17       3.630309      0.099024         0.014127        0.000215   \n",
              "16       1.792706      0.025737         0.008530        0.000246   \n",
              "15       5.193666      0.077654         0.018679        0.000568   \n",
              "14       3.903132      0.084699         0.014712        0.000062   \n",
              "13       2.581205      0.038792         0.010737        0.000476   \n",
              "12       1.286609      0.030930         0.006743        0.000049   \n",
              "11       4.765290      0.111254         0.017815        0.000230   \n",
              "10       3.558917      0.037653         0.014072        0.000170   \n",
              "9        2.366993      0.078378         0.010215        0.000177   \n",
              "8        1.184834      0.041688         0.006514        0.000091   \n",
              "7        4.179698      0.086867         0.016904        0.000363   \n",
              "6        3.110274      0.048170         0.013763        0.000543   \n",
              "5        2.114697      0.032054         0.009739        0.000146   \n",
              "4        1.058816      0.017870         0.006473        0.000114   \n",
              "3        3.541156      0.060838         0.016716        0.000310   \n",
              "2        2.629522      0.041774         0.012623        0.000079   \n",
              "0        0.865766      0.015469         0.006065        0.000091   \n",
              "1        1.742363      0.038025         0.009380        0.000042   \n",
              "\n",
              "   param_n_estimators param_max_depth param_criterion  \\\n",
              "19                200            None             mae   \n",
              "18                150            None             mae   \n",
              "17                100            None             mae   \n",
              "16                 50            None             mae   \n",
              "15                200               6             mae   \n",
              "14                150               6             mae   \n",
              "13                100               6             mae   \n",
              "12                 50               6             mae   \n",
              "11                200               5             mae   \n",
              "10                150               5             mae   \n",
              "9                 100               5             mae   \n",
              "8                  50               5             mae   \n",
              "7                 200               4             mae   \n",
              "6                 150               4             mae   \n",
              "5                 100               4             mae   \n",
              "4                  50               4             mae   \n",
              "3                 200               3             mae   \n",
              "2                 150               3             mae   \n",
              "0                  50               3             mae   \n",
              "1                 100               3             mae   \n",
              "\n",
              "                                               params  split0_test_score  \\\n",
              "19  {'n_estimators': 200, 'max_depth': None, 'crit...        -346.190062   \n",
              "18  {'n_estimators': 150, 'max_depth': None, 'crit...        -349.911236   \n",
              "17  {'n_estimators': 100, 'max_depth': None, 'crit...        -358.797290   \n",
              "16  {'n_estimators': 50, 'max_depth': None, 'crite...        -364.483053   \n",
              "15  {'n_estimators': 200, 'max_depth': 6, 'criteri...        -338.569868   \n",
              "14  {'n_estimators': 150, 'max_depth': 6, 'criteri...        -338.377144   \n",
              "13  {'n_estimators': 100, 'max_depth': 6, 'criteri...        -340.982617   \n",
              "12  {'n_estimators': 50, 'max_depth': 6, 'criterio...        -351.246199   \n",
              "11  {'n_estimators': 200, 'max_depth': 5, 'criteri...        -356.324579   \n",
              "10  {'n_estimators': 150, 'max_depth': 5, 'criteri...        -358.256376   \n",
              "9   {'n_estimators': 100, 'max_depth': 5, 'criteri...        -360.615374   \n",
              "8   {'n_estimators': 50, 'max_depth': 5, 'criterio...        -369.602181   \n",
              "7   {'n_estimators': 200, 'max_depth': 4, 'criteri...        -404.055187   \n",
              "6   {'n_estimators': 150, 'max_depth': 4, 'criteri...        -406.150997   \n",
              "5   {'n_estimators': 100, 'max_depth': 4, 'criteri...        -406.597025   \n",
              "4   {'n_estimators': 50, 'max_depth': 4, 'criterio...        -408.758910   \n",
              "3   {'n_estimators': 200, 'max_depth': 3, 'criteri...        -483.699548   \n",
              "2   {'n_estimators': 150, 'max_depth': 3, 'criteri...        -483.716656   \n",
              "0   {'n_estimators': 50, 'max_depth': 3, 'criterio...        -489.121495   \n",
              "1   {'n_estimators': 100, 'max_depth': 3, 'criteri...        -488.196713   \n",
              "\n",
              "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "19        -318.915483        -302.466970      -322.524172       18.031346   \n",
              "18        -319.031734        -300.739595      -323.227522       20.292298   \n",
              "17        -320.268505        -301.250794      -326.772196       23.939135   \n",
              "16        -320.885888        -309.882399      -331.750447       23.577346   \n",
              "15        -354.521698        -311.595148      -334.895571       17.716236   \n",
              "14        -354.626947        -312.454528      -335.152873       17.367118   \n",
              "13        -357.709143        -315.642445      -338.111402       17.293249   \n",
              "12        -357.480187        -316.174766      -341.633718       18.181205   \n",
              "11        -383.678715        -333.667445      -357.890247       20.447009   \n",
              "10        -383.658868        -333.006521      -358.307255       20.678765   \n",
              "9         -387.242134        -335.736137      -361.197882       21.031269   \n",
              "8         -387.080312        -338.029221      -364.903904       20.298731   \n",
              "7         -431.759984        -379.833333      -405.216168       21.214856   \n",
              "6         -432.763406        -379.827539      -406.247314       21.611085   \n",
              "5         -436.049143        -383.623676      -408.756615       21.457016   \n",
              "4         -433.390467        -387.022181      -409.723853       18.942067   \n",
              "3         -505.600724        -457.607796      -482.302690       19.617912   \n",
              "2         -505.904403        -458.223946      -482.615002       19.481046   \n",
              "0         -505.301495        -455.585670      -483.336220       20.704555   \n",
              "1         -509.457243        -463.737773      -487.130576       18.680114   \n",
              "\n",
              "    rank_test_score  split0_train_score  split1_train_score  \\\n",
              "19                1         -106.517150          -99.609498   \n",
              "18                2         -107.762653         -100.485644   \n",
              "17                3         -108.845631          -99.839463   \n",
              "16                4         -111.540125         -101.554470   \n",
              "15                5         -246.257967         -221.985066   \n",
              "14                6         -246.174886         -221.749720   \n",
              "13                7         -246.309688         -222.370779   \n",
              "12                8         -248.789798         -223.687555   \n",
              "11                9         -298.027368         -265.316632   \n",
              "10               10         -298.832762         -264.696511   \n",
              "9                11         -299.174914         -266.206192   \n",
              "8                12         -302.977492         -265.555234   \n",
              "7                13         -368.264938         -323.936024   \n",
              "6                14         -368.584808         -322.486532   \n",
              "5                15         -369.265179         -325.042087   \n",
              "4                16         -377.306449         -325.655140   \n",
              "3                17         -466.486546         -402.630779   \n",
              "2                18         -465.008146         -401.678790   \n",
              "0                19         -476.458053         -401.817897   \n",
              "1                20         -468.625397         -403.691752   \n",
              "\n",
              "    split2_train_score  mean_train_score  std_train_score  \n",
              "19         -111.020724       -105.715790         4.692949  \n",
              "18         -112.196288       -106.814862         4.827596  \n",
              "17         -113.803692       -107.496262         5.780168  \n",
              "16         -116.004953       -109.699849         6.041196  \n",
              "15         -247.074945       -238.439326        11.639698  \n",
              "14         -247.711983       -238.545530        11.892998  \n",
              "13         -249.967640       -239.549369        12.238549  \n",
              "12         -251.758738       -241.412030        12.591569  \n",
              "11         -293.241772       -285.528590        14.424931  \n",
              "10         -293.238640       -285.589304        14.948917  \n",
              "9          -294.979984       -286.787030        14.653271  \n",
              "8          -294.478816       -287.670514        16.018137  \n",
              "7          -357.404825       -349.868596        18.865475  \n",
              "6          -357.876501       -349.649280        19.698192  \n",
              "5          -360.111363       -351.472876        19.059347  \n",
              "4          -358.800561       -353.920717        21.367016  \n",
              "3          -442.234720       -437.117348        26.318946  \n",
              "2          -443.469128       -436.718688        26.291040  \n",
              "0          -444.233318       -440.836423        30.566238  \n",
              "1          -446.643006       -439.653385        26.965851  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ls2b-srdJKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking my above scores with the Linear Regression from lecture\n",
        "scores = cross_validate(LinearRegression(), X_train, y_train, \n",
        "                        scoring='neg_mean_absolute_error', cv=3, \n",
        "                        return_train_score=True, return_estimator=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvSlOyLQeMHQ",
        "colab_type": "code",
        "outputId": "efa5a010-b458-4bd0-ee17-68b5b50a9ab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "pd.DataFrame(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>estimator</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013551</td>\n",
              "      <td>0.002324</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-297.692524</td>\n",
              "      <td>-294.532315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.004608</td>\n",
              "      <td>0.001693</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-300.419037</td>\n",
              "      <td>-283.779461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.004674</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>-322.640378</td>\n",
              "      <td>-283.509114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time                                          estimator  \\\n",
              "0  0.013551    0.002324  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "1  0.004608    0.001693  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "2  0.004674    0.001773  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -297.692524  -294.532315  \n",
              "1 -300.419037  -283.779461  \n",
              "2 -322.640378  -283.509114  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fon-2UaIeSQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}